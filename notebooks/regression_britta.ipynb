{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(r\"c:\\Users\\britt\\Desktop\\YH\\Applicerad AI\\job_discrimination\")\n",
    "import re\n",
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import optuna\n",
    "from catboost import CatBoostRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.linear_model import LinearRegression, ElasticNet, SGDRegressor, BayesianRidge\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, precision_recall_fscore_support, classification_report, accuracy_score, recall_score, precision_score, f1_score, mean_squared_error\n",
    "from sklearn.model_selection import train_test_split, cross_validate, cross_val_score, cross_val_predict\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from unidecode import unidecode\n",
    "from xgboost.sklearn import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Job Description</th>\n",
       "      <th>Apps Received</th>\n",
       "      <th>Female</th>\n",
       "      <th>Male</th>\n",
       "      <th>Unknown_Gender</th>\n",
       "      <th>Cleaned text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9206</td>\n",
       "      <td>311 DIRECTOR</td>\n",
       "      <td>54</td>\n",
       "      <td>20</td>\n",
       "      <td>31</td>\n",
       "      <td>3</td>\n",
       "      <td>director class code open date annual salary du...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1223</td>\n",
       "      <td>ACCOUNTING CLERK</td>\n",
       "      <td>648</td>\n",
       "      <td>488</td>\n",
       "      <td>152</td>\n",
       "      <td>8</td>\n",
       "      <td>accounting clerk class code open date exam ope...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7260</td>\n",
       "      <td>AIRPORT MANAGER</td>\n",
       "      <td>51</td>\n",
       "      <td>13</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>airport manager class code open date exam open...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3227</td>\n",
       "      <td>AIRPORT POLICE LIEUTENANT</td>\n",
       "      <td>48</td>\n",
       "      <td>9</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>airport police lieutenant class code open date...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2400</td>\n",
       "      <td>AQUARIST</td>\n",
       "      <td>40</td>\n",
       "      <td>15</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>aquarist class code open date annual salary ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>7840</td>\n",
       "      <td>WASTEWATER TREATMENT LABORATORY MANAGER</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>wastewater treatment laboratory manager class ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>4123</td>\n",
       "      <td>WASTEWATER TREATMENT OPERATOR</td>\n",
       "      <td>125</td>\n",
       "      <td>9</td>\n",
       "      <td>113</td>\n",
       "      <td>3</td>\n",
       "      <td>wastewater treatment operator class code open ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>7857</td>\n",
       "      <td>WATER MICROBIOLOGIST</td>\n",
       "      <td>179</td>\n",
       "      <td>89</td>\n",
       "      <td>82</td>\n",
       "      <td>8</td>\n",
       "      <td>water microbiologist class code open date revi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>3912</td>\n",
       "      <td>WATER UTILITY WORKER</td>\n",
       "      <td>96</td>\n",
       "      <td>2</td>\n",
       "      <td>92</td>\n",
       "      <td>2</td>\n",
       "      <td>water utility worker class code open date exam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>1774</td>\n",
       "      <td>WORKERS COMPENSATION ANALYST</td>\n",
       "      <td>166</td>\n",
       "      <td>100</td>\n",
       "      <td>61</td>\n",
       "      <td>5</td>\n",
       "      <td>worker compensation analyst class code open da...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>177 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ID                          Job Description  Apps Received  Female  \\\n",
       "0    9206                             311 DIRECTOR             54      20   \n",
       "1    1223                         ACCOUNTING CLERK            648     488   \n",
       "2    7260                          AIRPORT MANAGER             51      13   \n",
       "3    3227                AIRPORT POLICE LIEUTENANT             48       9   \n",
       "4    2400                                 AQUARIST             40      15   \n",
       "..    ...                                      ...            ...     ...   \n",
       "172  7840  WASTEWATER TREATMENT LABORATORY MANAGER             16       6   \n",
       "173  4123            WASTEWATER TREATMENT OPERATOR            125       9   \n",
       "174  7857                     WATER MICROBIOLOGIST            179      89   \n",
       "175  3912                     WATER UTILITY WORKER             96       2   \n",
       "176  1774             WORKERS COMPENSATION ANALYST            166     100   \n",
       "\n",
       "     Male  Unknown_Gender                                       Cleaned text  \n",
       "0      31               3  director class code open date annual salary du...  \n",
       "1     152               8  accounting clerk class code open date exam ope...  \n",
       "2      37               1  airport manager class code open date exam open...  \n",
       "3      38               1  airport police lieutenant class code open date...  \n",
       "4      24               1  aquarist class code open date annual salary ca...  \n",
       "..    ...             ...                                                ...  \n",
       "172     9               1  wastewater treatment laboratory manager class ...  \n",
       "173   113               3  wastewater treatment operator class code open ...  \n",
       "174    82               8  water microbiologist class code open date revi...  \n",
       "175    92               2  water utility worker class code open date exam...  \n",
       "176    61               5  worker compensation analyst class code open da...  \n",
       "\n",
       "[177 rows x 7 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/cleaned_data/bulletins_w_labels_and_content.csv\", dtype={'ID': object})  \n",
    "df = df[[\"ID\", \"Job Description\", \"Apps Received\", \"Female\", \"Male\", \"Unknown_Gender\", \"Cleaned text\"]]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Job Description</th>\n",
       "      <th>Apps Received</th>\n",
       "      <th>Female</th>\n",
       "      <th>Male</th>\n",
       "      <th>Unknown_Gender</th>\n",
       "      <th>Cleaned text</th>\n",
       "      <th>Apps Received (unknown gender removed)</th>\n",
       "      <th>Male share</th>\n",
       "      <th>Female share</th>\n",
       "      <th>Male share (unknown gender included)</th>\n",
       "      <th>Female share (unknown gender included)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9206</td>\n",
       "      <td>311 DIRECTOR</td>\n",
       "      <td>54</td>\n",
       "      <td>20</td>\n",
       "      <td>31</td>\n",
       "      <td>3</td>\n",
       "      <td>director class code open date annual salary du...</td>\n",
       "      <td>51</td>\n",
       "      <td>0.608</td>\n",
       "      <td>0.392</td>\n",
       "      <td>0.574</td>\n",
       "      <td>0.370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1223</td>\n",
       "      <td>ACCOUNTING CLERK</td>\n",
       "      <td>648</td>\n",
       "      <td>488</td>\n",
       "      <td>152</td>\n",
       "      <td>8</td>\n",
       "      <td>accounting clerk class code open date exam ope...</td>\n",
       "      <td>640</td>\n",
       "      <td>0.238</td>\n",
       "      <td>0.762</td>\n",
       "      <td>0.235</td>\n",
       "      <td>0.753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7260</td>\n",
       "      <td>AIRPORT MANAGER</td>\n",
       "      <td>51</td>\n",
       "      <td>13</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>airport manager class code open date exam open...</td>\n",
       "      <td>50</td>\n",
       "      <td>0.740</td>\n",
       "      <td>0.260</td>\n",
       "      <td>0.725</td>\n",
       "      <td>0.255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3227</td>\n",
       "      <td>AIRPORT POLICE LIEUTENANT</td>\n",
       "      <td>48</td>\n",
       "      <td>9</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>airport police lieutenant class code open date...</td>\n",
       "      <td>47</td>\n",
       "      <td>0.809</td>\n",
       "      <td>0.191</td>\n",
       "      <td>0.792</td>\n",
       "      <td>0.188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2400</td>\n",
       "      <td>AQUARIST</td>\n",
       "      <td>40</td>\n",
       "      <td>15</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>aquarist class code open date annual salary ca...</td>\n",
       "      <td>39</td>\n",
       "      <td>0.615</td>\n",
       "      <td>0.385</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>7840</td>\n",
       "      <td>WASTEWATER TREATMENT LABORATORY MANAGER</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>wastewater treatment laboratory manager class ...</td>\n",
       "      <td>15</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.562</td>\n",
       "      <td>0.375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>4123</td>\n",
       "      <td>WASTEWATER TREATMENT OPERATOR</td>\n",
       "      <td>125</td>\n",
       "      <td>9</td>\n",
       "      <td>113</td>\n",
       "      <td>3</td>\n",
       "      <td>wastewater treatment operator class code open ...</td>\n",
       "      <td>122</td>\n",
       "      <td>0.926</td>\n",
       "      <td>0.074</td>\n",
       "      <td>0.904</td>\n",
       "      <td>0.072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>7857</td>\n",
       "      <td>WATER MICROBIOLOGIST</td>\n",
       "      <td>179</td>\n",
       "      <td>89</td>\n",
       "      <td>82</td>\n",
       "      <td>8</td>\n",
       "      <td>water microbiologist class code open date revi...</td>\n",
       "      <td>171</td>\n",
       "      <td>0.480</td>\n",
       "      <td>0.520</td>\n",
       "      <td>0.458</td>\n",
       "      <td>0.497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>3912</td>\n",
       "      <td>WATER UTILITY WORKER</td>\n",
       "      <td>96</td>\n",
       "      <td>2</td>\n",
       "      <td>92</td>\n",
       "      <td>2</td>\n",
       "      <td>water utility worker class code open date exam...</td>\n",
       "      <td>94</td>\n",
       "      <td>0.979</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.958</td>\n",
       "      <td>0.021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>1774</td>\n",
       "      <td>WORKERS COMPENSATION ANALYST</td>\n",
       "      <td>166</td>\n",
       "      <td>100</td>\n",
       "      <td>61</td>\n",
       "      <td>5</td>\n",
       "      <td>worker compensation analyst class code open da...</td>\n",
       "      <td>161</td>\n",
       "      <td>0.379</td>\n",
       "      <td>0.621</td>\n",
       "      <td>0.367</td>\n",
       "      <td>0.602</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>177 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ID                          Job Description  Apps Received  Female  \\\n",
       "0    9206                             311 DIRECTOR             54      20   \n",
       "1    1223                         ACCOUNTING CLERK            648     488   \n",
       "2    7260                          AIRPORT MANAGER             51      13   \n",
       "3    3227                AIRPORT POLICE LIEUTENANT             48       9   \n",
       "4    2400                                 AQUARIST             40      15   \n",
       "..    ...                                      ...            ...     ...   \n",
       "172  7840  WASTEWATER TREATMENT LABORATORY MANAGER             16       6   \n",
       "173  4123            WASTEWATER TREATMENT OPERATOR            125       9   \n",
       "174  7857                     WATER MICROBIOLOGIST            179      89   \n",
       "175  3912                     WATER UTILITY WORKER             96       2   \n",
       "176  1774             WORKERS COMPENSATION ANALYST            166     100   \n",
       "\n",
       "     Male  Unknown_Gender                                       Cleaned text  \\\n",
       "0      31               3  director class code open date annual salary du...   \n",
       "1     152               8  accounting clerk class code open date exam ope...   \n",
       "2      37               1  airport manager class code open date exam open...   \n",
       "3      38               1  airport police lieutenant class code open date...   \n",
       "4      24               1  aquarist class code open date annual salary ca...   \n",
       "..    ...             ...                                                ...   \n",
       "172     9               1  wastewater treatment laboratory manager class ...   \n",
       "173   113               3  wastewater treatment operator class code open ...   \n",
       "174    82               8  water microbiologist class code open date revi...   \n",
       "175    92               2  water utility worker class code open date exam...   \n",
       "176    61               5  worker compensation analyst class code open da...   \n",
       "\n",
       "     Apps Received (unknown gender removed)  Male share  Female share  \\\n",
       "0                                        51       0.608         0.392   \n",
       "1                                       640       0.238         0.762   \n",
       "2                                        50       0.740         0.260   \n",
       "3                                        47       0.809         0.191   \n",
       "4                                        39       0.615         0.385   \n",
       "..                                      ...         ...           ...   \n",
       "172                                      15       0.600         0.400   \n",
       "173                                     122       0.926         0.074   \n",
       "174                                     171       0.480         0.520   \n",
       "175                                      94       0.979         0.021   \n",
       "176                                     161       0.379         0.621   \n",
       "\n",
       "     Male share (unknown gender included)  \\\n",
       "0                                   0.574   \n",
       "1                                   0.235   \n",
       "2                                   0.725   \n",
       "3                                   0.792   \n",
       "4                                   0.600   \n",
       "..                                    ...   \n",
       "172                                 0.562   \n",
       "173                                 0.904   \n",
       "174                                 0.458   \n",
       "175                                 0.958   \n",
       "176                                 0.367   \n",
       "\n",
       "     Female share (unknown gender included)  \n",
       "0                                     0.370  \n",
       "1                                     0.753  \n",
       "2                                     0.255  \n",
       "3                                     0.188  \n",
       "4                                     0.375  \n",
       "..                                      ...  \n",
       "172                                   0.375  \n",
       "173                                   0.072  \n",
       "174                                   0.497  \n",
       "175                                   0.021  \n",
       "176                                   0.602  \n",
       "\n",
       "[177 rows x 12 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Apps Received (unknown gender removed)\"] = df[\"Male\"] + df[\"Female\"]\n",
    "df[\"Male share\"] = round(df[\"Male\"] / df[\"Apps Received (unknown gender removed)\"], 3)\n",
    "df[\"Female share\"] = round(df[\"Female\"] / df[\"Apps Received (unknown gender removed)\"], 3)\n",
    "df[\"Male share (unknown gender included)\"] =  round(df[\"Male\"] / df[\"Apps Received\"], 3)\n",
    "df[\"Female share (unknown gender included)\"] =  round(df[\"Female\"] / df[\"Apps Received\"], 3)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Job Description</th>\n",
       "      <th>Apps Received</th>\n",
       "      <th>Female</th>\n",
       "      <th>Male</th>\n",
       "      <th>Unknown_Gender</th>\n",
       "      <th>Cleaned text</th>\n",
       "      <th>Apps Received (unknown gender removed)</th>\n",
       "      <th>Male share</th>\n",
       "      <th>Female share</th>\n",
       "      <th>Male share (unknown gender included)</th>\n",
       "      <th>Female share (unknown gender included)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5235</td>\n",
       "      <td>SENIOR LOAD DISPATCHER</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>senior load dispatcher class code open date ex...</td>\n",
       "      <td>16</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2495</td>\n",
       "      <td>VOLUNTEER COORDINATOR</td>\n",
       "      <td>326</td>\n",
       "      <td>227</td>\n",
       "      <td>94</td>\n",
       "      <td>5</td>\n",
       "      <td>volunteer coordinator class code open date exa...</td>\n",
       "      <td>321</td>\n",
       "      <td>0.293</td>\n",
       "      <td>0.707</td>\n",
       "      <td>0.288</td>\n",
       "      <td>0.696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3775</td>\n",
       "      <td>SHEET METAL WORKER</td>\n",
       "      <td>271</td>\n",
       "      <td>3</td>\n",
       "      <td>265</td>\n",
       "      <td>3</td>\n",
       "      <td>sheet metal worker class code open date exam o...</td>\n",
       "      <td>268</td>\n",
       "      <td>0.989</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.978</td>\n",
       "      <td>0.011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3421</td>\n",
       "      <td>TRAFFIC PAINTER AND SIGN POSTER</td>\n",
       "      <td>1225</td>\n",
       "      <td>61</td>\n",
       "      <td>1150</td>\n",
       "      <td>14</td>\n",
       "      <td>traffic painter sign poster class code open da...</td>\n",
       "      <td>1211</td>\n",
       "      <td>0.950</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.939</td>\n",
       "      <td>0.050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1861</td>\n",
       "      <td>UTILITY BUYER</td>\n",
       "      <td>126</td>\n",
       "      <td>64</td>\n",
       "      <td>58</td>\n",
       "      <td>4</td>\n",
       "      <td>utility buyer class code open date exam open c...</td>\n",
       "      <td>122</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.525</td>\n",
       "      <td>0.460</td>\n",
       "      <td>0.508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>4240</td>\n",
       "      <td>FIRE SPRINKLER INSPECTOR</td>\n",
       "      <td>83</td>\n",
       "      <td>3</td>\n",
       "      <td>79</td>\n",
       "      <td>1</td>\n",
       "      <td>fire sprinkler inspector class code open date ...</td>\n",
       "      <td>82</td>\n",
       "      <td>0.963</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.952</td>\n",
       "      <td>0.036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>3802</td>\n",
       "      <td>COMMUNICATIONS CABLE WORKER</td>\n",
       "      <td>393</td>\n",
       "      <td>2</td>\n",
       "      <td>386</td>\n",
       "      <td>5</td>\n",
       "      <td>communication cable worker class code open dat...</td>\n",
       "      <td>388</td>\n",
       "      <td>0.995</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.982</td>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>2472</td>\n",
       "      <td>SUPERINTENDENT OF RECREATION AND PARKS OPERATIONS</td>\n",
       "      <td>26</td>\n",
       "      <td>8</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>superintendent recreation park operation class...</td>\n",
       "      <td>26</td>\n",
       "      <td>0.692</td>\n",
       "      <td>0.308</td>\n",
       "      <td>0.692</td>\n",
       "      <td>0.308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>5887</td>\n",
       "      <td>WATER TREATMENT SUPERVISOR</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>water treatment supervisor class code open dat...</td>\n",
       "      <td>15</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.938</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>7291</td>\n",
       "      <td>CONSTRUCTION INSPECTOR</td>\n",
       "      <td>471</td>\n",
       "      <td>17</td>\n",
       "      <td>443</td>\n",
       "      <td>11</td>\n",
       "      <td>construction inspector class code open date ex...</td>\n",
       "      <td>460</td>\n",
       "      <td>0.963</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.941</td>\n",
       "      <td>0.036</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>177 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ID                                    Job Description  Apps Received  \\\n",
       "0    5235                             SENIOR LOAD DISPATCHER             18   \n",
       "1    2495                              VOLUNTEER COORDINATOR            326   \n",
       "2    3775                                 SHEET METAL WORKER            271   \n",
       "3    3421                    TRAFFIC PAINTER AND SIGN POSTER           1225   \n",
       "4    1861                                      UTILITY BUYER            126   \n",
       "..    ...                                                ...            ...   \n",
       "172  4240                           FIRE SPRINKLER INSPECTOR             83   \n",
       "173  3802                        COMMUNICATIONS CABLE WORKER            393   \n",
       "174  2472  SUPERINTENDENT OF RECREATION AND PARKS OPERATIONS             26   \n",
       "175  5887                         WATER TREATMENT SUPERVISOR             16   \n",
       "176  7291                             CONSTRUCTION INSPECTOR            471   \n",
       "\n",
       "     Female  Male  Unknown_Gender  \\\n",
       "0         2    14               2   \n",
       "1       227    94               5   \n",
       "2         3   265               3   \n",
       "3        61  1150              14   \n",
       "4        64    58               4   \n",
       "..      ...   ...             ...   \n",
       "172       3    79               1   \n",
       "173       2   386               5   \n",
       "174       8    18               0   \n",
       "175       0    15               1   \n",
       "176      17   443              11   \n",
       "\n",
       "                                          Cleaned text  \\\n",
       "0    senior load dispatcher class code open date ex...   \n",
       "1    volunteer coordinator class code open date exa...   \n",
       "2    sheet metal worker class code open date exam o...   \n",
       "3    traffic painter sign poster class code open da...   \n",
       "4    utility buyer class code open date exam open c...   \n",
       "..                                                 ...   \n",
       "172  fire sprinkler inspector class code open date ...   \n",
       "173  communication cable worker class code open dat...   \n",
       "174  superintendent recreation park operation class...   \n",
       "175  water treatment supervisor class code open dat...   \n",
       "176  construction inspector class code open date ex...   \n",
       "\n",
       "     Apps Received (unknown gender removed)  Male share  Female share  \\\n",
       "0                                        16       0.875         0.125   \n",
       "1                                       321       0.293         0.707   \n",
       "2                                       268       0.989         0.011   \n",
       "3                                      1211       0.950         0.050   \n",
       "4                                       122       0.475         0.525   \n",
       "..                                      ...         ...           ...   \n",
       "172                                      82       0.963         0.037   \n",
       "173                                     388       0.995         0.005   \n",
       "174                                      26       0.692         0.308   \n",
       "175                                      15       1.000         0.000   \n",
       "176                                     460       0.963         0.037   \n",
       "\n",
       "     Male share (unknown gender included)  \\\n",
       "0                                   0.778   \n",
       "1                                   0.288   \n",
       "2                                   0.978   \n",
       "3                                   0.939   \n",
       "4                                   0.460   \n",
       "..                                    ...   \n",
       "172                                 0.952   \n",
       "173                                 0.982   \n",
       "174                                 0.692   \n",
       "175                                 0.938   \n",
       "176                                 0.941   \n",
       "\n",
       "     Female share (unknown gender included)  \n",
       "0                                     0.111  \n",
       "1                                     0.696  \n",
       "2                                     0.011  \n",
       "3                                     0.050  \n",
       "4                                     0.508  \n",
       "..                                      ...  \n",
       "172                                   0.036  \n",
       "173                                   0.005  \n",
       "174                                   0.308  \n",
       "175                                   0.000  \n",
       "176                                   0.036  \n",
       "\n",
       "[177 rows x 12 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[\"Cleaned text\"]\n",
    "y = df[\"Male share\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(X).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_reg = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = lin_reg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3029337019999674"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(lin_reg, X, y, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.66522046, 0.30128712, 0.12389617, 0.63643065, 0.56745595,\n",
       "       0.1734767 , 0.19236536, 0.54139226, 0.56984163, 0.26709787])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "\n",
    "    # classifier_name = trial.suggest_categorical(\"classifier\", [\"LinReg\", \"RandomForest\", \"DecTree\", \"SVR\", \"GradientBoost\", \"ElasticNet\", \"SGD\", \"BayesRidge\", \"CatBoost\", \"KernelRidge\", \"XGBoost\", \"LGBM\"])\n",
    "    classifier_name = trial.suggest_categorical(\"classifier\", [\"RandomForest\", \"GradientBoost\", \"CatBoost\", \"LGBM\"])\n",
    "    \n",
    "    # Step 2. Setup values for the hyperparameters:\n",
    "    # if classifier_name == 'LinReg':\n",
    "    #     classifier_obj = LinearRegression()\n",
    "    if classifier_name == \"RandomForest\":\n",
    "    #else:\n",
    "        rf_n_estimators = trial.suggest_int(\"rf_n_estimators\", 10, 1000)\n",
    "        rf_max_depth = trial.suggest_int(\"rf_max_depth\", 2, 32, log=True)\n",
    "        classifier_obj = RandomForestRegressor(n_estimators=rf_n_estimators, max_depth=rf_max_depth)\n",
    "    # elif classifier_name == \"DecTree\":\n",
    "    #     classifier_obj = DecisionTreeRegressor()\n",
    "    # elif classifier_name == \"SVR\":\n",
    "    #     #svr_c = trial.suggest_float('svr_c', 1e-10, 1e10, log=True)\n",
    "    #     classifier_obj = SVR(gamma='auto')\n",
    "    elif classifier_name == \"GradientBoost\":\n",
    "        gb_n_estimators = trial.suggest_int(\"gb_n_estimators\", 10, 1000)\n",
    "        gb_lr = trial.suggest_float(\"gb_lr\", 1e-10, 1e10, log=True)\n",
    "        classifier_obj = GradientBoostingRegressor(learning_rate=gb_lr, n_estimators=gb_n_estimators)\n",
    "    # elif classifier_name == \"ElasticNet\":\n",
    "    #     classifier_obj = ElasticNet()\n",
    "    # elif classifier_name == \"SGD\":\n",
    "    #     classifier_obj = SGDRegressor()\n",
    "    # elif classifier_name == \"BayesRidge\":\n",
    "    #     classifier_obj = BayesianRidge()\n",
    "    elif classifier_name == \"CatBoost\":\n",
    "        #cb_lr = trial.suggest_float(\"cb_lr\", 1e-10, 1e10, log=True)\n",
    "        classifier_obj = CatBoostRegressor()\n",
    "    # elif classifier_name == \"KernelRidge\":\n",
    "    #     classifier_obj = KernelRidge()\n",
    "    # elif classifier_name == \"XGBoost\":\n",
    "    #     classifier_obj = XGBRegressor()\n",
    "    elif classifier_name == \"LGBM\":\n",
    "        lgbm_n_estimators = trial.suggest_int(\"lgbm_n_estimators\", 10, 1000)\n",
    "        lgbm_max_depth = trial.suggest_int(\"lgbm_max_depth\", 2, 32, log=True)\n",
    "        classifier_obj = LGBMRegressor(n_estimators=lgbm_n_estimators, max_depth=lgbm_max_depth)\n",
    "\n",
    "    # Step 3: Scoring method:\n",
    "    score = cross_val_score(classifier_obj, X, y, n_jobs=-1, cv=3)\n",
    "    accuracy = score.mean()\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-01-09 15:45:31,497]\u001b[0m A new study created in memory with name: no-name-7e98c05a-e7f5-49db-bb41-7ff0d89b8042\u001b[0m\n",
      "\u001b[33m[W 2023-01-09 15:45:38,048]\u001b[0m Trial 0 failed because of the following error: The value nan is not acceptable.\u001b[0m\n",
      "\u001b[32m[I 2023-01-09 15:46:07,108]\u001b[0m Trial 1 finished with value: 0.5307620110314387 and parameters: {'classifier': 'CatBoost'}. Best is trial 1 with value: 0.5307620110314387.\u001b[0m\n",
      "\u001b[32m[I 2023-01-09 15:46:32,768]\u001b[0m Trial 2 finished with value: 0.5307620110314387 and parameters: {'classifier': 'CatBoost'}. Best is trial 1 with value: 0.5307620110314387.\u001b[0m\n",
      "\u001b[32m[I 2023-01-09 15:46:39,328]\u001b[0m Trial 3 finished with value: 0.5098793832609321 and parameters: {'classifier': 'RandomForest', 'rf_n_estimators': 324, 'rf_max_depth': 19}. Best is trial 1 with value: 0.5307620110314387.\u001b[0m\n",
      "\u001b[32m[I 2023-01-09 15:46:40,749]\u001b[0m Trial 4 finished with value: 0.5351803772256639 and parameters: {'classifier': 'LGBM', 'lgbm_n_estimators': 78, 'lgbm_max_depth': 32}. Best is trial 4 with value: 0.5351803772256639.\u001b[0m\n",
      "\u001b[32m[I 2023-01-09 15:46:54,130]\u001b[0m Trial 5 finished with value: 0.5046551856672782 and parameters: {'classifier': 'RandomForest', 'rf_n_estimators': 579, 'rf_max_depth': 32}. Best is trial 4 with value: 0.5351803772256639.\u001b[0m\n",
      "\u001b[32m[I 2023-01-09 15:46:54,799]\u001b[0m Trial 6 finished with value: 0.5406850188717081 and parameters: {'classifier': 'LGBM', 'lgbm_n_estimators': 866, 'lgbm_max_depth': 8}. Best is trial 6 with value: 0.5406850188717081.\u001b[0m\n",
      "\u001b[32m[I 2023-01-09 15:47:01,193]\u001b[0m Trial 7 finished with value: 0.49668001804688355 and parameters: {'classifier': 'RandomForest', 'rf_n_estimators': 288, 'rf_max_depth': 9}. Best is trial 6 with value: 0.5406850188717081.\u001b[0m\n",
      "\u001b[33m[W 2023-01-09 15:47:06,068]\u001b[0m Trial 8 failed because of the following error: The value nan is not acceptable.\u001b[0m\n",
      "\u001b[32m[I 2023-01-09 15:47:12,022]\u001b[0m Trial 9 finished with value: -0.011265080052880183 and parameters: {'classifier': 'GradientBoost', 'gb_n_estimators': 445, 'gb_lr': 3.2670810312222538e-06}. Best is trial 6 with value: 0.5406850188717081.\u001b[0m\n",
      "\u001b[33m[W 2023-01-09 15:47:13,702]\u001b[0m Trial 10 failed because of the following error: The value nan is not acceptable.\u001b[0m\n",
      "\u001b[32m[I 2023-01-09 15:47:39,224]\u001b[0m Trial 11 finished with value: 0.5307620110314387 and parameters: {'classifier': 'CatBoost'}. Best is trial 6 with value: 0.5406850188717081.\u001b[0m\n",
      "\u001b[32m[I 2023-01-09 15:47:55,305]\u001b[0m Trial 12 finished with value: 0.5068958455120286 and parameters: {'classifier': 'RandomForest', 'rf_n_estimators': 784, 'rf_max_depth': 13}. Best is trial 6 with value: 0.5406850188717081.\u001b[0m\n",
      "\u001b[32m[I 2023-01-09 15:47:56,080]\u001b[0m Trial 13 finished with value: 0.5406217479252226 and parameters: {'classifier': 'LGBM', 'lgbm_n_estimators': 974, 'lgbm_max_depth': 4}. Best is trial 6 with value: 0.5406850188717081.\u001b[0m\n",
      "\u001b[32m[I 2023-01-09 15:47:56,717]\u001b[0m Trial 14 finished with value: 0.5406109086093885 and parameters: {'classifier': 'LGBM', 'lgbm_n_estimators': 991, 'lgbm_max_depth': 4}. Best is trial 6 with value: 0.5406850188717081.\u001b[0m\n",
      "\u001b[32m[I 2023-01-09 15:47:57,367]\u001b[0m Trial 15 finished with value: 0.5406212919318788 and parameters: {'classifier': 'LGBM', 'lgbm_n_estimators': 977, 'lgbm_max_depth': 7}. Best is trial 6 with value: 0.5406850188717081.\u001b[0m\n",
      "\u001b[32m[I 2023-01-09 15:47:57,837]\u001b[0m Trial 16 finished with value: 0.5408139487836695 and parameters: {'classifier': 'LGBM', 'lgbm_n_estimators': 733, 'lgbm_max_depth': 8}. Best is trial 16 with value: 0.5408139487836695.\u001b[0m\n",
      "\u001b[32m[I 2023-01-09 15:47:58,459]\u001b[0m Trial 17 finished with value: 0.5409457499149265 and parameters: {'classifier': 'LGBM', 'lgbm_n_estimators': 627, 'lgbm_max_depth': 11}. Best is trial 17 with value: 0.5409457499149265.\u001b[0m\n",
      "\u001b[33m[W 2023-01-09 15:48:03,730]\u001b[0m Trial 18 failed because of the following error: The value nan is not acceptable.\u001b[0m\n",
      "\u001b[33m[W 2023-01-09 15:48:08,927]\u001b[0m Trial 19 failed because of the following error: The value nan is not acceptable.\u001b[0m\n",
      "\u001b[33m[W 2023-01-09 15:48:14,317]\u001b[0m Trial 20 failed because of the following error: The value nan is not acceptable.\u001b[0m\n",
      "\u001b[33m[W 2023-01-09 15:48:19,336]\u001b[0m Trial 21 failed because of the following error: The value nan is not acceptable.\u001b[0m\n",
      "\u001b[33m[W 2023-01-09 15:48:24,202]\u001b[0m Trial 22 failed because of the following error: The value nan is not acceptable.\u001b[0m\n",
      "\u001b[33m[W 2023-01-09 15:48:29,681]\u001b[0m Trial 23 failed because of the following error: The value nan is not acceptable.\u001b[0m\n",
      "\u001b[33m[W 2023-01-09 15:48:34,548]\u001b[0m Trial 24 failed because of the following error: The value nan is not acceptable.\u001b[0m\n",
      "\u001b[33m[W 2023-01-09 15:48:39,250]\u001b[0m Trial 25 failed because of the following error: The value nan is not acceptable.\u001b[0m\n",
      "\u001b[33m[W 2023-01-09 15:48:44,307]\u001b[0m Trial 26 failed because of the following error: The value nan is not acceptable.\u001b[0m\n",
      "\u001b[33m[W 2023-01-09 15:48:49,330]\u001b[0m Trial 27 failed because of the following error: The value nan is not acceptable.\u001b[0m\n",
      "\u001b[33m[W 2023-01-09 15:48:54,340]\u001b[0m Trial 28 failed because of the following error: The value nan is not acceptable.\u001b[0m\n",
      "\u001b[33m[W 2023-01-09 15:48:59,361]\u001b[0m Trial 29 failed because of the following error: The value nan is not acceptable.\u001b[0m\n",
      "\u001b[33m[W 2023-01-09 15:49:04,383]\u001b[0m Trial 30 failed because of the following error: The value nan is not acceptable.\u001b[0m\n",
      "\u001b[33m[W 2023-01-09 15:49:10,042]\u001b[0m Trial 31 failed because of the following error: The value nan is not acceptable.\u001b[0m\n",
      "\u001b[33m[W 2023-01-09 15:49:13,875]\u001b[0m Trial 32 failed because of the following error: The value nan is not acceptable.\u001b[0m\n",
      "\u001b[33m[W 2023-01-09 15:49:17,790]\u001b[0m Trial 33 failed because of the following error: The value nan is not acceptable.\u001b[0m\n",
      "\u001b[33m[W 2023-01-09 15:49:22,549]\u001b[0m Trial 34 failed because of the following error: The value nan is not acceptable.\u001b[0m\n",
      "\u001b[33m[W 2023-01-09 15:49:26,328]\u001b[0m Trial 35 failed because of the following error: The value nan is not acceptable.\u001b[0m\n",
      "\u001b[33m[W 2023-01-09 15:49:30,471]\u001b[0m Trial 36 failed because of the following error: The value nan is not acceptable.\u001b[0m\n",
      "\u001b[33m[W 2023-01-09 15:49:35,613]\u001b[0m Trial 37 failed because of the following error: The value nan is not acceptable.\u001b[0m\n",
      "\u001b[33m[W 2023-01-09 15:49:40,809]\u001b[0m Trial 38 failed because of the following error: The value nan is not acceptable.\u001b[0m\n",
      "\u001b[33m[W 2023-01-09 15:49:45,150]\u001b[0m Trial 39 failed because of the following error: The value nan is not acceptable.\u001b[0m\n",
      "\u001b[33m[W 2023-01-09 15:49:49,269]\u001b[0m Trial 40 failed because of the following error: KeyboardInterrupt()\u001b[0m\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\britt\\Desktop\\YH\\Applicerad AI\\job_discrimination\\venv_job_discrimination\\lib\\site-packages\\optuna\\study\\_optimize.py\", line 196, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"C:\\Users\\britt\\AppData\\Local\\Temp\\ipykernel_5484\\4202786873.py\", line 42, in objective\n",
      "    score = cross_val_score(classifier_obj, X, y, n_jobs=-1, cv=3)\n",
      "  File \"c:\\Users\\britt\\Desktop\\YH\\Applicerad AI\\job_discrimination\\venv_job_discrimination\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 515, in cross_val_score\n",
      "    cv_results = cross_validate(\n",
      "  File \"c:\\Users\\britt\\Desktop\\YH\\Applicerad AI\\job_discrimination\\venv_job_discrimination\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 266, in cross_validate\n",
      "    results = parallel(\n",
      "  File \"c:\\Users\\britt\\Desktop\\YH\\Applicerad AI\\job_discrimination\\venv_job_discrimination\\lib\\site-packages\\joblib\\parallel.py\", line 1098, in __call__\n",
      "    self.retrieve()\n",
      "  File \"c:\\Users\\britt\\Desktop\\YH\\Applicerad AI\\job_discrimination\\venv_job_discrimination\\lib\\site-packages\\joblib\\parallel.py\", line 975, in retrieve\n",
      "    self._output.extend(job.get(timeout=self.timeout))\n",
      "  File \"c:\\Users\\britt\\Desktop\\YH\\Applicerad AI\\job_discrimination\\venv_job_discrimination\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 567, in wrap_future_result\n",
      "    return future.result(timeout=timeout)\n",
      "  File \"C:\\Users\\britt\\Languages\\Python\\Python3106\\lib\\concurrent\\futures\\_base.py\", line 453, in result\n",
      "    self._condition.wait(timeout)\n",
      "  File \"C:\\Users\\britt\\Languages\\Python\\Python3106\\lib\\threading.py\", line 320, in wait\n",
      "    waiter.acquire()\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m study \u001b[39m=\u001b[39m optuna\u001b[39m.\u001b[39mcreate_study(direction\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmaximize\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m study\u001b[39m.\u001b[39;49moptimize(objective, n_trials\u001b[39m=\u001b[39;49m\u001b[39m50\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\britt\\Desktop\\YH\\Applicerad AI\\job_discrimination\\venv_job_discrimination\\lib\\site-packages\\optuna\\study\\study.py:419\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    315\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39moptimize\u001b[39m(\n\u001b[0;32m    316\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    317\u001b[0m     func: ObjectiveFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    324\u001b[0m     show_progress_bar: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    325\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    326\u001b[0m     \u001b[39m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[0;32m    327\u001b[0m \n\u001b[0;32m    328\u001b[0m \u001b[39m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    416\u001b[0m \u001b[39m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[0;32m    417\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 419\u001b[0m     _optimize(\n\u001b[0;32m    420\u001b[0m         study\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[0;32m    421\u001b[0m         func\u001b[39m=\u001b[39;49mfunc,\n\u001b[0;32m    422\u001b[0m         n_trials\u001b[39m=\u001b[39;49mn_trials,\n\u001b[0;32m    423\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[0;32m    424\u001b[0m         n_jobs\u001b[39m=\u001b[39;49mn_jobs,\n\u001b[0;32m    425\u001b[0m         catch\u001b[39m=\u001b[39;49mcatch,\n\u001b[0;32m    426\u001b[0m         callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[0;32m    427\u001b[0m         gc_after_trial\u001b[39m=\u001b[39;49mgc_after_trial,\n\u001b[0;32m    428\u001b[0m         show_progress_bar\u001b[39m=\u001b[39;49mshow_progress_bar,\n\u001b[0;32m    429\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\britt\\Desktop\\YH\\Applicerad AI\\job_discrimination\\venv_job_discrimination\\lib\\site-packages\\optuna\\study\\_optimize.py:66\u001b[0m, in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     65\u001b[0m     \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m---> 66\u001b[0m         _optimize_sequential(\n\u001b[0;32m     67\u001b[0m             study,\n\u001b[0;32m     68\u001b[0m             func,\n\u001b[0;32m     69\u001b[0m             n_trials,\n\u001b[0;32m     70\u001b[0m             timeout,\n\u001b[0;32m     71\u001b[0m             catch,\n\u001b[0;32m     72\u001b[0m             callbacks,\n\u001b[0;32m     73\u001b[0m             gc_after_trial,\n\u001b[0;32m     74\u001b[0m             reseed_sampler_rng\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m     75\u001b[0m             time_start\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m     76\u001b[0m             progress_bar\u001b[39m=\u001b[39;49mprogress_bar,\n\u001b[0;32m     77\u001b[0m         )\n\u001b[0;32m     78\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     79\u001b[0m         \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\britt\\Desktop\\YH\\Applicerad AI\\job_discrimination\\venv_job_discrimination\\lib\\site-packages\\optuna\\study\\_optimize.py:160\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    157\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m    159\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 160\u001b[0m     frozen_trial \u001b[39m=\u001b[39m _run_trial(study, func, catch)\n\u001b[0;32m    161\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    162\u001b[0m     \u001b[39m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[0;32m    163\u001b[0m     \u001b[39m# environments (e.g., services that use computing containers such as CircleCI).\u001b[39;00m\n\u001b[0;32m    164\u001b[0m     \u001b[39m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[0;32m    165\u001b[0m     \u001b[39m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[0;32m    166\u001b[0m     \u001b[39mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[1;32mc:\\Users\\britt\\Desktop\\YH\\Applicerad AI\\job_discrimination\\venv_job_discrimination\\lib\\site-packages\\optuna\\study\\_optimize.py:234\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    227\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mFalse\u001b[39;00m, \u001b[39m\"\u001b[39m\u001b[39mShould not reach.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    229\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[0;32m    230\u001b[0m     frozen_trial\u001b[39m.\u001b[39mstate \u001b[39m==\u001b[39m TrialState\u001b[39m.\u001b[39mFAIL\n\u001b[0;32m    231\u001b[0m     \u001b[39mand\u001b[39;00m func_err \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    232\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(func_err, catch)\n\u001b[0;32m    233\u001b[0m ):\n\u001b[1;32m--> 234\u001b[0m     \u001b[39mraise\u001b[39;00m func_err\n\u001b[0;32m    235\u001b[0m \u001b[39mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[1;32mc:\\Users\\britt\\Desktop\\YH\\Applicerad AI\\job_discrimination\\venv_job_discrimination\\lib\\site-packages\\optuna\\study\\_optimize.py:196\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    194\u001b[0m \u001b[39mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[39m.\u001b[39m_trial_id, study\u001b[39m.\u001b[39m_storage):\n\u001b[0;32m    195\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 196\u001b[0m         value_or_values \u001b[39m=\u001b[39m func(trial)\n\u001b[0;32m    197\u001b[0m     \u001b[39mexcept\u001b[39;00m exceptions\u001b[39m.\u001b[39mTrialPruned \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    198\u001b[0m         \u001b[39m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[0;32m    199\u001b[0m         state \u001b[39m=\u001b[39m TrialState\u001b[39m.\u001b[39mPRUNED\n",
      "Cell \u001b[1;32mIn[15], line 42\u001b[0m, in \u001b[0;36mobjective\u001b[1;34m(trial)\u001b[0m\n\u001b[0;32m     39\u001b[0m     classifier_obj \u001b[39m=\u001b[39m LGBMRegressor(n_estimators\u001b[39m=\u001b[39mlgbm_n_estimators, max_depth\u001b[39m=\u001b[39mlgbm_max_depth)\n\u001b[0;32m     41\u001b[0m \u001b[39m# Step 3: Scoring method:\u001b[39;00m\n\u001b[1;32m---> 42\u001b[0m score \u001b[39m=\u001b[39m cross_val_score(classifier_obj, X, y, n_jobs\u001b[39m=\u001b[39;49m\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m, cv\u001b[39m=\u001b[39;49m\u001b[39m3\u001b[39;49m)\n\u001b[0;32m     43\u001b[0m accuracy \u001b[39m=\u001b[39m score\u001b[39m.\u001b[39mmean()\n\u001b[0;32m     44\u001b[0m \u001b[39mreturn\u001b[39;00m accuracy\n",
      "File \u001b[1;32mc:\\Users\\britt\\Desktop\\YH\\Applicerad AI\\job_discrimination\\venv_job_discrimination\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:515\u001b[0m, in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[0;32m    512\u001b[0m \u001b[39m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[0;32m    513\u001b[0m scorer \u001b[39m=\u001b[39m check_scoring(estimator, scoring\u001b[39m=\u001b[39mscoring)\n\u001b[1;32m--> 515\u001b[0m cv_results \u001b[39m=\u001b[39m cross_validate(\n\u001b[0;32m    516\u001b[0m     estimator\u001b[39m=\u001b[39;49mestimator,\n\u001b[0;32m    517\u001b[0m     X\u001b[39m=\u001b[39;49mX,\n\u001b[0;32m    518\u001b[0m     y\u001b[39m=\u001b[39;49my,\n\u001b[0;32m    519\u001b[0m     groups\u001b[39m=\u001b[39;49mgroups,\n\u001b[0;32m    520\u001b[0m     scoring\u001b[39m=\u001b[39;49m{\u001b[39m\"\u001b[39;49m\u001b[39mscore\u001b[39;49m\u001b[39m\"\u001b[39;49m: scorer},\n\u001b[0;32m    521\u001b[0m     cv\u001b[39m=\u001b[39;49mcv,\n\u001b[0;32m    522\u001b[0m     n_jobs\u001b[39m=\u001b[39;49mn_jobs,\n\u001b[0;32m    523\u001b[0m     verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[0;32m    524\u001b[0m     fit_params\u001b[39m=\u001b[39;49mfit_params,\n\u001b[0;32m    525\u001b[0m     pre_dispatch\u001b[39m=\u001b[39;49mpre_dispatch,\n\u001b[0;32m    526\u001b[0m     error_score\u001b[39m=\u001b[39;49merror_score,\n\u001b[0;32m    527\u001b[0m )\n\u001b[0;32m    528\u001b[0m \u001b[39mreturn\u001b[39;00m cv_results[\u001b[39m\"\u001b[39m\u001b[39mtest_score\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\britt\\Desktop\\YH\\Applicerad AI\\job_discrimination\\venv_job_discrimination\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:266\u001b[0m, in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    263\u001b[0m \u001b[39m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[0;32m    264\u001b[0m \u001b[39m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[0;32m    265\u001b[0m parallel \u001b[39m=\u001b[39m Parallel(n_jobs\u001b[39m=\u001b[39mn_jobs, verbose\u001b[39m=\u001b[39mverbose, pre_dispatch\u001b[39m=\u001b[39mpre_dispatch)\n\u001b[1;32m--> 266\u001b[0m results \u001b[39m=\u001b[39m parallel(\n\u001b[0;32m    267\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    268\u001b[0m         clone(estimator),\n\u001b[0;32m    269\u001b[0m         X,\n\u001b[0;32m    270\u001b[0m         y,\n\u001b[0;32m    271\u001b[0m         scorers,\n\u001b[0;32m    272\u001b[0m         train,\n\u001b[0;32m    273\u001b[0m         test,\n\u001b[0;32m    274\u001b[0m         verbose,\n\u001b[0;32m    275\u001b[0m         \u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m    276\u001b[0m         fit_params,\n\u001b[0;32m    277\u001b[0m         return_train_score\u001b[39m=\u001b[39;49mreturn_train_score,\n\u001b[0;32m    278\u001b[0m         return_times\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m    279\u001b[0m         return_estimator\u001b[39m=\u001b[39;49mreturn_estimator,\n\u001b[0;32m    280\u001b[0m         error_score\u001b[39m=\u001b[39;49merror_score,\n\u001b[0;32m    281\u001b[0m     )\n\u001b[0;32m    282\u001b[0m     \u001b[39mfor\u001b[39;49;00m train, test \u001b[39min\u001b[39;49;00m cv\u001b[39m.\u001b[39;49msplit(X, y, groups)\n\u001b[0;32m    283\u001b[0m )\n\u001b[0;32m    285\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[0;32m    287\u001b[0m \u001b[39m# For callabe scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[0;32m    288\u001b[0m \u001b[39m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[0;32m    289\u001b[0m \u001b[39m# the correct key.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\britt\\Desktop\\YH\\Applicerad AI\\job_discrimination\\venv_job_discrimination\\lib\\site-packages\\joblib\\parallel.py:1098\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1095\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m   1097\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend\u001b[39m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1098\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mretrieve()\n\u001b[0;32m   1099\u001b[0m \u001b[39m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[0;32m   1100\u001b[0m elapsed_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_start_time\n",
      "File \u001b[1;32mc:\\Users\\britt\\Desktop\\YH\\Applicerad AI\\job_discrimination\\venv_job_discrimination\\lib\\site-packages\\joblib\\parallel.py:975\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    973\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    974\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, \u001b[39m'\u001b[39m\u001b[39msupports_timeout\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m--> 975\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtimeout))\n\u001b[0;32m    976\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    977\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39mget())\n",
      "File \u001b[1;32mc:\\Users\\britt\\Desktop\\YH\\Applicerad AI\\job_discrimination\\venv_job_discrimination\\lib\\site-packages\\joblib\\_parallel_backends.py:567\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    564\u001b[0m \u001b[39m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[0;32m    565\u001b[0m \u001b[39mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[0;32m    566\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 567\u001b[0m     \u001b[39mreturn\u001b[39;00m future\u001b[39m.\u001b[39;49mresult(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[0;32m    568\u001b[0m \u001b[39mexcept\u001b[39;00m CfTimeoutError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    569\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "File \u001b[1;32m~\\Languages\\Python\\Python3106\\lib\\concurrent\\futures\\_base.py:453\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    450\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[0;32m    451\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__get_result()\n\u001b[1;32m--> 453\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_condition\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[0;32m    455\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[0;32m    456\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[1;32m~\\Languages\\Python\\Python3106\\lib\\threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[39mtry\u001b[39;00m:    \u001b[39m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[0;32m    319\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 320\u001b[0m         waiter\u001b[39m.\u001b[39;49macquire()\n\u001b[0;32m    321\u001b[0m         gotit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    322\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    param = {}\n",
    "    param['learning_rate'] = trial.suggest_float(\"learning_rate\", 0.001, 0.02, step=0.001)\n",
    "    param['depth'] = trial.suggest_int('depth', 9, 15)\n",
    "    param['l2_leaf_reg'] = trial.suggest_float('l2_leaf_reg', 1.0, 5.5, step=0.5)\n",
    "    param['min_child_samples'] = trial.suggest_categorical('min_child_samples', [1, 4, 8, 16, 32])\n",
    "    param['grow_policy'] = 'Depthwise'\n",
    "    #param['iterations'] = 10000\n",
    "    #param['use_best_model'] = True\n",
    "    param['eval_metric'] = 'RMSE'\n",
    "    param['od_type'] = 'iter'\n",
    "    param['od_wait'] = 20\n",
    "    param['random_state'] = 1\n",
    "    param['logging_level'] = 'Silent'\n",
    "    \n",
    "    regressor = CatBoostRegressor(**param)\n",
    "\n",
    "    regressor.fit(X_train, y_train, early_stopping_rounds=100)\n",
    "    loss = mean_squared_error(y_test, regressor.predict(X_test))\n",
    "    return loss\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-01-10 08:58:28,874]\u001b[0m A new study created in memory with name: catboost-seed1\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 09:00:06,943]\u001b[0m Trial 0 finished with value: 0.031040337805151554 and parameters: {'learning_rate': 0.005, 'depth': 9, 'l2_leaf_reg': 5.5, 'min_child_samples': 1}. Best is trial 0 with value: 0.031040337805151554.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 09:01:28,512]\u001b[0m Trial 1 finished with value: 0.040813299781956615 and parameters: {'learning_rate': 0.001, 'depth': 15, 'l2_leaf_reg': 1.5, 'min_child_samples': 8}. Best is trial 0 with value: 0.031040337805151554.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 09:02:39,974]\u001b[0m Trial 2 finished with value: 0.03245324351548526 and parameters: {'learning_rate': 0.002, 'depth': 13, 'l2_leaf_reg': 1.0, 'min_child_samples': 8}. Best is trial 0 with value: 0.031040337805151554.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 09:03:11,248]\u001b[0m Trial 3 finished with value: 0.02709879194730593 and parameters: {'learning_rate': 0.007, 'depth': 11, 'l2_leaf_reg': 1.5, 'min_child_samples': 32}. Best is trial 3 with value: 0.02709879194730593.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 09:04:07,245]\u001b[0m Trial 4 finished with value: 0.02769062005599278 and parameters: {'learning_rate': 0.017, 'depth': 12, 'l2_leaf_reg': 1.0, 'min_child_samples': 8}. Best is trial 3 with value: 0.02709879194730593.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 09:04:49,893]\u001b[0m Trial 5 finished with value: 0.027598595418711038 and parameters: {'learning_rate': 0.011, 'depth': 11, 'l2_leaf_reg': 4.0, 'min_child_samples': 16}. Best is trial 3 with value: 0.02709879194730593.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 09:07:05,962]\u001b[0m Trial 6 finished with value: 0.04346807473968585 and parameters: {'learning_rate': 0.001, 'depth': 15, 'l2_leaf_reg': 2.0, 'min_child_samples': 4}. Best is trial 3 with value: 0.02709879194730593.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 09:07:44,960]\u001b[0m Trial 7 finished with value: 0.0269256274688837 and parameters: {'learning_rate': 0.008, 'depth': 10, 'l2_leaf_reg': 4.0, 'min_child_samples': 16}. Best is trial 7 with value: 0.0269256274688837.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 09:08:19,685]\u001b[0m Trial 8 finished with value: 0.02796798559823946 and parameters: {'learning_rate': 0.011, 'depth': 9, 'l2_leaf_reg': 5.0, 'min_child_samples': 16}. Best is trial 7 with value: 0.0269256274688837.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 09:10:54,211]\u001b[0m Trial 9 finished with value: 0.030238302416927383 and parameters: {'learning_rate': 0.007, 'depth': 10, 'l2_leaf_reg': 5.0, 'min_child_samples': 1}. Best is trial 7 with value: 0.0269256274688837.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 09:11:37,076]\u001b[0m Trial 10 finished with value: 0.02683411912185851 and parameters: {'learning_rate': 0.015, 'depth': 13, 'l2_leaf_reg': 3.0, 'min_child_samples': 16}. Best is trial 10 with value: 0.02683411912185851.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 09:12:16,619]\u001b[0m Trial 11 finished with value: 0.02760042770426677 and parameters: {'learning_rate': 0.017, 'depth': 13, 'l2_leaf_reg': 3.0, 'min_child_samples': 16}. Best is trial 10 with value: 0.02683411912185851.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 09:12:56,997]\u001b[0m Trial 12 finished with value: 0.02856919391298818 and parameters: {'learning_rate': 0.014000000000000002, 'depth': 13, 'l2_leaf_reg': 3.5, 'min_child_samples': 16}. Best is trial 10 with value: 0.02683411912185851.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 09:13:41,309]\u001b[0m Trial 13 finished with value: 0.02550329900720659 and parameters: {'learning_rate': 0.014000000000000002, 'depth': 14, 'l2_leaf_reg': 3.0, 'min_child_samples': 16}. Best is trial 13 with value: 0.02550329900720659.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 09:14:59,497]\u001b[0m Trial 14 finished with value: 0.0291353752591373 and parameters: {'learning_rate': 0.02, 'depth': 14, 'l2_leaf_reg': 2.5, 'min_child_samples': 4}. Best is trial 13 with value: 0.02550329900720659.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 09:15:35,109]\u001b[0m Trial 15 finished with value: 0.026832910088750456 and parameters: {'learning_rate': 0.014000000000000002, 'depth': 14, 'l2_leaf_reg': 3.0, 'min_child_samples': 32}. Best is trial 13 with value: 0.02550329900720659.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 09:16:11,318]\u001b[0m Trial 16 finished with value: 0.025497529454035987 and parameters: {'learning_rate': 0.013000000000000001, 'depth': 14, 'l2_leaf_reg': 2.5, 'min_child_samples': 32}. Best is trial 16 with value: 0.025497529454035987.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 09:16:46,175]\u001b[0m Trial 17 finished with value: 0.025872142746798315 and parameters: {'learning_rate': 0.013000000000000001, 'depth': 14, 'l2_leaf_reg': 2.0, 'min_child_samples': 32}. Best is trial 16 with value: 0.025497529454035987.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 09:17:25,453]\u001b[0m Trial 18 finished with value: 0.02615775077672944 and parameters: {'learning_rate': 0.02, 'depth': 15, 'l2_leaf_reg': 4.0, 'min_child_samples': 32}. Best is trial 16 with value: 0.025497529454035987.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 09:17:58,972]\u001b[0m Trial 19 finished with value: 0.026583066313876483 and parameters: {'learning_rate': 0.017, 'depth': 12, 'l2_leaf_reg': 2.5, 'min_child_samples': 32}. Best is trial 16 with value: 0.025497529454035987.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 09:19:40,425]\u001b[0m Trial 20 finished with value: 0.029037788573981156 and parameters: {'learning_rate': 0.010000000000000002, 'depth': 14, 'l2_leaf_reg': 3.5, 'min_child_samples': 4}. Best is trial 16 with value: 0.025497529454035987.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 09:20:22,244]\u001b[0m Trial 21 finished with value: 0.025872142746798315 and parameters: {'learning_rate': 0.013000000000000001, 'depth': 14, 'l2_leaf_reg': 2.0, 'min_child_samples': 32}. Best is trial 16 with value: 0.025497529454035987.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 09:21:03,175]\u001b[0m Trial 22 finished with value: 0.02627741590191873 and parameters: {'learning_rate': 0.012, 'depth': 14, 'l2_leaf_reg': 2.5, 'min_child_samples': 32}. Best is trial 16 with value: 0.025497529454035987.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 09:21:47,300]\u001b[0m Trial 23 finished with value: 0.025363418771704435 and parameters: {'learning_rate': 0.015, 'depth': 15, 'l2_leaf_reg': 2.0, 'min_child_samples': 32}. Best is trial 23 with value: 0.025363418771704435.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 09:22:29,376]\u001b[0m Trial 24 finished with value: 0.027325749413668873 and parameters: {'learning_rate': 0.016, 'depth': 15, 'l2_leaf_reg': 1.5, 'min_child_samples': 32}. Best is trial 23 with value: 0.025363418771704435.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 09:29:07,771]\u001b[0m Trial 25 finished with value: 0.03178394109016273 and parameters: {'learning_rate': 0.009000000000000001, 'depth': 15, 'l2_leaf_reg': 2.5, 'min_child_samples': 1}. Best is trial 23 with value: 0.025363418771704435.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 09:29:43,158]\u001b[0m Trial 26 finished with value: 0.026818950033417967 and parameters: {'learning_rate': 0.018000000000000002, 'depth': 12, 'l2_leaf_reg': 3.5, 'min_child_samples': 32}. Best is trial 23 with value: 0.025363418771704435.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 09:30:24,663]\u001b[0m Trial 27 finished with value: 0.025363418771704435 and parameters: {'learning_rate': 0.015, 'depth': 15, 'l2_leaf_reg': 2.0, 'min_child_samples': 32}. Best is trial 23 with value: 0.025363418771704435.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 09:31:06,055]\u001b[0m Trial 28 finished with value: 0.027042910859895262 and parameters: {'learning_rate': 0.019000000000000003, 'depth': 15, 'l2_leaf_reg': 2.0, 'min_child_samples': 32}. Best is trial 23 with value: 0.025363418771704435.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 09:31:43,109]\u001b[0m Trial 29 finished with value: 0.027397261248303037 and parameters: {'learning_rate': 0.004, 'depth': 15, 'l2_leaf_reg': 1.5, 'min_child_samples': 32}. Best is trial 23 with value: 0.025363418771704435.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 09:38:55,946]\u001b[0m Trial 30 finished with value: 0.03354835811115365 and parameters: {'learning_rate': 0.016, 'depth': 15, 'l2_leaf_reg': 1.0, 'min_child_samples': 1}. Best is trial 23 with value: 0.025363418771704435.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 09:39:36,839]\u001b[0m Trial 31 finished with value: 0.02689209377529509 and parameters: {'learning_rate': 0.015, 'depth': 14, 'l2_leaf_reg': 2.5, 'min_child_samples': 32}. Best is trial 23 with value: 0.025363418771704435.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 09:40:38,470]\u001b[0m Trial 32 finished with value: 0.029226985276557274 and parameters: {'learning_rate': 0.013000000000000001, 'depth': 14, 'l2_leaf_reg': 2.0, 'min_child_samples': 8}. Best is trial 23 with value: 0.025363418771704435.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 09:41:15,437]\u001b[0m Trial 33 finished with value: 0.027287945216616608 and parameters: {'learning_rate': 0.015, 'depth': 13, 'l2_leaf_reg': 3.0, 'min_child_samples': 32}. Best is trial 23 with value: 0.025363418771704435.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 09:42:05,956]\u001b[0m Trial 34 finished with value: 0.02763087696221102 and parameters: {'learning_rate': 0.014000000000000002, 'depth': 15, 'l2_leaf_reg': 2.5, 'min_child_samples': 16}. Best is trial 23 with value: 0.025363418771704435.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 09:42:44,688]\u001b[0m Trial 35 finished with value: 0.026443383965895087 and parameters: {'learning_rate': 0.012, 'depth': 15, 'l2_leaf_reg': 1.5, 'min_child_samples': 32}. Best is trial 23 with value: 0.025363418771704435.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 09:43:46,407]\u001b[0m Trial 36 finished with value: 0.02865389678681158 and parameters: {'learning_rate': 0.010000000000000002, 'depth': 14, 'l2_leaf_reg': 2.0, 'min_child_samples': 8}. Best is trial 23 with value: 0.025363418771704435.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 09:45:10,778]\u001b[0m Trial 37 finished with value: 0.02909068543751234 and parameters: {'learning_rate': 0.012, 'depth': 13, 'l2_leaf_reg': 1.0, 'min_child_samples': 4}. Best is trial 23 with value: 0.025363418771704435.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 09:46:11,729]\u001b[0m Trial 38 finished with value: 0.02780302038095028 and parameters: {'learning_rate': 0.018000000000000002, 'depth': 15, 'l2_leaf_reg': 3.0, 'min_child_samples': 8}. Best is trial 23 with value: 0.025363418771704435.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 09:46:50,082]\u001b[0m Trial 39 finished with value: 0.02909424982744563 and parameters: {'learning_rate': 0.016, 'depth': 11, 'l2_leaf_reg': 1.5, 'min_child_samples': 16}. Best is trial 23 with value: 0.025363418771704435.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 09:47:27,801]\u001b[0m Trial 40 finished with value: 0.027741723475747646 and parameters: {'learning_rate': 0.011, 'depth': 14, 'l2_leaf_reg': 4.5, 'min_child_samples': 32}. Best is trial 23 with value: 0.025363418771704435.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 09:48:05,426]\u001b[0m Trial 41 finished with value: 0.025872142746798315 and parameters: {'learning_rate': 0.013000000000000001, 'depth': 14, 'l2_leaf_reg': 2.0, 'min_child_samples': 32}. Best is trial 23 with value: 0.025363418771704435.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 09:48:40,721]\u001b[0m Trial 42 finished with value: 0.027113659107858876 and parameters: {'learning_rate': 0.014000000000000002, 'depth': 13, 'l2_leaf_reg': 2.0, 'min_child_samples': 32}. Best is trial 23 with value: 0.025363418771704435.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 09:49:20,580]\u001b[0m Trial 43 finished with value: 0.026772303021648246 and parameters: {'learning_rate': 0.015, 'depth': 15, 'l2_leaf_reg': 2.5, 'min_child_samples': 32}. Best is trial 23 with value: 0.025363418771704435.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 09:54:54,296]\u001b[0m Trial 44 finished with value: 0.031643702065584485 and parameters: {'learning_rate': 0.013000000000000001, 'depth': 14, 'l2_leaf_reg': 1.5, 'min_child_samples': 1}. Best is trial 23 with value: 0.025363418771704435.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 09:55:36,620]\u001b[0m Trial 45 finished with value: 0.027369643000187134 and parameters: {'learning_rate': 0.012, 'depth': 12, 'l2_leaf_reg': 2.0, 'min_child_samples': 16}. Best is trial 23 with value: 0.025363418771704435.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 09:56:12,670]\u001b[0m Trial 46 finished with value: 0.027084959527894116 and parameters: {'learning_rate': 0.009000000000000001, 'depth': 13, 'l2_leaf_reg': 3.0, 'min_child_samples': 32}. Best is trial 23 with value: 0.025363418771704435.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 09:57:03,064]\u001b[0m Trial 47 finished with value: 0.02730426296769121 and parameters: {'learning_rate': 0.016, 'depth': 15, 'l2_leaf_reg': 5.5, 'min_child_samples': 16}. Best is trial 23 with value: 0.025363418771704435.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 09:57:30,102]\u001b[0m Trial 48 finished with value: 0.026673587632222582 and parameters: {'learning_rate': 0.014000000000000002, 'depth': 9, 'l2_leaf_reg': 2.5, 'min_child_samples': 32}. Best is trial 23 with value: 0.025363418771704435.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 09:58:57,162]\u001b[0m Trial 49 finished with value: 0.029605610812041532 and parameters: {'learning_rate': 0.018000000000000002, 'depth': 14, 'l2_leaf_reg': 3.5, 'min_child_samples': 4}. Best is trial 23 with value: 0.025363418771704435.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 09:59:34,289]\u001b[0m Trial 50 finished with value: 0.02597020186291109 and parameters: {'learning_rate': 0.011, 'depth': 14, 'l2_leaf_reg': 1.0, 'min_child_samples': 32}. Best is trial 23 with value: 0.025363418771704435.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 10:00:13,404]\u001b[0m Trial 51 finished with value: 0.025872142746798315 and parameters: {'learning_rate': 0.013000000000000001, 'depth': 14, 'l2_leaf_reg': 2.0, 'min_child_samples': 32}. Best is trial 23 with value: 0.025363418771704435.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 10:00:43,500]\u001b[0m Trial 52 finished with value: 0.026868975099429412 and parameters: {'learning_rate': 0.013000000000000001, 'depth': 10, 'l2_leaf_reg': 2.0, 'min_child_samples': 32}. Best is trial 23 with value: 0.025363418771704435.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 10:01:21,413]\u001b[0m Trial 53 finished with value: 0.02572447819867774 and parameters: {'learning_rate': 0.015, 'depth': 14, 'l2_leaf_reg': 1.5, 'min_child_samples': 32}. Best is trial 23 with value: 0.025363418771704435.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 10:01:56,979]\u001b[0m Trial 54 finished with value: 0.026293274284618886 and parameters: {'learning_rate': 0.015, 'depth': 13, 'l2_leaf_reg': 1.5, 'min_child_samples': 32}. Best is trial 23 with value: 0.025363418771704435.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 10:02:44,493]\u001b[0m Trial 55 finished with value: 0.0260725675125253 and parameters: {'learning_rate': 0.017, 'depth': 14, 'l2_leaf_reg': 2.5, 'min_child_samples': 16}. Best is trial 23 with value: 0.025363418771704435.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 10:03:24,393]\u001b[0m Trial 56 finished with value: 0.027325749413668873 and parameters: {'learning_rate': 0.016, 'depth': 15, 'l2_leaf_reg': 1.5, 'min_child_samples': 32}. Best is trial 23 with value: 0.025363418771704435.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 10:08:12,559]\u001b[0m Trial 57 finished with value: 0.030315539403471408 and parameters: {'learning_rate': 0.014000000000000002, 'depth': 13, 'l2_leaf_reg': 3.0, 'min_child_samples': 1}. Best is trial 23 with value: 0.025363418771704435.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 10:08:53,641]\u001b[0m Trial 58 finished with value: 0.025363418771704435 and parameters: {'learning_rate': 0.015, 'depth': 15, 'l2_leaf_reg': 2.0, 'min_child_samples': 32}. Best is trial 23 with value: 0.025363418771704435.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 10:09:58,010]\u001b[0m Trial 59 finished with value: 0.027201311380738207 and parameters: {'learning_rate': 0.017, 'depth': 15, 'l2_leaf_reg': 1.0, 'min_child_samples': 8}. Best is trial 23 with value: 0.025363418771704435.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 10:10:38,869]\u001b[0m Trial 60 finished with value: 0.026772303021648246 and parameters: {'learning_rate': 0.015, 'depth': 15, 'l2_leaf_reg': 2.5, 'min_child_samples': 32}. Best is trial 23 with value: 0.025363418771704435.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 10:11:20,549]\u001b[0m Trial 61 finished with value: 0.025363418771704435 and parameters: {'learning_rate': 0.015, 'depth': 15, 'l2_leaf_reg': 2.0, 'min_child_samples': 32}. Best is trial 23 with value: 0.025363418771704435.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 10:12:00,539]\u001b[0m Trial 62 finished with value: 0.025363418771704435 and parameters: {'learning_rate': 0.015, 'depth': 15, 'l2_leaf_reg': 2.0, 'min_child_samples': 32}. Best is trial 23 with value: 0.025363418771704435.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 10:12:44,594]\u001b[0m Trial 63 finished with value: 0.026486494170384824 and parameters: {'learning_rate': 0.017, 'depth': 15, 'l2_leaf_reg': 2.5, 'min_child_samples': 32}. Best is trial 23 with value: 0.025363418771704435.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 10:13:26,687]\u001b[0m Trial 64 finished with value: 0.02668572554281462 and parameters: {'learning_rate': 0.014000000000000002, 'depth': 15, 'l2_leaf_reg': 2.0, 'min_child_samples': 32}. Best is trial 23 with value: 0.025363418771704435.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 10:15:00,345]\u001b[0m Trial 65 finished with value: 0.029635024232240455 and parameters: {'learning_rate': 0.016, 'depth': 15, 'l2_leaf_reg': 2.0, 'min_child_samples': 4}. Best is trial 23 with value: 0.025363418771704435.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 10:15:53,665]\u001b[0m Trial 66 finished with value: 0.028581823718356957 and parameters: {'learning_rate': 0.019000000000000003, 'depth': 15, 'l2_leaf_reg': 2.5, 'min_child_samples': 16}. Best is trial 23 with value: 0.025363418771704435.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 10:16:32,162]\u001b[0m Trial 67 finished with value: 0.02685203928895958 and parameters: {'learning_rate': 0.006, 'depth': 15, 'l2_leaf_reg': 2.5, 'min_child_samples': 32}. Best is trial 23 with value: 0.025363418771704435.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 10:17:06,869]\u001b[0m Trial 68 finished with value: 0.032313872213175804 and parameters: {'learning_rate': 0.002, 'depth': 15, 'l2_leaf_reg': 3.0, 'min_child_samples': 32}. Best is trial 23 with value: 0.025363418771704435.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 10:17:37,163]\u001b[0m Trial 69 finished with value: 0.027182452868046117 and parameters: {'learning_rate': 0.012, 'depth': 15, 'l2_leaf_reg': 2.0, 'min_child_samples': 32}. Best is trial 23 with value: 0.025363418771704435.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 10:18:08,660]\u001b[0m Trial 70 finished with value: 0.027118357453025294 and parameters: {'learning_rate': 0.016, 'depth': 15, 'l2_leaf_reg': 3.5, 'min_child_samples': 32}. Best is trial 23 with value: 0.025363418771704435.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 10:18:36,540]\u001b[0m Trial 71 finished with value: 0.02572447819867774 and parameters: {'learning_rate': 0.015, 'depth': 14, 'l2_leaf_reg': 1.5, 'min_child_samples': 32}. Best is trial 23 with value: 0.025363418771704435.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 10:19:04,556]\u001b[0m Trial 72 finished with value: 0.02572447819867774 and parameters: {'learning_rate': 0.015, 'depth': 14, 'l2_leaf_reg': 1.5, 'min_child_samples': 32}. Best is trial 23 with value: 0.025363418771704435.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 10:19:34,568]\u001b[0m Trial 73 finished with value: 0.02668572554281462 and parameters: {'learning_rate': 0.014000000000000002, 'depth': 15, 'l2_leaf_reg': 2.0, 'min_child_samples': 32}. Best is trial 23 with value: 0.025363418771704435.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 10:20:02,420]\u001b[0m Trial 74 finished with value: 0.02572447819867774 and parameters: {'learning_rate': 0.015, 'depth': 14, 'l2_leaf_reg': 1.5, 'min_child_samples': 32}. Best is trial 23 with value: 0.025363418771704435.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 10:20:40,577]\u001b[0m Trial 75 finished with value: 0.026446934452026425 and parameters: {'learning_rate': 0.014000000000000002, 'depth': 15, 'l2_leaf_reg': 2.0, 'min_child_samples': 16}. Best is trial 23 with value: 0.025363418771704435.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 10:25:17,939]\u001b[0m Trial 76 finished with value: 0.03201943851118298 and parameters: {'learning_rate': 0.016, 'depth': 14, 'l2_leaf_reg': 2.0, 'min_child_samples': 1}. Best is trial 23 with value: 0.025363418771704435.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 10:25:53,081]\u001b[0m Trial 77 finished with value: 0.02780564548108459 and parameters: {'learning_rate': 0.018000000000000002, 'depth': 15, 'l2_leaf_reg': 1.5, 'min_child_samples': 32}. Best is trial 23 with value: 0.025363418771704435.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 10:26:39,710]\u001b[0m Trial 78 finished with value: 0.028244653712581443 and parameters: {'learning_rate': 0.017, 'depth': 14, 'l2_leaf_reg': 2.5, 'min_child_samples': 8}. Best is trial 23 with value: 0.025363418771704435.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 10:27:11,569]\u001b[0m Trial 79 finished with value: 0.02651368824391269 and parameters: {'learning_rate': 0.013000000000000001, 'depth': 15, 'l2_leaf_reg': 2.0, 'min_child_samples': 32}. Best is trial 23 with value: 0.025363418771704435.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 10:28:10,260]\u001b[0m Trial 80 finished with value: 0.02881190941573431 and parameters: {'learning_rate': 0.012, 'depth': 11, 'l2_leaf_reg': 2.5, 'min_child_samples': 4}. Best is trial 23 with value: 0.025363418771704435.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 10:28:39,288]\u001b[0m Trial 81 finished with value: 0.02572447819867774 and parameters: {'learning_rate': 0.015, 'depth': 14, 'l2_leaf_reg': 1.5, 'min_child_samples': 32}. Best is trial 23 with value: 0.025363418771704435.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 10:29:08,607]\u001b[0m Trial 82 finished with value: 0.02572447819867774 and parameters: {'learning_rate': 0.015, 'depth': 14, 'l2_leaf_reg': 1.5, 'min_child_samples': 32}. Best is trial 23 with value: 0.025363418771704435.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 10:29:37,842]\u001b[0m Trial 83 finished with value: 0.026974784220272198 and parameters: {'learning_rate': 0.014000000000000002, 'depth': 14, 'l2_leaf_reg': 1.0, 'min_child_samples': 32}. Best is trial 23 with value: 0.025363418771704435.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 10:30:09,014]\u001b[0m Trial 84 finished with value: 0.027325749413668873 and parameters: {'learning_rate': 0.016, 'depth': 15, 'l2_leaf_reg': 1.5, 'min_child_samples': 32}. Best is trial 23 with value: 0.025363418771704435.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 10:30:37,381]\u001b[0m Trial 85 finished with value: 0.025952629953151597 and parameters: {'learning_rate': 0.015, 'depth': 13, 'l2_leaf_reg': 2.0, 'min_child_samples': 32}. Best is trial 23 with value: 0.025363418771704435.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 10:31:11,085]\u001b[0m Trial 86 finished with value: 0.027587553117244798 and parameters: {'learning_rate': 0.013000000000000001, 'depth': 14, 'l2_leaf_reg': 1.5, 'min_child_samples': 32}. Best is trial 23 with value: 0.025363418771704435.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 10:31:53,665]\u001b[0m Trial 87 finished with value: 0.026446934452026425 and parameters: {'learning_rate': 0.014000000000000002, 'depth': 15, 'l2_leaf_reg': 2.0, 'min_child_samples': 16}. Best is trial 23 with value: 0.025363418771704435.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 10:32:23,033]\u001b[0m Trial 88 finished with value: 0.025756890555638453 and parameters: {'learning_rate': 0.015, 'depth': 15, 'l2_leaf_reg': 1.0, 'min_child_samples': 32}. Best is trial 23 with value: 0.025363418771704435.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 10:32:52,826]\u001b[0m Trial 89 finished with value: 0.027385514764929002 and parameters: {'learning_rate': 0.016, 'depth': 14, 'l2_leaf_reg': 2.0, 'min_child_samples': 32}. Best is trial 23 with value: 0.025363418771704435.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 10:33:21,302]\u001b[0m Trial 90 finished with value: 0.027133982680991823 and parameters: {'learning_rate': 0.014000000000000002, 'depth': 13, 'l2_leaf_reg': 3.0, 'min_child_samples': 32}. Best is trial 23 with value: 0.025363418771704435.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 10:33:49,534]\u001b[0m Trial 91 finished with value: 0.02572447819867774 and parameters: {'learning_rate': 0.015, 'depth': 14, 'l2_leaf_reg': 1.5, 'min_child_samples': 32}. Best is trial 23 with value: 0.025363418771704435.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 10:34:18,670]\u001b[0m Trial 92 finished with value: 0.02572447819867774 and parameters: {'learning_rate': 0.015, 'depth': 14, 'l2_leaf_reg': 1.5, 'min_child_samples': 32}. Best is trial 23 with value: 0.025363418771704435.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 10:34:46,980]\u001b[0m Trial 93 finished with value: 0.02596323366361286 and parameters: {'learning_rate': 0.016, 'depth': 14, 'l2_leaf_reg': 1.5, 'min_child_samples': 32}. Best is trial 23 with value: 0.025363418771704435.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 10:35:18,004]\u001b[0m Trial 94 finished with value: 0.027075636930130646 and parameters: {'learning_rate': 0.017, 'depth': 15, 'l2_leaf_reg': 2.0, 'min_child_samples': 32}. Best is trial 23 with value: 0.025363418771704435.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 10:35:48,272]\u001b[0m Trial 95 finished with value: 0.027373858378262877 and parameters: {'learning_rate': 0.015, 'depth': 14, 'l2_leaf_reg': 1.0, 'min_child_samples': 32}. Best is trial 23 with value: 0.025363418771704435.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 10:40:15,004]\u001b[0m Trial 96 finished with value: 0.032020497318533375 and parameters: {'learning_rate': 0.013000000000000001, 'depth': 13, 'l2_leaf_reg': 5.0, 'min_child_samples': 1}. Best is trial 23 with value: 0.025363418771704435.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 10:41:02,582]\u001b[0m Trial 97 finished with value: 0.028034072822532893 and parameters: {'learning_rate': 0.014000000000000002, 'depth': 14, 'l2_leaf_reg': 1.5, 'min_child_samples': 16}. Best is trial 23 with value: 0.025363418771704435.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 10:41:56,385]\u001b[0m Trial 98 finished with value: 0.028013564692100666 and parameters: {'learning_rate': 0.016, 'depth': 12, 'l2_leaf_reg': 2.0, 'min_child_samples': 8}. Best is trial 23 with value: 0.025363418771704435.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 10:42:42,202]\u001b[0m Trial 99 finished with value: 0.026486494170384824 and parameters: {'learning_rate': 0.017, 'depth': 15, 'l2_leaf_reg': 2.5, 'min_child_samples': 32}. Best is trial 23 with value: 0.025363418771704435.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 10:43:26,245]\u001b[0m Trial 100 finished with value: 0.02742283464440672 and parameters: {'learning_rate': 0.014000000000000002, 'depth': 15, 'l2_leaf_reg': 1.5, 'min_child_samples': 32}. Best is trial 23 with value: 0.025363418771704435.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 10:44:09,628]\u001b[0m Trial 101 finished with value: 0.02572447819867774 and parameters: {'learning_rate': 0.015, 'depth': 14, 'l2_leaf_reg': 1.5, 'min_child_samples': 32}. Best is trial 23 with value: 0.025363418771704435.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 10:44:51,198]\u001b[0m Trial 102 finished with value: 0.02572447819867774 and parameters: {'learning_rate': 0.015, 'depth': 14, 'l2_leaf_reg': 1.5, 'min_child_samples': 32}. Best is trial 23 with value: 0.025363418771704435.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 10:45:32,994]\u001b[0m Trial 103 finished with value: 0.027801838776841455 and parameters: {'learning_rate': 0.016, 'depth': 14, 'l2_leaf_reg': 1.0, 'min_child_samples': 32}. Best is trial 23 with value: 0.025363418771704435.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 10:46:17,893]\u001b[0m Trial 104 finished with value: 0.027586360780910424 and parameters: {'learning_rate': 0.015, 'depth': 15, 'l2_leaf_reg': 1.5, 'min_child_samples': 32}. Best is trial 23 with value: 0.025363418771704435.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 10:47:04,597]\u001b[0m Trial 105 finished with value: 0.025872142746798315 and parameters: {'learning_rate': 0.013000000000000001, 'depth': 14, 'l2_leaf_reg': 2.0, 'min_child_samples': 32}. Best is trial 23 with value: 0.025363418771704435.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 10:48:36,564]\u001b[0m Trial 106 finished with value: 0.02824119704819915 and parameters: {'learning_rate': 0.014000000000000002, 'depth': 13, 'l2_leaf_reg': 2.5, 'min_child_samples': 4}. Best is trial 23 with value: 0.025363418771704435.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 10:49:25,120]\u001b[0m Trial 107 finished with value: 0.025363418771704435 and parameters: {'learning_rate': 0.015, 'depth': 15, 'l2_leaf_reg': 2.0, 'min_child_samples': 32}. Best is trial 23 with value: 0.025363418771704435.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 10:50:27,744]\u001b[0m Trial 108 finished with value: 0.02662913310875324 and parameters: {'learning_rate': 0.016, 'depth': 15, 'l2_leaf_reg': 2.0, 'min_child_samples': 16}. Best is trial 23 with value: 0.025363418771704435.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 10:51:19,435]\u001b[0m Trial 109 finished with value: 0.02668572554281462 and parameters: {'learning_rate': 0.014000000000000002, 'depth': 15, 'l2_leaf_reg': 2.0, 'min_child_samples': 32}. Best is trial 23 with value: 0.025363418771704435.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 10:52:07,928]\u001b[0m Trial 110 finished with value: 0.027089623973078625 and parameters: {'learning_rate': 0.017, 'depth': 15, 'l2_leaf_reg': 3.0, 'min_child_samples': 32}. Best is trial 23 with value: 0.025363418771704435.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 10:52:50,393]\u001b[0m Trial 111 finished with value: 0.02572447819867774 and parameters: {'learning_rate': 0.015, 'depth': 14, 'l2_leaf_reg': 1.5, 'min_child_samples': 32}. Best is trial 23 with value: 0.025363418771704435.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 10:53:37,756]\u001b[0m Trial 112 finished with value: 0.025363418771704435 and parameters: {'learning_rate': 0.015, 'depth': 15, 'l2_leaf_reg': 2.0, 'min_child_samples': 32}. Best is trial 23 with value: 0.025363418771704435.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 10:54:24,649]\u001b[0m Trial 113 finished with value: 0.026177872099894372 and parameters: {'learning_rate': 0.016, 'depth': 15, 'l2_leaf_reg': 2.0, 'min_child_samples': 32}. Best is trial 23 with value: 0.025363418771704435.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 10:55:11,325]\u001b[0m Trial 114 finished with value: 0.026772303021648246 and parameters: {'learning_rate': 0.015, 'depth': 15, 'l2_leaf_reg': 2.5, 'min_child_samples': 32}. Best is trial 23 with value: 0.025363418771704435.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 10:55:58,212]\u001b[0m Trial 115 finished with value: 0.02668572554281462 and parameters: {'learning_rate': 0.014000000000000002, 'depth': 15, 'l2_leaf_reg': 2.0, 'min_child_samples': 32}. Best is trial 23 with value: 0.025363418771704435.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 10:56:49,725]\u001b[0m Trial 116 finished with value: 0.027264369704185096 and parameters: {'learning_rate': 0.016, 'depth': 15, 'l2_leaf_reg': 2.5, 'min_child_samples': 32}. Best is trial 23 with value: 0.025363418771704435.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 10:57:40,837]\u001b[0m Trial 117 finished with value: 0.027673020553586048 and parameters: {'learning_rate': 0.015, 'depth': 15, 'l2_leaf_reg': 4.0, 'min_child_samples': 32}. Best is trial 23 with value: 0.025363418771704435.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 11:04:44,144]\u001b[0m Trial 118 finished with value: 0.032316138639038816 and parameters: {'learning_rate': 0.012, 'depth': 15, 'l2_leaf_reg': 2.0, 'min_child_samples': 1}. Best is trial 23 with value: 0.025363418771704435.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 11:05:32,883]\u001b[0m Trial 119 finished with value: 0.02651368824391269 and parameters: {'learning_rate': 0.013000000000000001, 'depth': 15, 'l2_leaf_reg': 2.0, 'min_child_samples': 32}. Best is trial 23 with value: 0.025363418771704435.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 11:06:33,641]\u001b[0m Trial 120 finished with value: 0.02763087696221102 and parameters: {'learning_rate': 0.014000000000000002, 'depth': 15, 'l2_leaf_reg': 2.5, 'min_child_samples': 16}. Best is trial 23 with value: 0.025363418771704435.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 11:07:18,758]\u001b[0m Trial 121 finished with value: 0.02572447819867774 and parameters: {'learning_rate': 0.015, 'depth': 14, 'l2_leaf_reg': 1.5, 'min_child_samples': 32}. Best is trial 23 with value: 0.025363418771704435.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 11:08:03,078]\u001b[0m Trial 122 finished with value: 0.025992727138016074 and parameters: {'learning_rate': 0.015, 'depth': 14, 'l2_leaf_reg': 2.0, 'min_child_samples': 32}. Best is trial 23 with value: 0.025363418771704435.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 11:08:44,279]\u001b[0m Trial 123 finished with value: 0.02596323366361286 and parameters: {'learning_rate': 0.016, 'depth': 14, 'l2_leaf_reg': 1.5, 'min_child_samples': 32}. Best is trial 23 with value: 0.025363418771704435.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 11:09:30,419]\u001b[0m Trial 124 finished with value: 0.02668572554281462 and parameters: {'learning_rate': 0.014000000000000002, 'depth': 15, 'l2_leaf_reg': 2.0, 'min_child_samples': 32}. Best is trial 23 with value: 0.025363418771704435.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 11:10:33,896]\u001b[0m Trial 125 finished with value: 0.02816545827353426 and parameters: {'learning_rate': 0.016, 'depth': 14, 'l2_leaf_reg': 2.0, 'min_child_samples': 8}. Best is trial 23 with value: 0.025363418771704435.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 11:11:19,133]\u001b[0m Trial 126 finished with value: 0.027586360780910424 and parameters: {'learning_rate': 0.015, 'depth': 15, 'l2_leaf_reg': 1.5, 'min_child_samples': 32}. Best is trial 23 with value: 0.025363418771704435.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 11:12:02,472]\u001b[0m Trial 127 finished with value: 0.0275766815084794 and parameters: {'learning_rate': 0.014000000000000002, 'depth': 14, 'l2_leaf_reg': 2.0, 'min_child_samples': 32}. Best is trial 23 with value: 0.025363418771704435.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 11:12:47,671]\u001b[0m Trial 128 finished with value: 0.0272942564557518 and parameters: {'learning_rate': 0.013000000000000001, 'depth': 15, 'l2_leaf_reg': 1.5, 'min_child_samples': 32}. Best is trial 23 with value: 0.025363418771704435.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 11:13:29,831]\u001b[0m Trial 129 finished with value: 0.027373858378262877 and parameters: {'learning_rate': 0.015, 'depth': 14, 'l2_leaf_reg': 1.0, 'min_child_samples': 32}. Best is trial 23 with value: 0.025363418771704435.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 11:14:36,203]\u001b[0m Trial 130 finished with value: 0.028913511077484102 and parameters: {'learning_rate': 0.015, 'depth': 10, 'l2_leaf_reg': 2.5, 'min_child_samples': 4}. Best is trial 23 with value: 0.025363418771704435.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 11:15:18,678]\u001b[0m Trial 131 finished with value: 0.02572447819867774 and parameters: {'learning_rate': 0.015, 'depth': 14, 'l2_leaf_reg': 1.5, 'min_child_samples': 32}. Best is trial 23 with value: 0.025363418771704435.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 11:16:01,957]\u001b[0m Trial 132 finished with value: 0.02596323366361286 and parameters: {'learning_rate': 0.016, 'depth': 14, 'l2_leaf_reg': 1.5, 'min_child_samples': 32}. Best is trial 23 with value: 0.025363418771704435.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 11:16:44,790]\u001b[0m Trial 133 finished with value: 0.0275766815084794 and parameters: {'learning_rate': 0.014000000000000002, 'depth': 14, 'l2_leaf_reg': 2.0, 'min_child_samples': 32}. Best is trial 23 with value: 0.025363418771704435.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 11:17:27,311]\u001b[0m Trial 134 finished with value: 0.02572447819867774 and parameters: {'learning_rate': 0.015, 'depth': 14, 'l2_leaf_reg': 1.5, 'min_child_samples': 32}. Best is trial 23 with value: 0.025363418771704435.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 11:18:13,639]\u001b[0m Trial 135 finished with value: 0.02709144381837473 and parameters: {'learning_rate': 0.017, 'depth': 15, 'l2_leaf_reg': 1.5, 'min_child_samples': 32}. Best is trial 23 with value: 0.025363418771704435.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 11:18:51,923]\u001b[0m Trial 136 finished with value: 0.025796617516673663 and parameters: {'learning_rate': 0.014000000000000002, 'depth': 12, 'l2_leaf_reg': 1.0, 'min_child_samples': 32}. Best is trial 23 with value: 0.025363418771704435.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 11:19:35,009]\u001b[0m Trial 137 finished with value: 0.02596323366361286 and parameters: {'learning_rate': 0.016, 'depth': 14, 'l2_leaf_reg': 1.5, 'min_child_samples': 32}. Best is trial 23 with value: 0.025363418771704435.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 11:20:26,403]\u001b[0m Trial 138 finished with value: 0.02802592735790256 and parameters: {'learning_rate': 0.015, 'depth': 13, 'l2_leaf_reg': 2.0, 'min_child_samples': 16}. Best is trial 23 with value: 0.025363418771704435.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 11:21:15,991]\u001b[0m Trial 139 finished with value: 0.027586360780910424 and parameters: {'learning_rate': 0.015, 'depth': 15, 'l2_leaf_reg': 1.5, 'min_child_samples': 32}. Best is trial 23 with value: 0.025363418771704435.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 11:22:01,355]\u001b[0m Trial 140 finished with value: 0.02668572554281462 and parameters: {'learning_rate': 0.014000000000000002, 'depth': 15, 'l2_leaf_reg': 2.0, 'min_child_samples': 32}. Best is trial 23 with value: 0.025363418771704435.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 11:22:43,051]\u001b[0m Trial 141 finished with value: 0.02572447819867774 and parameters: {'learning_rate': 0.015, 'depth': 14, 'l2_leaf_reg': 1.5, 'min_child_samples': 32}. Best is trial 23 with value: 0.025363418771704435.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 11:23:22,694]\u001b[0m Trial 142 finished with value: 0.02572447819867774 and parameters: {'learning_rate': 0.015, 'depth': 14, 'l2_leaf_reg': 1.5, 'min_child_samples': 32}. Best is trial 23 with value: 0.025363418771704435.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 11:24:02,080]\u001b[0m Trial 143 finished with value: 0.027385514764929002 and parameters: {'learning_rate': 0.016, 'depth': 14, 'l2_leaf_reg': 2.0, 'min_child_samples': 32}. Best is trial 23 with value: 0.025363418771704435.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 11:24:46,615]\u001b[0m Trial 144 finished with value: 0.02572447819867774 and parameters: {'learning_rate': 0.015, 'depth': 14, 'l2_leaf_reg': 1.5, 'min_child_samples': 32}. Best is trial 23 with value: 0.025363418771704435.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 11:25:35,746]\u001b[0m Trial 145 finished with value: 0.02668572554281462 and parameters: {'learning_rate': 0.014000000000000002, 'depth': 15, 'l2_leaf_reg': 2.0, 'min_child_samples': 32}. Best is trial 23 with value: 0.025363418771704435.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 11:26:17,149]\u001b[0m Trial 146 finished with value: 0.02572447819867774 and parameters: {'learning_rate': 0.015, 'depth': 14, 'l2_leaf_reg': 1.5, 'min_child_samples': 32}. Best is trial 23 with value: 0.025363418771704435.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 11:27:01,037]\u001b[0m Trial 147 finished with value: 0.025921601612736146 and parameters: {'learning_rate': 0.009000000000000001, 'depth': 14, 'l2_leaf_reg': 1.5, 'min_child_samples': 32}. Best is trial 23 with value: 0.025363418771704435.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 11:32:54,586]\u001b[0m Trial 148 finished with value: 0.031643702065584485 and parameters: {'learning_rate': 0.013000000000000001, 'depth': 14, 'l2_leaf_reg': 1.5, 'min_child_samples': 1}. Best is trial 23 with value: 0.025363418771704435.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 11:33:42,178]\u001b[0m Trial 149 finished with value: 0.026177872099894372 and parameters: {'learning_rate': 0.016, 'depth': 15, 'l2_leaf_reg': 2.0, 'min_child_samples': 32}. Best is trial 23 with value: 0.025363418771704435.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 11:34:43,514]\u001b[0m Trial 150 finished with value: 0.027943088453794913 and parameters: {'learning_rate': 0.014000000000000002, 'depth': 13, 'l2_leaf_reg': 3.5, 'min_child_samples': 8}. Best is trial 23 with value: 0.025363418771704435.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 11:35:24,684]\u001b[0m Trial 151 finished with value: 0.027373858378262877 and parameters: {'learning_rate': 0.015, 'depth': 14, 'l2_leaf_reg': 1.0, 'min_child_samples': 32}. Best is trial 23 with value: 0.025363418771704435.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 11:36:07,595]\u001b[0m Trial 152 finished with value: 0.02572447819867774 and parameters: {'learning_rate': 0.015, 'depth': 14, 'l2_leaf_reg': 1.5, 'min_child_samples': 32}. Best is trial 23 with value: 0.025363418771704435.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 11:36:38,894]\u001b[0m Trial 153 finished with value: 0.02572447819867774 and parameters: {'learning_rate': 0.015, 'depth': 14, 'l2_leaf_reg': 1.5, 'min_child_samples': 32}. Best is trial 23 with value: 0.025363418771704435.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 11:37:09,650]\u001b[0m Trial 154 finished with value: 0.02788815217153443 and parameters: {'learning_rate': 0.004, 'depth': 14, 'l2_leaf_reg': 1.5, 'min_child_samples': 32}. Best is trial 23 with value: 0.025363418771704435.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 11:37:40,435]\u001b[0m Trial 155 finished with value: 0.027385514764929002 and parameters: {'learning_rate': 0.016, 'depth': 14, 'l2_leaf_reg': 2.0, 'min_child_samples': 32}. Best is trial 23 with value: 0.025363418771704435.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 11:38:22,467]\u001b[0m Trial 156 finished with value: 0.028554340097928125 and parameters: {'learning_rate': 0.014000000000000002, 'depth': 15, 'l2_leaf_reg': 1.5, 'min_child_samples': 16}. Best is trial 23 with value: 0.025363418771704435.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 11:38:54,034]\u001b[0m Trial 157 finished with value: 0.027845653732253676 and parameters: {'learning_rate': 0.015, 'depth': 14, 'l2_leaf_reg': 3.0, 'min_child_samples': 32}. Best is trial 23 with value: 0.025363418771704435.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 11:39:29,602]\u001b[0m Trial 158 finished with value: 0.025363418771704435 and parameters: {'learning_rate': 0.015, 'depth': 15, 'l2_leaf_reg': 2.0, 'min_child_samples': 32}. Best is trial 23 with value: 0.025363418771704435.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 11:40:03,505]\u001b[0m Trial 159 finished with value: 0.02668572554281462 and parameters: {'learning_rate': 0.014000000000000002, 'depth': 15, 'l2_leaf_reg': 2.0, 'min_child_samples': 32}. Best is trial 23 with value: 0.025363418771704435.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 11:41:32,750]\u001b[0m Trial 160 finished with value: 0.029635024232240455 and parameters: {'learning_rate': 0.016, 'depth': 15, 'l2_leaf_reg': 2.0, 'min_child_samples': 4}. Best is trial 23 with value: 0.025363418771704435.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 11:42:07,358]\u001b[0m Trial 161 finished with value: 0.025363418771704435 and parameters: {'learning_rate': 0.015, 'depth': 15, 'l2_leaf_reg': 2.0, 'min_child_samples': 32}. Best is trial 23 with value: 0.025363418771704435.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 11:42:38,515]\u001b[0m Trial 162 finished with value: 0.025363418771704435 and parameters: {'learning_rate': 0.015, 'depth': 15, 'l2_leaf_reg': 2.0, 'min_child_samples': 32}. Best is trial 23 with value: 0.025363418771704435.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 11:43:09,403]\u001b[0m Trial 163 finished with value: 0.026177872099894372 and parameters: {'learning_rate': 0.016, 'depth': 15, 'l2_leaf_reg': 2.0, 'min_child_samples': 32}. Best is trial 23 with value: 0.025363418771704435.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 11:43:40,708]\u001b[0m Trial 164 finished with value: 0.026772303021648246 and parameters: {'learning_rate': 0.015, 'depth': 15, 'l2_leaf_reg': 2.5, 'min_child_samples': 32}. Best is trial 23 with value: 0.025363418771704435.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 11:44:10,666]\u001b[0m Trial 165 finished with value: 0.02668572554281462 and parameters: {'learning_rate': 0.014000000000000002, 'depth': 15, 'l2_leaf_reg': 2.0, 'min_child_samples': 32}. Best is trial 23 with value: 0.025363418771704435.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 11:44:42,461]\u001b[0m Trial 166 finished with value: 0.025363418771704435 and parameters: {'learning_rate': 0.015, 'depth': 15, 'l2_leaf_reg': 2.0, 'min_child_samples': 32}. Best is trial 23 with value: 0.025363418771704435.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 11:45:13,215]\u001b[0m Trial 167 finished with value: 0.025363418771704435 and parameters: {'learning_rate': 0.015, 'depth': 15, 'l2_leaf_reg': 2.0, 'min_child_samples': 32}. Best is trial 23 with value: 0.025363418771704435.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 11:45:44,506]\u001b[0m Trial 168 finished with value: 0.026177872099894372 and parameters: {'learning_rate': 0.016, 'depth': 15, 'l2_leaf_reg': 2.0, 'min_child_samples': 32}. Best is trial 23 with value: 0.025363418771704435.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 11:46:15,417]\u001b[0m Trial 169 finished with value: 0.02668572554281462 and parameters: {'learning_rate': 0.014000000000000002, 'depth': 15, 'l2_leaf_reg': 2.0, 'min_child_samples': 32}. Best is trial 23 with value: 0.025363418771704435.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 11:46:53,584]\u001b[0m Trial 170 finished with value: 0.02745749696810118 and parameters: {'learning_rate': 0.017, 'depth': 15, 'l2_leaf_reg': 2.5, 'min_child_samples': 16}. Best is trial 23 with value: 0.025363418771704435.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 11:47:25,234]\u001b[0m Trial 171 finished with value: 0.025363418771704435 and parameters: {'learning_rate': 0.015, 'depth': 15, 'l2_leaf_reg': 2.0, 'min_child_samples': 32}. Best is trial 23 with value: 0.025363418771704435.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 11:47:56,164]\u001b[0m Trial 172 finished with value: 0.025363418771704435 and parameters: {'learning_rate': 0.015, 'depth': 15, 'l2_leaf_reg': 2.0, 'min_child_samples': 32}. Best is trial 23 with value: 0.025363418771704435.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 11:48:28,165]\u001b[0m Trial 173 finished with value: 0.025363418771704435 and parameters: {'learning_rate': 0.015, 'depth': 15, 'l2_leaf_reg': 2.0, 'min_child_samples': 32}. Best is trial 23 with value: 0.025363418771704435.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 11:48:59,668]\u001b[0m Trial 174 finished with value: 0.025363418771704435 and parameters: {'learning_rate': 0.015, 'depth': 15, 'l2_leaf_reg': 2.0, 'min_child_samples': 32}. Best is trial 23 with value: 0.025363418771704435.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 11:49:30,719]\u001b[0m Trial 175 finished with value: 0.026177872099894372 and parameters: {'learning_rate': 0.016, 'depth': 15, 'l2_leaf_reg': 2.0, 'min_child_samples': 32}. Best is trial 23 with value: 0.025363418771704435.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 11:50:00,228]\u001b[0m Trial 176 finished with value: 0.02668572554281462 and parameters: {'learning_rate': 0.014000000000000002, 'depth': 15, 'l2_leaf_reg': 2.0, 'min_child_samples': 32}. Best is trial 23 with value: 0.025363418771704435.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 11:50:31,352]\u001b[0m Trial 177 finished with value: 0.025363418771704435 and parameters: {'learning_rate': 0.015, 'depth': 15, 'l2_leaf_reg': 2.0, 'min_child_samples': 32}. Best is trial 23 with value: 0.025363418771704435.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 11:51:02,153]\u001b[0m Trial 178 finished with value: 0.025363418771704435 and parameters: {'learning_rate': 0.015, 'depth': 15, 'l2_leaf_reg': 2.0, 'min_child_samples': 32}. Best is trial 23 with value: 0.025363418771704435.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 11:51:33,057]\u001b[0m Trial 179 finished with value: 0.026177872099894372 and parameters: {'learning_rate': 0.016, 'depth': 15, 'l2_leaf_reg': 2.0, 'min_child_samples': 32}. Best is trial 23 with value: 0.025363418771704435.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 11:52:03,329]\u001b[0m Trial 180 finished with value: 0.025363418771704435 and parameters: {'learning_rate': 0.015, 'depth': 15, 'l2_leaf_reg': 2.0, 'min_child_samples': 32}. Best is trial 23 with value: 0.025363418771704435.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 11:52:34,151]\u001b[0m Trial 181 finished with value: 0.025363418771704435 and parameters: {'learning_rate': 0.015, 'depth': 15, 'l2_leaf_reg': 2.0, 'min_child_samples': 32}. Best is trial 23 with value: 0.025363418771704435.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 11:53:04,210]\u001b[0m Trial 182 finished with value: 0.025363418771704435 and parameters: {'learning_rate': 0.015, 'depth': 15, 'l2_leaf_reg': 2.0, 'min_child_samples': 32}. Best is trial 23 with value: 0.025363418771704435.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 11:53:35,132]\u001b[0m Trial 183 finished with value: 0.025363418771704435 and parameters: {'learning_rate': 0.015, 'depth': 15, 'l2_leaf_reg': 2.0, 'min_child_samples': 32}. Best is trial 23 with value: 0.025363418771704435.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 11:54:05,841]\u001b[0m Trial 184 finished with value: 0.026177872099894372 and parameters: {'learning_rate': 0.016, 'depth': 15, 'l2_leaf_reg': 2.0, 'min_child_samples': 32}. Best is trial 23 with value: 0.025363418771704435.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 11:54:36,768]\u001b[0m Trial 185 finished with value: 0.025363418771704435 and parameters: {'learning_rate': 0.015, 'depth': 15, 'l2_leaf_reg': 2.0, 'min_child_samples': 32}. Best is trial 23 with value: 0.025363418771704435.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 11:55:06,789]\u001b[0m Trial 186 finished with value: 0.025363418771704435 and parameters: {'learning_rate': 0.015, 'depth': 15, 'l2_leaf_reg': 2.0, 'min_child_samples': 32}. Best is trial 23 with value: 0.025363418771704435.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 11:55:37,609]\u001b[0m Trial 187 finished with value: 0.026177872099894372 and parameters: {'learning_rate': 0.016, 'depth': 15, 'l2_leaf_reg': 2.0, 'min_child_samples': 32}. Best is trial 23 with value: 0.025363418771704435.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 11:56:07,269]\u001b[0m Trial 188 finished with value: 0.02668572554281462 and parameters: {'learning_rate': 0.014000000000000002, 'depth': 15, 'l2_leaf_reg': 2.0, 'min_child_samples': 32}. Best is trial 23 with value: 0.025363418771704435.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 11:56:38,351]\u001b[0m Trial 189 finished with value: 0.025363418771704435 and parameters: {'learning_rate': 0.015, 'depth': 15, 'l2_leaf_reg': 2.0, 'min_child_samples': 32}. Best is trial 23 with value: 0.025363418771704435.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 11:57:08,210]\u001b[0m Trial 190 finished with value: 0.025363418771704435 and parameters: {'learning_rate': 0.015, 'depth': 15, 'l2_leaf_reg': 2.0, 'min_child_samples': 32}. Best is trial 23 with value: 0.025363418771704435.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 11:57:39,043]\u001b[0m Trial 191 finished with value: 0.025363418771704435 and parameters: {'learning_rate': 0.015, 'depth': 15, 'l2_leaf_reg': 2.0, 'min_child_samples': 32}. Best is trial 23 with value: 0.025363418771704435.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 11:58:09,403]\u001b[0m Trial 192 finished with value: 0.025363418771704435 and parameters: {'learning_rate': 0.015, 'depth': 15, 'l2_leaf_reg': 2.0, 'min_child_samples': 32}. Best is trial 23 with value: 0.025363418771704435.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 11:58:40,208]\u001b[0m Trial 193 finished with value: 0.025363418771704435 and parameters: {'learning_rate': 0.015, 'depth': 15, 'l2_leaf_reg': 2.0, 'min_child_samples': 32}. Best is trial 23 with value: 0.025363418771704435.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 11:59:10,664]\u001b[0m Trial 194 finished with value: 0.025363418771704435 and parameters: {'learning_rate': 0.015, 'depth': 15, 'l2_leaf_reg': 2.0, 'min_child_samples': 32}. Best is trial 23 with value: 0.025363418771704435.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 11:59:41,667]\u001b[0m Trial 195 finished with value: 0.02668572554281462 and parameters: {'learning_rate': 0.014000000000000002, 'depth': 15, 'l2_leaf_reg': 2.0, 'min_child_samples': 32}. Best is trial 23 with value: 0.025363418771704435.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 12:00:11,898]\u001b[0m Trial 196 finished with value: 0.026177872099894372 and parameters: {'learning_rate': 0.016, 'depth': 15, 'l2_leaf_reg': 2.0, 'min_child_samples': 32}. Best is trial 23 with value: 0.025363418771704435.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 12:00:42,682]\u001b[0m Trial 197 finished with value: 0.025363418771704435 and parameters: {'learning_rate': 0.015, 'depth': 15, 'l2_leaf_reg': 2.0, 'min_child_samples': 32}. Best is trial 23 with value: 0.025363418771704435.\u001b[0m\n",
      "\u001b[32m[I 2023-01-10 12:01:14,565]\u001b[0m Trial 198 finished with value: 0.02668572554281462 and parameters: {'learning_rate': 0.014000000000000002, 'depth': 15, 'l2_leaf_reg': 2.0, 'min_child_samples': 32}. Best is trial 23 with value: 0.025363418771704435.\u001b[0m\n",
      "\u001b[33m[W 2023-01-10 12:03:21,180]\u001b[0m Trial 199 failed because of the following error: KeyboardInterrupt('')\u001b[0m\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\britt\\Desktop\\YH\\Applicerad AI\\job_discrimination\\venv_job_discrimination\\lib\\site-packages\\optuna\\study\\_optimize.py\", line 196, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"C:\\Users\\britt\\AppData\\Local\\Temp\\ipykernel_3000\\3088757681.py\", line 18, in objective\n",
      "    regressor.fit(X_train, y_train, early_stopping_rounds=100)\n",
      "  File \"c:\\Users\\britt\\Desktop\\YH\\Applicerad AI\\job_discrimination\\venv_job_discrimination\\lib\\site-packages\\catboost\\core.py\", line 5730, in fit\n",
      "    return self._fit(X, y, cat_features, text_features, embedding_features, None, sample_weight, None, None, None, None, baseline,\n",
      "  File \"c:\\Users\\britt\\Desktop\\YH\\Applicerad AI\\job_discrimination\\venv_job_discrimination\\lib\\site-packages\\catboost\\core.py\", line 2355, in _fit\n",
      "    self._train(\n",
      "  File \"c:\\Users\\britt\\Desktop\\YH\\Applicerad AI\\job_discrimination\\venv_job_discrimination\\lib\\site-packages\\catboost\\core.py\", line 1759, in _train\n",
      "    self._object._train(train_pool, test_pool, params, allow_clear_pool, init_model._object if init_model else None)\n",
      "  File \"_catboost.pyx\", line 4623, in _catboost._CatBoost._train\n",
      "  File \"_catboost.pyx\", line 4672, in _catboost._CatBoost._train\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m study \u001b[39m=\u001b[39m optuna\u001b[39m.\u001b[39mcreate_study(study_name\u001b[39m=\u001b[39m\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mcatboost-seed\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m study\u001b[39m.\u001b[39;49moptimize(objective, n_trials\u001b[39m=\u001b[39;49m\u001b[39m200\u001b[39;49m, timeout\u001b[39m=\u001b[39;49m\u001b[39m24000\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\britt\\Desktop\\YH\\Applicerad AI\\job_discrimination\\venv_job_discrimination\\lib\\site-packages\\optuna\\study\\study.py:419\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    315\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39moptimize\u001b[39m(\n\u001b[0;32m    316\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    317\u001b[0m     func: ObjectiveFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    324\u001b[0m     show_progress_bar: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    325\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    326\u001b[0m     \u001b[39m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[0;32m    327\u001b[0m \n\u001b[0;32m    328\u001b[0m \u001b[39m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    416\u001b[0m \u001b[39m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[0;32m    417\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 419\u001b[0m     _optimize(\n\u001b[0;32m    420\u001b[0m         study\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[0;32m    421\u001b[0m         func\u001b[39m=\u001b[39;49mfunc,\n\u001b[0;32m    422\u001b[0m         n_trials\u001b[39m=\u001b[39;49mn_trials,\n\u001b[0;32m    423\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[0;32m    424\u001b[0m         n_jobs\u001b[39m=\u001b[39;49mn_jobs,\n\u001b[0;32m    425\u001b[0m         catch\u001b[39m=\u001b[39;49mcatch,\n\u001b[0;32m    426\u001b[0m         callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[0;32m    427\u001b[0m         gc_after_trial\u001b[39m=\u001b[39;49mgc_after_trial,\n\u001b[0;32m    428\u001b[0m         show_progress_bar\u001b[39m=\u001b[39;49mshow_progress_bar,\n\u001b[0;32m    429\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\britt\\Desktop\\YH\\Applicerad AI\\job_discrimination\\venv_job_discrimination\\lib\\site-packages\\optuna\\study\\_optimize.py:66\u001b[0m, in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     65\u001b[0m     \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m---> 66\u001b[0m         _optimize_sequential(\n\u001b[0;32m     67\u001b[0m             study,\n\u001b[0;32m     68\u001b[0m             func,\n\u001b[0;32m     69\u001b[0m             n_trials,\n\u001b[0;32m     70\u001b[0m             timeout,\n\u001b[0;32m     71\u001b[0m             catch,\n\u001b[0;32m     72\u001b[0m             callbacks,\n\u001b[0;32m     73\u001b[0m             gc_after_trial,\n\u001b[0;32m     74\u001b[0m             reseed_sampler_rng\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m     75\u001b[0m             time_start\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m     76\u001b[0m             progress_bar\u001b[39m=\u001b[39;49mprogress_bar,\n\u001b[0;32m     77\u001b[0m         )\n\u001b[0;32m     78\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     79\u001b[0m         \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\britt\\Desktop\\YH\\Applicerad AI\\job_discrimination\\venv_job_discrimination\\lib\\site-packages\\optuna\\study\\_optimize.py:160\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    157\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m    159\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 160\u001b[0m     frozen_trial \u001b[39m=\u001b[39m _run_trial(study, func, catch)\n\u001b[0;32m    161\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    162\u001b[0m     \u001b[39m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[0;32m    163\u001b[0m     \u001b[39m# environments (e.g., services that use computing containers such as CircleCI).\u001b[39;00m\n\u001b[0;32m    164\u001b[0m     \u001b[39m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[0;32m    165\u001b[0m     \u001b[39m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[0;32m    166\u001b[0m     \u001b[39mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[1;32mc:\\Users\\britt\\Desktop\\YH\\Applicerad AI\\job_discrimination\\venv_job_discrimination\\lib\\site-packages\\optuna\\study\\_optimize.py:234\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    227\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mFalse\u001b[39;00m, \u001b[39m\"\u001b[39m\u001b[39mShould not reach.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    229\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[0;32m    230\u001b[0m     frozen_trial\u001b[39m.\u001b[39mstate \u001b[39m==\u001b[39m TrialState\u001b[39m.\u001b[39mFAIL\n\u001b[0;32m    231\u001b[0m     \u001b[39mand\u001b[39;00m func_err \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    232\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(func_err, catch)\n\u001b[0;32m    233\u001b[0m ):\n\u001b[1;32m--> 234\u001b[0m     \u001b[39mraise\u001b[39;00m func_err\n\u001b[0;32m    235\u001b[0m \u001b[39mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[1;32mc:\\Users\\britt\\Desktop\\YH\\Applicerad AI\\job_discrimination\\venv_job_discrimination\\lib\\site-packages\\optuna\\study\\_optimize.py:196\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    194\u001b[0m \u001b[39mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[39m.\u001b[39m_trial_id, study\u001b[39m.\u001b[39m_storage):\n\u001b[0;32m    195\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 196\u001b[0m         value_or_values \u001b[39m=\u001b[39m func(trial)\n\u001b[0;32m    197\u001b[0m     \u001b[39mexcept\u001b[39;00m exceptions\u001b[39m.\u001b[39mTrialPruned \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    198\u001b[0m         \u001b[39m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[0;32m    199\u001b[0m         state \u001b[39m=\u001b[39m TrialState\u001b[39m.\u001b[39mPRUNED\n",
      "Cell \u001b[1;32mIn[34], line 18\u001b[0m, in \u001b[0;36mobjective\u001b[1;34m(trial)\u001b[0m\n\u001b[0;32m     14\u001b[0m param[\u001b[39m'\u001b[39m\u001b[39mlogging_level\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mSilent\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m     16\u001b[0m regressor \u001b[39m=\u001b[39m CatBoostRegressor(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparam)\n\u001b[1;32m---> 18\u001b[0m regressor\u001b[39m.\u001b[39;49mfit(X_train, y_train, early_stopping_rounds\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m)\n\u001b[0;32m     19\u001b[0m loss \u001b[39m=\u001b[39m mean_squared_error(y_test, regressor\u001b[39m.\u001b[39mpredict(X_test))\n\u001b[0;32m     20\u001b[0m \u001b[39mreturn\u001b[39;00m loss\n",
      "File \u001b[1;32mc:\\Users\\britt\\Desktop\\YH\\Applicerad AI\\job_discrimination\\venv_job_discrimination\\lib\\site-packages\\catboost\\core.py:5730\u001b[0m, in \u001b[0;36mCatBoostRegressor.fit\u001b[1;34m(self, X, y, cat_features, text_features, embedding_features, sample_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[0;32m   5727\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mloss_function\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m params:\n\u001b[0;32m   5728\u001b[0m     CatBoostRegressor\u001b[39m.\u001b[39m_check_is_compatible_loss(params[\u001b[39m'\u001b[39m\u001b[39mloss_function\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m-> 5730\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit(X, y, cat_features, text_features, embedding_features, \u001b[39mNone\u001b[39;49;00m, sample_weight, \u001b[39mNone\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m, baseline,\n\u001b[0;32m   5731\u001b[0m                  use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description,\n\u001b[0;32m   5732\u001b[0m                  verbose_eval, metric_period, silent, early_stopping_rounds,\n\u001b[0;32m   5733\u001b[0m                  save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\n",
      "File \u001b[1;32mc:\\Users\\britt\\Desktop\\YH\\Applicerad AI\\job_discrimination\\venv_job_discrimination\\lib\\site-packages\\catboost\\core.py:2355\u001b[0m, in \u001b[0;36mCatBoost._fit\u001b[1;34m(self, X, y, cat_features, text_features, embedding_features, pairs, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[0;32m   2351\u001b[0m allow_clear_pool \u001b[39m=\u001b[39m train_params[\u001b[39m\"\u001b[39m\u001b[39mallow_clear_pool\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m   2353\u001b[0m \u001b[39mwith\u001b[39;00m log_fixup(log_cout, log_cerr), \\\n\u001b[0;32m   2354\u001b[0m     plot_wrapper(plot, plot_file, \u001b[39m'\u001b[39m\u001b[39mTraining plots\u001b[39m\u001b[39m'\u001b[39m, [_get_train_dir(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_params())]):\n\u001b[1;32m-> 2355\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_train(\n\u001b[0;32m   2356\u001b[0m         train_pool,\n\u001b[0;32m   2357\u001b[0m         train_params[\u001b[39m\"\u001b[39;49m\u001b[39meval_sets\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[0;32m   2358\u001b[0m         params,\n\u001b[0;32m   2359\u001b[0m         allow_clear_pool,\n\u001b[0;32m   2360\u001b[0m         train_params[\u001b[39m\"\u001b[39;49m\u001b[39minit_model\u001b[39;49m\u001b[39m\"\u001b[39;49m]\n\u001b[0;32m   2361\u001b[0m     )\n\u001b[0;32m   2363\u001b[0m \u001b[39m# Have property feature_importance possibly set\u001b[39;00m\n\u001b[0;32m   2364\u001b[0m loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_object\u001b[39m.\u001b[39m_get_loss_function_name()\n",
      "File \u001b[1;32mc:\\Users\\britt\\Desktop\\YH\\Applicerad AI\\job_discrimination\\venv_job_discrimination\\lib\\site-packages\\catboost\\core.py:1759\u001b[0m, in \u001b[0;36m_CatBoostBase._train\u001b[1;34m(self, train_pool, test_pool, params, allow_clear_pool, init_model)\u001b[0m\n\u001b[0;32m   1758\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_train\u001b[39m(\u001b[39mself\u001b[39m, train_pool, test_pool, params, allow_clear_pool, init_model):\n\u001b[1;32m-> 1759\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_object\u001b[39m.\u001b[39;49m_train(train_pool, test_pool, params, allow_clear_pool, init_model\u001b[39m.\u001b[39;49m_object \u001b[39mif\u001b[39;49;00m init_model \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m)\n\u001b[0;32m   1760\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_trained_model_attributes()\n",
      "File \u001b[1;32m_catboost.pyx:4623\u001b[0m, in \u001b[0;36m_catboost._CatBoost._train\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_catboost.pyx:4672\u001b[0m, in \u001b[0;36m_catboost._CatBoost._train\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(study_name=f'catboost-seed{1}')\n",
    "study.optimize(objective, n_trials=200, timeout=24000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.009000000000000001,\n",
       " 'depth': 15,\n",
       " 'l2_leaf_reg': 3.0,\n",
       " 'min_child_samples': 32}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {}\n",
    "param['learning_rate'] = 0.009\n",
    "param['depth'] = 15\n",
    "param['l2_leaf_reg'] = 3.0\n",
    "param['min_child_samples'] = 32\n",
    "param['grow_policy'] = 'Depthwise'\n",
    "#param['iterations'] = 10000\n",
    "param['eval_metric'] = 'RMSE'\n",
    "param['od_type'] = 'Iter'\n",
    "param['od_wait'] = 20\n",
    "param['random_state'] = 1\n",
    "param['logging_level'] = 'Silent'\n",
    "    \n",
    "regressor = CatBoostRegressor(**param)\n",
    "\n",
    "score = cross_val_score(regressor, X, y, n_jobs=-1, cv=3)\n",
    "accuracy = score.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5738416188135632"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor.fit(X_train, y_train, early_stopping_rounds=100)\n",
    "loss = mean_squared_error(y_test, regressor.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0262218829760942"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_job_discrimination",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "08461e0241a6d6061baac27f7d4197c6311cc2729e9bda34332c71c2f4c49bb9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
