{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First try with linear regression and tuning with Optuna. Looking for ways to measure the results. Nothing really useful in this notebook."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First try with linear regression and tuning with Optuna. Searchin for good ways to measure the results. Nothing really useful in this notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(r\"c:\\Users\\britt\\Desktop\\YH\\Applicerad AI\\job_discrimination\")\n",
    "import re\n",
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import optuna\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, precision_recall_fscore_support, classification_report, accuracy_score, recall_score, precision_score, f1_score\n",
    "from sklearn.model_selection import train_test_split, cross_validate, cross_val_score, cross_val_predict\n",
    "from sklearn.svm import SVC\n",
    "from unidecode import unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Job Description</th>\n",
       "      <th>Apps Received</th>\n",
       "      <th>Female</th>\n",
       "      <th>Male</th>\n",
       "      <th>Unknown_Gender</th>\n",
       "      <th>File Names</th>\n",
       "      <th>Label 60/40</th>\n",
       "      <th>Numeric label 60/40</th>\n",
       "      <th>Label 70/30</th>\n",
       "      <th>Numeric label 70/30</th>\n",
       "      <th>Cleaned text</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9206</td>\n",
       "      <td>311 DIRECTOR</td>\n",
       "      <td>54</td>\n",
       "      <td>20</td>\n",
       "      <td>31</td>\n",
       "      <td>3</td>\n",
       "      <td>311 DIRECTOR  9206 041814.txt</td>\n",
       "      <td>M</td>\n",
       "      <td>2</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>director class code open date annual salary du...</td>\n",
       "      <td>311 DIRECTOR Class Code:       9206 Open Date:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1223</td>\n",
       "      <td>ACCOUNTING CLERK</td>\n",
       "      <td>648</td>\n",
       "      <td>488</td>\n",
       "      <td>152</td>\n",
       "      <td>8</td>\n",
       "      <td>ACCOUNTING CLERK 1223 071318.txt</td>\n",
       "      <td>W</td>\n",
       "      <td>1</td>\n",
       "      <td>W</td>\n",
       "      <td>1</td>\n",
       "      <td>accounting clerk class code open date exam ope...</td>\n",
       "      <td>ACCOUNTING CLERK  Class Code:       1223 Open ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7260</td>\n",
       "      <td>AIRPORT MANAGER</td>\n",
       "      <td>51</td>\n",
       "      <td>13</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>AIRPORT MANAGER 7260 120216.txt</td>\n",
       "      <td>M</td>\n",
       "      <td>2</td>\n",
       "      <td>M</td>\n",
       "      <td>2</td>\n",
       "      <td>airport manager class code open date exam open...</td>\n",
       "      <td>AIRPORT MANAGER  Class Code:       7260 Open D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3227</td>\n",
       "      <td>AIRPORT POLICE LIEUTENANT</td>\n",
       "      <td>48</td>\n",
       "      <td>9</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>AIRPORT POLICE LIEUTENANT 3227 091616.txt</td>\n",
       "      <td>M</td>\n",
       "      <td>2</td>\n",
       "      <td>M</td>\n",
       "      <td>2</td>\n",
       "      <td>airport police lieutenant class code open date...</td>\n",
       "      <td>AIRPORT POLICE LIEUTENANT                 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2400</td>\n",
       "      <td>AQUARIST</td>\n",
       "      <td>40</td>\n",
       "      <td>15</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>AQUARIST 2400 050214.txt</td>\n",
       "      <td>M</td>\n",
       "      <td>2</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>aquarist class code open date annual salary ca...</td>\n",
       "      <td>AQUARIST Class Code:       2400 Open Date:  05...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>7840</td>\n",
       "      <td>WASTEWATER TREATMENT LABORATORY MANAGER</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>WASTEWATER TREATMENT LABORATORY MANAGER 7840 1...</td>\n",
       "      <td>M</td>\n",
       "      <td>2</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>wastewater treatment laboratory manager class ...</td>\n",
       "      <td>WASTEWATER TREATMENT LABORATORY MANAGER  Class...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>4123</td>\n",
       "      <td>WASTEWATER TREATMENT OPERATOR</td>\n",
       "      <td>125</td>\n",
       "      <td>9</td>\n",
       "      <td>113</td>\n",
       "      <td>3</td>\n",
       "      <td>WASTEWATER TREATMENT OPERATOR 120718.txt</td>\n",
       "      <td>M</td>\n",
       "      <td>2</td>\n",
       "      <td>M</td>\n",
       "      <td>2</td>\n",
       "      <td>wastewater treatment operator class code open ...</td>\n",
       "      <td>WASTEWATER TREATMENT OPERATOR  Class Code:    ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>7857</td>\n",
       "      <td>WATER MICROBIOLOGIST</td>\n",
       "      <td>179</td>\n",
       "      <td>89</td>\n",
       "      <td>82</td>\n",
       "      <td>8</td>\n",
       "      <td>WATER MICROBIOLOGIST  7857 072514 rev073114.txt</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>water microbiologist class code open date revi...</td>\n",
       "      <td>WATER MICROBIOLOGIST Class Code:       7857...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>3912</td>\n",
       "      <td>WATER UTILITY WORKER</td>\n",
       "      <td>96</td>\n",
       "      <td>2</td>\n",
       "      <td>92</td>\n",
       "      <td>2</td>\n",
       "      <td>WATER UTILITY WORKER 3912 120817.txt</td>\n",
       "      <td>M</td>\n",
       "      <td>2</td>\n",
       "      <td>M</td>\n",
       "      <td>2</td>\n",
       "      <td>water utility worker class code open date exam...</td>\n",
       "      <td>WATER UTILITY WORKER Class Code:       3912 Op...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>1774</td>\n",
       "      <td>WORKERS COMPENSATION ANALYST</td>\n",
       "      <td>166</td>\n",
       "      <td>100</td>\n",
       "      <td>61</td>\n",
       "      <td>5</td>\n",
       "      <td>WORKERS_ COMPENSATION ANALYST 1774 032417R.txt</td>\n",
       "      <td>W</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>worker compensation analyst class code open da...</td>\n",
       "      <td>WORKERS' COMPENSATION ANALYST Class Code:     ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>177 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ID                          Job Description  Apps Received  Female  \\\n",
       "0    9206                             311 DIRECTOR             54      20   \n",
       "1    1223                         ACCOUNTING CLERK            648     488   \n",
       "2    7260                          AIRPORT MANAGER             51      13   \n",
       "3    3227                AIRPORT POLICE LIEUTENANT             48       9   \n",
       "4    2400                                 AQUARIST             40      15   \n",
       "..    ...                                      ...            ...     ...   \n",
       "172  7840  WASTEWATER TREATMENT LABORATORY MANAGER             16       6   \n",
       "173  4123            WASTEWATER TREATMENT OPERATOR            125       9   \n",
       "174  7857                     WATER MICROBIOLOGIST            179      89   \n",
       "175  3912                     WATER UTILITY WORKER             96       2   \n",
       "176  1774             WORKERS COMPENSATION ANALYST            166     100   \n",
       "\n",
       "     Male  Unknown_Gender                                         File Names  \\\n",
       "0      31               3                      311 DIRECTOR  9206 041814.txt   \n",
       "1     152               8                   ACCOUNTING CLERK 1223 071318.txt   \n",
       "2      37               1                    AIRPORT MANAGER 7260 120216.txt   \n",
       "3      38               1          AIRPORT POLICE LIEUTENANT 3227 091616.txt   \n",
       "4      24               1                           AQUARIST 2400 050214.txt   \n",
       "..    ...             ...                                                ...   \n",
       "172     9               1  WASTEWATER TREATMENT LABORATORY MANAGER 7840 1...   \n",
       "173   113               3           WASTEWATER TREATMENT OPERATOR 120718.txt   \n",
       "174    82               8    WATER MICROBIOLOGIST  7857 072514 rev073114.txt   \n",
       "175    92               2               WATER UTILITY WORKER 3912 120817.txt   \n",
       "176    61               5     WORKERS_ COMPENSATION ANALYST 1774 032417R.txt   \n",
       "\n",
       "    Label 60/40  Numeric label 60/40 Label 70/30  Numeric label 70/30  \\\n",
       "0             M                    2           N                    0   \n",
       "1             W                    1           W                    1   \n",
       "2             M                    2           M                    2   \n",
       "3             M                    2           M                    2   \n",
       "4             M                    2           N                    0   \n",
       "..          ...                  ...         ...                  ...   \n",
       "172           M                    2           N                    0   \n",
       "173           M                    2           M                    2   \n",
       "174           N                    0           N                    0   \n",
       "175           M                    2           M                    2   \n",
       "176           W                    1           N                    0   \n",
       "\n",
       "                                          Cleaned text  \\\n",
       "0    director class code open date annual salary du...   \n",
       "1    accounting clerk class code open date exam ope...   \n",
       "2    airport manager class code open date exam open...   \n",
       "3    airport police lieutenant class code open date...   \n",
       "4    aquarist class code open date annual salary ca...   \n",
       "..                                                 ...   \n",
       "172  wastewater treatment laboratory manager class ...   \n",
       "173  wastewater treatment operator class code open ...   \n",
       "174  water microbiologist class code open date revi...   \n",
       "175  water utility worker class code open date exam...   \n",
       "176  worker compensation analyst class code open da...   \n",
       "\n",
       "                                                  Text  \n",
       "0    311 DIRECTOR Class Code:       9206 Open Date:...  \n",
       "1    ACCOUNTING CLERK  Class Code:       1223 Open ...  \n",
       "2    AIRPORT MANAGER  Class Code:       7260 Open D...  \n",
       "3        AIRPORT POLICE LIEUTENANT                 ...  \n",
       "4    AQUARIST Class Code:       2400 Open Date:  05...  \n",
       "..                                                 ...  \n",
       "172  WASTEWATER TREATMENT LABORATORY MANAGER  Class...  \n",
       "173  WASTEWATER TREATMENT OPERATOR  Class Code:    ...  \n",
       "174     WATER MICROBIOLOGIST Class Code:       7857...  \n",
       "175  WATER UTILITY WORKER Class Code:       3912 Op...  \n",
       "176  WORKERS' COMPENSATION ANALYST Class Code:     ...  \n",
       "\n",
       "[177 rows x 13 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/cleaned_data/bulletins_w_labels_and_content.csv\", dtype={'ID': object})  \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Job Description</th>\n",
       "      <th>Apps Received</th>\n",
       "      <th>Female</th>\n",
       "      <th>Male</th>\n",
       "      <th>Unknown_Gender</th>\n",
       "      <th>File Names</th>\n",
       "      <th>Label 60/40</th>\n",
       "      <th>Numeric label 60/40</th>\n",
       "      <th>Label 70/30</th>\n",
       "      <th>Numeric label 70/30</th>\n",
       "      <th>Cleaned text</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1770</td>\n",
       "      <td>SENIOR CLAIMS REPRESENTATIVE</td>\n",
       "      <td>175</td>\n",
       "      <td>89</td>\n",
       "      <td>84</td>\n",
       "      <td>2</td>\n",
       "      <td>SENIOR CLAIMS REPRESENTATIVE 1770 070717 (1).txt</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>senior claim representative class code open da...</td>\n",
       "      <td>SENIOR CLAIMS REPRESENTATIVE  Class Code:     ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3819</td>\n",
       "      <td>SIGNAL SYSTEMS ELECTRICIAN</td>\n",
       "      <td>223</td>\n",
       "      <td>1</td>\n",
       "      <td>222</td>\n",
       "      <td>0</td>\n",
       "      <td>SIGNAL SYSTEMS ELECTRICIAN 3819 042018.txt</td>\n",
       "      <td>M</td>\n",
       "      <td>2</td>\n",
       "      <td>M</td>\n",
       "      <td>2</td>\n",
       "      <td>signal system electrician class code open date...</td>\n",
       "      <td>SIGNAL SYSTEMS ELECTRICIAN\\t\\t   Class Code:  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3595</td>\n",
       "      <td>AUTOMOTIVE DISPATCHER</td>\n",
       "      <td>104</td>\n",
       "      <td>27</td>\n",
       "      <td>75</td>\n",
       "      <td>2</td>\n",
       "      <td>AUTOMOTIVE DISPATCHER 3595 102017 revised.txt</td>\n",
       "      <td>M</td>\n",
       "      <td>2</td>\n",
       "      <td>M</td>\n",
       "      <td>2</td>\n",
       "      <td>automotive dispatcher class code open date exa...</td>\n",
       "      <td>AUTOMOTIVE DISPATCHER  Class Code:     3595 Op...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3987</td>\n",
       "      <td>WATERWORKS MECHANIC SUPERVISOR</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>WATERWORKS MECHANIC SUPERVISOR 3987 051614 (1)...</td>\n",
       "      <td>M</td>\n",
       "      <td>2</td>\n",
       "      <td>M</td>\n",
       "      <td>2</td>\n",
       "      <td>waterworks mechanic supervisor class code open...</td>\n",
       "      <td>WATERWORKS MECHANIC SUPERVISOR                ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1839</td>\n",
       "      <td>PRINCIPAL STOREKEEPER</td>\n",
       "      <td>56</td>\n",
       "      <td>13</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>PRINCIPAL STOREKEEPER 1839 072718.txt</td>\n",
       "      <td>M</td>\n",
       "      <td>2</td>\n",
       "      <td>M</td>\n",
       "      <td>2</td>\n",
       "      <td>principal storekeeper class code open date exa...</td>\n",
       "      <td>PRINCIPAL STOREKEEPER   Class Code:       1839...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>2472</td>\n",
       "      <td>SUPERINTENDENT OF RECREATION AND PARKS OPERATIONS</td>\n",
       "      <td>26</td>\n",
       "      <td>8</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>SUPERINTENDENT OF RECREATION AND PARKS OPERATI...</td>\n",
       "      <td>M</td>\n",
       "      <td>2</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>superintendent recreation park operation class...</td>\n",
       "      <td>SUPERINTENDENT OF RECREATION AND PARKS OPERATI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>7857</td>\n",
       "      <td>WATER MICROBIOLOGIST</td>\n",
       "      <td>179</td>\n",
       "      <td>89</td>\n",
       "      <td>82</td>\n",
       "      <td>8</td>\n",
       "      <td>WATER MICROBIOLOGIST  7857 072514 rev073114.txt</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>water microbiologist class code open date revi...</td>\n",
       "      <td>WATER MICROBIOLOGIST Class Code:       7857...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>2454</td>\n",
       "      <td>ARTS ASSOCIATE</td>\n",
       "      <td>702</td>\n",
       "      <td>430</td>\n",
       "      <td>240</td>\n",
       "      <td>32</td>\n",
       "      <td>ARTS ASSOCIATE 2454 072117 REV 072817.txt</td>\n",
       "      <td>W</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>art associate class code open date revise exam...</td>\n",
       "      <td>ARTS ASSOCIATE Class Code:       2454         ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>3801</td>\n",
       "      <td>SENIOR COMMUNICATIONS CABLE WORKER</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>SENIOR COMMUNICATIONS CABLE WORKER 3801 102116...</td>\n",
       "      <td>M</td>\n",
       "      <td>2</td>\n",
       "      <td>M</td>\n",
       "      <td>2</td>\n",
       "      <td>senior communication cable worker class code o...</td>\n",
       "      <td>SENIOR COMMUNICATIONS CABLE WORKER  Class Code...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>9602</td>\n",
       "      <td>WATER SERVICES MANAGER</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>WATER SERVICES MANAGER 9602 081216.txt</td>\n",
       "      <td>M</td>\n",
       "      <td>2</td>\n",
       "      <td>M</td>\n",
       "      <td>2</td>\n",
       "      <td>water service manager class code open date exa...</td>\n",
       "      <td>WATER SERVICES MANAGER  Class Code:       9602...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>177 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ID                                    Job Description  Apps Received  \\\n",
       "0    1770                       SENIOR CLAIMS REPRESENTATIVE            175   \n",
       "1    3819                         SIGNAL SYSTEMS ELECTRICIAN            223   \n",
       "2    3595                              AUTOMOTIVE DISPATCHER            104   \n",
       "3    3987                     WATERWORKS MECHANIC SUPERVISOR             30   \n",
       "4    1839                              PRINCIPAL STOREKEEPER             56   \n",
       "..    ...                                                ...            ...   \n",
       "172  2472  SUPERINTENDENT OF RECREATION AND PARKS OPERATIONS             26   \n",
       "173  7857                               WATER MICROBIOLOGIST            179   \n",
       "174  2454                                     ARTS ASSOCIATE            702   \n",
       "175  3801                 SENIOR COMMUNICATIONS CABLE WORKER             28   \n",
       "176  9602                             WATER SERVICES MANAGER              8   \n",
       "\n",
       "     Female  Male  Unknown_Gender  \\\n",
       "0        89    84               2   \n",
       "1         1   222               0   \n",
       "2        27    75               2   \n",
       "3         1    29               0   \n",
       "4        13    43               0   \n",
       "..      ...   ...             ...   \n",
       "172       8    18               0   \n",
       "173      89    82               8   \n",
       "174     430   240              32   \n",
       "175       0    27               1   \n",
       "176       0     8               0   \n",
       "\n",
       "                                            File Names Label 60/40  \\\n",
       "0     SENIOR CLAIMS REPRESENTATIVE 1770 070717 (1).txt           N   \n",
       "1           SIGNAL SYSTEMS ELECTRICIAN 3819 042018.txt           M   \n",
       "2        AUTOMOTIVE DISPATCHER 3595 102017 revised.txt           M   \n",
       "3    WATERWORKS MECHANIC SUPERVISOR 3987 051614 (1)...           M   \n",
       "4                PRINCIPAL STOREKEEPER 1839 072718.txt           M   \n",
       "..                                                 ...         ...   \n",
       "172  SUPERINTENDENT OF RECREATION AND PARKS OPERATI...           M   \n",
       "173    WATER MICROBIOLOGIST  7857 072514 rev073114.txt           N   \n",
       "174          ARTS ASSOCIATE 2454 072117 REV 072817.txt           W   \n",
       "175  SENIOR COMMUNICATIONS CABLE WORKER 3801 102116...           M   \n",
       "176             WATER SERVICES MANAGER 9602 081216.txt           M   \n",
       "\n",
       "     Numeric label 60/40 Label 70/30  Numeric label 70/30  \\\n",
       "0                      0           N                    0   \n",
       "1                      2           M                    2   \n",
       "2                      2           M                    2   \n",
       "3                      2           M                    2   \n",
       "4                      2           M                    2   \n",
       "..                   ...         ...                  ...   \n",
       "172                    2           N                    0   \n",
       "173                    0           N                    0   \n",
       "174                    1           N                    0   \n",
       "175                    2           M                    2   \n",
       "176                    2           M                    2   \n",
       "\n",
       "                                          Cleaned text  \\\n",
       "0    senior claim representative class code open da...   \n",
       "1    signal system electrician class code open date...   \n",
       "2    automotive dispatcher class code open date exa...   \n",
       "3    waterworks mechanic supervisor class code open...   \n",
       "4    principal storekeeper class code open date exa...   \n",
       "..                                                 ...   \n",
       "172  superintendent recreation park operation class...   \n",
       "173  water microbiologist class code open date revi...   \n",
       "174  art associate class code open date revise exam...   \n",
       "175  senior communication cable worker class code o...   \n",
       "176  water service manager class code open date exa...   \n",
       "\n",
       "                                                  Text  \n",
       "0    SENIOR CLAIMS REPRESENTATIVE  Class Code:     ...  \n",
       "1    SIGNAL SYSTEMS ELECTRICIAN\\t\\t   Class Code:  ...  \n",
       "2    AUTOMOTIVE DISPATCHER  Class Code:     3595 Op...  \n",
       "3    WATERWORKS MECHANIC SUPERVISOR                ...  \n",
       "4    PRINCIPAL STOREKEEPER   Class Code:       1839...  \n",
       "..                                                 ...  \n",
       "172  SUPERINTENDENT OF RECREATION AND PARKS OPERATI...  \n",
       "173     WATER MICROBIOLOGIST Class Code:       7857...  \n",
       "174  ARTS ASSOCIATE Class Code:       2454         ...  \n",
       "175  SENIOR COMMUNICATIONS CABLE WORKER  Class Code...  \n",
       "176  WATER SERVICES MANAGER  Class Code:       9602...  \n",
       "\n",
       "[177 rows x 13 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[\"Cleaned text\"]\n",
    "y = df[\"Numeric label 70/30\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = vectorizer.fit_transform(X).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\britt\\Desktop\\YH\\Applicerad AI\\job_discrimination\\venv_job_discrimination\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-17 {color: black;background-color: white;}#sk-container-id-17 pre{padding: 0;}#sk-container-id-17 div.sk-toggleable {background-color: white;}#sk-container-id-17 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-17 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-17 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-17 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-17 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-17 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-17 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-17 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-17 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-17 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-17 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-17 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-17 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-17 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-17 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-17 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-17 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-17 div.sk-item {position: relative;z-index: 1;}#sk-container-id-17 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-17 div.sk-item::before, #sk-container-id-17 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-17 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-17 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-17 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-17 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-17 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-17 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-17 div.sk-label-container {text-align: center;}#sk-container-id-17 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-17 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-17\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" checked><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = log_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, 2, 0, 2, 0, 2, 2, 0, 0, 0, 2, 2, 2, 2, 2, 2, 0, 2, 1, 2,\n",
       "       2, 2, 0, 2, 2, 2, 2, 1, 2, 0, 0, 2, 0, 2, 0, 2, 2, 2, 0, 2, 2, 2,\n",
       "       2], dtype=int64)"
      ]
     },
     "execution_count": 387,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, 2),\n",
       " (2, 2),\n",
       " (2, 2),\n",
       " (1, 2),\n",
       " (0, 0),\n",
       " (0, 2),\n",
       " (0, 0),\n",
       " (2, 2),\n",
       " (2, 2),\n",
       " (2, 0),\n",
       " (0, 0),\n",
       " (2, 0),\n",
       " (2, 2),\n",
       " (2, 2),\n",
       " (2, 2),\n",
       " (0, 2),\n",
       " (2, 2),\n",
       " (2, 2),\n",
       " (0, 0),\n",
       " (1, 2),\n",
       " (0, 1),\n",
       " (2, 2),\n",
       " (2, 2),\n",
       " (2, 2),\n",
       " (1, 0),\n",
       " (0, 2),\n",
       " (2, 2),\n",
       " (2, 2),\n",
       " (2, 2),\n",
       " (2, 1),\n",
       " (2, 2),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (2, 2),\n",
       " (2, 0),\n",
       " (2, 2),\n",
       " (2, 0),\n",
       " (2, 2),\n",
       " (2, 2),\n",
       " (2, 2),\n",
       " (0, 0),\n",
       " (2, 2),\n",
       " (2, 2),\n",
       " (2, 2),\n",
       " (2, 2)]"
      ]
     },
     "execution_count": 388,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(y_test, list(predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7333333333333333"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = log_reg.score(X_test, y_test)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\britt\\Desktop\\YH\\Applicerad AI\\job_discrimination\\venv_job_discrimination\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\britt\\Desktop\\YH\\Applicerad AI\\job_discrimination\\venv_job_discrimination\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\britt\\Desktop\\YH\\Applicerad AI\\job_discrimination\\venv_job_discrimination\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\britt\\Desktop\\YH\\Applicerad AI\\job_discrimination\\venv_job_discrimination\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\britt\\Desktop\\YH\\Applicerad AI\\job_discrimination\\venv_job_discrimination\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\britt\\Desktop\\YH\\Applicerad AI\\job_discrimination\\venv_job_discrimination\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\britt\\Desktop\\YH\\Applicerad AI\\job_discrimination\\venv_job_discrimination\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\britt\\Desktop\\YH\\Applicerad AI\\job_discrimination\\venv_job_discrimination\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\britt\\Desktop\\YH\\Applicerad AI\\job_discrimination\\venv_job_discrimination\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\britt\\Desktop\\YH\\Applicerad AI\\job_discrimination\\venv_job_discrimination\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(log_reg, X, y, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.72222222, 0.83333333, 0.88888889, 0.83333333, 0.83333333,\n",
       "       0.88888889, 0.83333333, 0.82352941, 0.76470588, 0.88235294])"
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.830392156862745"
      ]
     },
     "execution_count": 392,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_test, X_gtest, y_train_test, y_gtest = train_test_split(X, y, test_size=0.10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\britt\\Desktop\\YH\\Applicerad AI\\job_discrimination\\venv_job_discrimination\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\britt\\Desktop\\YH\\Applicerad AI\\job_discrimination\\venv_job_discrimination\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\britt\\Desktop\\YH\\Applicerad AI\\job_discrimination\\venv_job_discrimination\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\britt\\Desktop\\YH\\Applicerad AI\\job_discrimination\\venv_job_discrimination\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\britt\\Desktop\\YH\\Applicerad AI\\job_discrimination\\venv_job_discrimination\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "cv_results = cross_validate(log_reg, X_train_test, y_train_test, cv=5, return_estimator=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.875     , 0.78125   , 0.78125   , 0.875     , 0.77419355])"
      ]
     },
     "execution_count": 395,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results[\"test_score\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8173387096774194"
      ]
     },
     "execution_count": 396,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results[\"test_score\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtest_score = []\n",
    "for i in range(len(cv_results['estimator'])):\n",
    "  gtest_score.append(cv_results['estimator'][i].score(X_gtest, y_gtest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8222222222222223"
      ]
     },
     "execution_count": 398,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(gtest_score) / len(gtest_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):    \n",
    "    # Step 2. Setup values for the hyperparameters:\n",
    "    logreg_c = trial.suggest_float(\"logreg_c\", 1e-10, 1e10, log=True)\n",
    "    classifier_obj = LogisticRegression(C=logreg_c)\n",
    "\n",
    "    classifier_obj.fit(X_train, y_train)\n",
    "    preds = classifier_obj.predict(X_test)\n",
    "    \n",
    "    # Step 3: Scoring method:\n",
    "    score = cross_val_score(classifier_obj, X, y, n_jobs=-1, cv=3)\n",
    "    accuracy = score.mean()\n",
    "    p_r_f_s = precision_recall_fscore_support(y_test, preds)\n",
    "    precision = p_r_f_s[0][0]\n",
    "    print(precision)\n",
    "    recall = p_r_f_s[0][1]\n",
    "    f1 = p_r_f_s[0][2]\n",
    "    #support = p_r_f_s[3]\n",
    "    \n",
    "    return accuracy, precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-12-20 16:54:31,425]\u001b[0m A new study created in memory with name: no-name-191ad48d-f9de-4cf9-abfe-2eeef78ead27\u001b[0m\n",
      "c:\\Users\\britt\\Desktop\\YH\\Applicerad AI\\job_discrimination\\venv_job_discrimination\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "\u001b[32m[I 2022-12-20 16:54:34,807]\u001b[0m Trial 0 finished with values: [0.847457627118644, 0.5384615384615384, 0.0, 0.8333333333333334] and parameters: {'logreg_c': 40.40055447162931}. \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5384615384615384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-12-20 16:54:36,047]\u001b[0m Trial 1 finished with values: [0.847457627118644, 0.5384615384615384, 0.0, 0.8333333333333334] and parameters: {'logreg_c': 1497875.789770839}. \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5384615384615384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\britt\\Desktop\\YH\\Applicerad AI\\job_discrimination\\venv_job_discrimination\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\u001b[32m[I 2022-12-20 16:54:37,352]\u001b[0m Trial 2 finished with values: [0.7288135593220338, 0.8333333333333334, 0.0, 0.7692307692307693] and parameters: {'logreg_c': 0.00017347009095646909}. \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8333333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\britt\\Desktop\\YH\\Applicerad AI\\job_discrimination\\venv_job_discrimination\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "\u001b[32m[I 2022-12-20 16:54:39,250]\u001b[0m Trial 3 finished with values: [0.847457627118644, 0.5384615384615384, 0.0, 0.8333333333333334] and parameters: {'logreg_c': 44.16849644775723}. \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5384615384615384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-12-20 16:54:40,839]\u001b[0m Trial 4 finished with values: [0.8531073446327683, 0.5384615384615384, 0.0, 0.8333333333333334] and parameters: {'logreg_c': 3120.1234661796025}. \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5384615384615384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\britt\\Desktop\\YH\\Applicerad AI\\job_discrimination\\venv_job_discrimination\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "\u001b[32m[I 2022-12-20 16:54:42,376]\u001b[0m Trial 5 finished with values: [0.8305084745762712, 0.6363636363636364, 0.0, 0.8484848484848485] and parameters: {'logreg_c': 0.0039002995527574968}. \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6363636363636364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-12-20 16:54:42,811]\u001b[0m Trial 6 finished with values: [0.8531073446327683, 0.5384615384615384, 0.0, 0.8333333333333334] and parameters: {'logreg_c': 4474.286228409772}. \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5384615384615384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-12-20 16:54:43,152]\u001b[0m Trial 7 finished with values: [0.847457627118644, 0.5384615384615384, 0.0, 0.8333333333333334] and parameters: {'logreg_c': 63776917.63856781}. \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5384615384615384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\britt\\Desktop\\YH\\Applicerad AI\\job_discrimination\\venv_job_discrimination\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\u001b[32m[I 2022-12-20 16:54:43,634]\u001b[0m Trial 8 finished with values: [0.7401129943502825, 0.8333333333333334, 0.0, 0.7692307692307693] and parameters: {'logreg_c': 0.00026116404381777795}. \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8333333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-12-20 16:54:43,973]\u001b[0m Trial 9 finished with values: [0.847457627118644, 0.5384615384615384, 0.0, 0.8333333333333334] and parameters: {'logreg_c': 145471139.34151244}. \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5384615384615384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\britt\\Desktop\\YH\\Applicerad AI\\job_discrimination\\venv_job_discrimination\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\u001b[32m[I 2022-12-20 16:54:44,412]\u001b[0m Trial 10 finished with values: [0.5932203389830508, 0.0, 0.0, 0.6888888888888889] and parameters: {'logreg_c': 1.41088368391129e-09}. \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-12-20 16:54:44,910]\u001b[0m Trial 11 finished with values: [0.8418079096045198, 0.5384615384615384, 0.0, 0.8333333333333334] and parameters: {'logreg_c': 2081.2505269157687}. \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5384615384615384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-12-20 16:54:45,250]\u001b[0m Trial 12 finished with values: [0.847457627118644, 0.5384615384615384, 0.0, 0.8333333333333334] and parameters: {'logreg_c': 2474324.1005232004}. \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5384615384615384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-12-20 16:54:45,577]\u001b[0m Trial 13 finished with values: [0.847457627118644, 0.5384615384615384, 0.0, 0.8333333333333334] and parameters: {'logreg_c': 876592423.6803751}. \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5384615384615384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\britt\\Desktop\\YH\\Applicerad AI\\job_discrimination\\venv_job_discrimination\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\u001b[32m[I 2022-12-20 16:54:46,030]\u001b[0m Trial 14 finished with values: [0.5932203389830508, 0.0, 0.0, 0.6888888888888889] and parameters: {'logreg_c': 8.214403960159615e-09}. \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-12-20 16:54:46,667]\u001b[0m Trial 15 finished with values: [0.847457627118644, 0.5384615384615384, 0.0, 0.8333333333333334] and parameters: {'logreg_c': 221.43274530918788}. \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5384615384615384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\britt\\Desktop\\YH\\Applicerad AI\\job_discrimination\\venv_job_discrimination\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\u001b[32m[I 2022-12-20 16:54:47,022]\u001b[0m Trial 16 finished with values: [0.5932203389830508, 0.0, 0.0, 0.6888888888888889] and parameters: {'logreg_c': 1.326467576172658e-06}. \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-12-20 16:54:47,627]\u001b[0m Trial 17 finished with values: [0.847457627118644, 0.5384615384615384, 0.0, 0.8333333333333334] and parameters: {'logreg_c': 9308341172.937336}. \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5384615384615384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\britt\\Desktop\\YH\\Applicerad AI\\job_discrimination\\venv_job_discrimination\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "\u001b[32m[I 2022-12-20 16:54:48,428]\u001b[0m Trial 18 finished with values: [0.8418079096045198, 0.5384615384615384, 0.0, 0.8333333333333334] and parameters: {'logreg_c': 1.0413476778025816}. \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5384615384615384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\britt\\Desktop\\YH\\Applicerad AI\\job_discrimination\\venv_job_discrimination\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "\u001b[32m[I 2022-12-20 16:54:49,293]\u001b[0m Trial 19 finished with values: [0.847457627118644, 0.5384615384615384, 0.0, 0.8333333333333334] and parameters: {'logreg_c': 58.90009904919971}. \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5384615384615384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\britt\\Desktop\\YH\\Applicerad AI\\job_discrimination\\venv_job_discrimination\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "\u001b[32m[I 2022-12-20 16:54:50,166]\u001b[0m Trial 20 finished with values: [0.8418079096045198, 0.5384615384615384, 0.0, 0.8333333333333334] and parameters: {'logreg_c': 0.8972182859381165}. \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5384615384615384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-12-20 16:54:50,507]\u001b[0m Trial 21 finished with values: [0.847457627118644, 0.5384615384615384, 0.0, 0.8333333333333334] and parameters: {'logreg_c': 8790237.747557133}. \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5384615384615384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\britt\\Desktop\\YH\\Applicerad AI\\job_discrimination\\venv_job_discrimination\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "\u001b[32m[I 2022-12-20 16:54:51,512]\u001b[0m Trial 22 finished with values: [0.8418079096045198, 0.5384615384615384, 0.0, 0.8333333333333334] and parameters: {'logreg_c': 0.2710097161168381}. \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5384615384615384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\britt\\Desktop\\YH\\Applicerad AI\\job_discrimination\\venv_job_discrimination\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\u001b[32m[I 2022-12-20 16:54:51,931]\u001b[0m Trial 23 finished with values: [0.5932203389830508, 0.0, 0.0, 0.6888888888888889] and parameters: {'logreg_c': 8.648385484475096e-08}. \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-12-20 16:54:52,259]\u001b[0m Trial 24 finished with values: [0.847457627118644, 0.5384615384615384, 0.0, 0.8333333333333334] and parameters: {'logreg_c': 24328728.19683115}. \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5384615384615384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-12-20 16:54:52,617]\u001b[0m Trial 25 finished with values: [0.847457627118644, 0.5384615384615384, 0.0, 0.8333333333333334] and parameters: {'logreg_c': 25325.04962340838}. \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5384615384615384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\britt\\Desktop\\YH\\Applicerad AI\\job_discrimination\\venv_job_discrimination\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\u001b[32m[I 2022-12-20 16:54:53,009]\u001b[0m Trial 26 finished with values: [0.6779661016949152, 0.75, 0.0, 0.7317073170731707] and parameters: {'logreg_c': 7.632648731048564e-05}. \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\britt\\Desktop\\YH\\Applicerad AI\\job_discrimination\\venv_job_discrimination\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "\u001b[32m[I 2022-12-20 16:54:53,804]\u001b[0m Trial 27 finished with values: [0.8418079096045198, 0.5384615384615384, 0.0, 0.8333333333333334] and parameters: {'logreg_c': 2.1730289814890797}. \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5384615384615384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-12-20 16:54:54,224]\u001b[0m Trial 28 finished with values: [0.847457627118644, 0.5384615384615384, 0.0, 0.8333333333333334] and parameters: {'logreg_c': 167156559.86465746}. \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5384615384615384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-12-20 16:54:54,672]\u001b[0m Trial 29 finished with values: [0.847457627118644, 0.5384615384615384, 0.0, 0.8333333333333334] and parameters: {'logreg_c': 5515575631.778255}. \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5384615384615384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\britt\\Desktop\\YH\\Applicerad AI\\job_discrimination\\venv_job_discrimination\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "\u001b[32m[I 2022-12-20 16:54:55,526]\u001b[0m Trial 30 finished with values: [0.847457627118644, 0.5384615384615384, 0.0, 0.8333333333333334] and parameters: {'logreg_c': 25.5874935479746}. \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5384615384615384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-12-20 16:54:55,884]\u001b[0m Trial 31 finished with values: [0.847457627118644, 0.5384615384615384, 0.0, 0.8333333333333334] and parameters: {'logreg_c': 76063216.59020081}. \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5384615384615384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-12-20 16:54:56,243]\u001b[0m Trial 32 finished with values: [0.847457627118644, 0.5384615384615384, 0.0, 0.8333333333333334] and parameters: {'logreg_c': 1462288579.6601548}. \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5384615384615384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\britt\\Desktop\\YH\\Applicerad AI\\job_discrimination\\venv_job_discrimination\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "\u001b[32m[I 2022-12-20 16:54:57,022]\u001b[0m Trial 33 finished with values: [0.847457627118644, 0.5384615384615384, 0.0, 0.8333333333333334] and parameters: {'logreg_c': 5.9190644358259945}. \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5384615384615384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-12-20 16:54:57,364]\u001b[0m Trial 34 finished with values: [0.847457627118644, 0.5384615384615384, 0.0, 0.8333333333333334] and parameters: {'logreg_c': 4323840524.135543}. \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5384615384615384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-12-20 16:54:57,705]\u001b[0m Trial 35 finished with values: [0.847457627118644, 0.5384615384615384, 0.0, 0.8333333333333334] and parameters: {'logreg_c': 69043.02481576797}. \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5384615384615384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\britt\\Desktop\\YH\\Applicerad AI\\job_discrimination\\venv_job_discrimination\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\u001b[32m[I 2022-12-20 16:54:57,969]\u001b[0m Trial 36 finished with values: [0.5932203389830508, 0.0, 0.0, 0.6888888888888889] and parameters: {'logreg_c': 1.7833018667527524e-10}. \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-12-20 16:54:58,297]\u001b[0m Trial 37 finished with values: [0.847457627118644, 0.5384615384615384, 0.0, 0.8333333333333334] and parameters: {'logreg_c': 821995.2597395538}. \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5384615384615384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-12-20 16:54:58,751]\u001b[0m Trial 38 finished with values: [0.8531073446327683, 0.5384615384615384, 0.0, 0.8333333333333334] and parameters: {'logreg_c': 6149.9766206077575}. \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5384615384615384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\britt\\Desktop\\YH\\Applicerad AI\\job_discrimination\\venv_job_discrimination\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\u001b[32m[I 2022-12-20 16:54:59,251]\u001b[0m Trial 39 finished with values: [0.7457627118644067, 0.8333333333333334, 0.0, 0.7692307692307693] and parameters: {'logreg_c': 0.00029075434165292714}. \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8333333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-12-20 16:54:59,577]\u001b[0m Trial 40 finished with values: [0.847457627118644, 0.5384615384615384, 0.0, 0.8333333333333334] and parameters: {'logreg_c': 137231925.9367498}. \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5384615384615384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-12-20 16:54:59,918]\u001b[0m Trial 41 finished with values: [0.8531073446327683, 0.5384615384615384, 0.0, 0.8333333333333334] and parameters: {'logreg_c': 46130.98180642906}. \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5384615384615384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-12-20 16:55:00,247]\u001b[0m Trial 42 finished with values: [0.847457627118644, 0.5384615384615384, 0.0, 0.8333333333333334] and parameters: {'logreg_c': 5180520033.35532}. \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5384615384615384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-12-20 16:55:00,729]\u001b[0m Trial 43 finished with values: [0.847457627118644, 0.5384615384615384, 0.0, 0.8333333333333334] and parameters: {'logreg_c': 2116.382186115042}. \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5384615384615384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-12-20 16:55:01,056]\u001b[0m Trial 44 finished with values: [0.847457627118644, 0.5384615384615384, 0.0, 0.8333333333333334] and parameters: {'logreg_c': 108474.82808838805}. \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5384615384615384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\britt\\Desktop\\YH\\Applicerad AI\\job_discrimination\\venv_job_discrimination\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "\u001b[32m[I 2022-12-20 16:55:01,835]\u001b[0m Trial 45 finished with values: [0.847457627118644, 0.5384615384615384, 0.0, 0.8333333333333334] and parameters: {'logreg_c': 5.18218987948677}. \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5384615384615384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\britt\\Desktop\\YH\\Applicerad AI\\job_discrimination\\venv_job_discrimination\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\u001b[32m[I 2022-12-20 16:55:02,116]\u001b[0m Trial 46 finished with values: [0.5932203389830508, 0.0, 0.0, 0.6888888888888889] and parameters: {'logreg_c': 1.5706373524587092e-10}. \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-12-20 16:55:02,755]\u001b[0m Trial 47 finished with values: [0.8418079096045198, 0.5384615384615384, 0.0, 0.8333333333333334] and parameters: {'logreg_c': 313.23956730548736}. \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5384615384615384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-12-20 16:55:03,111]\u001b[0m Trial 48 finished with values: [0.847457627118644, 0.5384615384615384, 0.0, 0.8333333333333334] and parameters: {'logreg_c': 2851681.877022187}. \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5384615384615384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-12-20 16:55:03,798]\u001b[0m Trial 49 finished with values: [0.847457627118644, 0.5384615384615384, 0.0, 0.8333333333333334] and parameters: {'logreg_c': 151.29767309891403}. \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5384615384615384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\britt\\Desktop\\YH\\Applicerad AI\\job_discrimination\\venv_job_discrimination\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "\u001b[32m[I 2022-12-20 16:55:04,654]\u001b[0m Trial 50 finished with values: [0.847457627118644, 0.5384615384615384, 0.0, 0.8333333333333334] and parameters: {'logreg_c': 8.621467510649879}. \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5384615384615384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\britt\\Desktop\\YH\\Applicerad AI\\job_discrimination\\venv_job_discrimination\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\u001b[32m[I 2022-12-20 16:55:05,137]\u001b[0m Trial 51 finished with values: [0.5932203389830508, 0.0, 0.0, 0.6888888888888889] and parameters: {'logreg_c': 2.0895836295588517e-09}. \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\britt\\Desktop\\YH\\Applicerad AI\\job_discrimination\\venv_job_discrimination\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\u001b[32m[I 2022-12-20 16:55:05,508]\u001b[0m Trial 52 finished with values: [0.5932203389830508, 0.0, 0.0, 0.6888888888888889] and parameters: {'logreg_c': 2.0136538977871903e-06}. \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-12-20 16:55:05,895]\u001b[0m Trial 53 finished with values: [0.847457627118644, 0.5384615384615384, 0.0, 0.8333333333333334] and parameters: {'logreg_c': 4133391378.8235}. \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5384615384615384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\britt\\Desktop\\YH\\Applicerad AI\\job_discrimination\\venv_job_discrimination\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\u001b[32m[I 2022-12-20 16:55:06,178]\u001b[0m Trial 54 finished with values: [0.5932203389830508, 0.0, 0.0, 0.6888888888888889] and parameters: {'logreg_c': 2.7794939718548573e-10}. \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\britt\\Desktop\\YH\\Applicerad AI\\job_discrimination\\venv_job_discrimination\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\u001b[32m[I 2022-12-20 16:55:06,537]\u001b[0m Trial 55 finished with values: [0.5932203389830508, 0.0, 0.0, 0.6888888888888889] and parameters: {'logreg_c': 1.1055814050411254e-05}. \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-12-20 16:55:07,127]\u001b[0m Trial 56 finished with values: [0.847457627118644, 0.5384615384615384, 0.0, 0.8333333333333334] and parameters: {'logreg_c': 156731.14992317668}. \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5384615384615384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-12-20 16:55:07,455]\u001b[0m Trial 57 finished with values: [0.847457627118644, 0.5384615384615384, 0.0, 0.8333333333333334] and parameters: {'logreg_c': 70267851.60656622}. \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5384615384615384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\britt\\Desktop\\YH\\Applicerad AI\\job_discrimination\\venv_job_discrimination\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "\u001b[32m[I 2022-12-20 16:55:08,249]\u001b[0m Trial 58 finished with values: [0.8418079096045198, 0.5384615384615384, 0.0, 0.8333333333333334] and parameters: {'logreg_c': 0.5212020133162119}. \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5384615384615384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-12-20 16:55:08,919]\u001b[0m Trial 59 finished with values: [0.847457627118644, 0.5384615384615384, 0.0, 0.8333333333333334] and parameters: {'logreg_c': 157.0997323313373}. \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5384615384615384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\britt\\Desktop\\YH\\Applicerad AI\\job_discrimination\\venv_job_discrimination\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\u001b[32m[I 2022-12-20 16:55:09,183]\u001b[0m Trial 60 finished with values: [0.5932203389830508, 0.0, 0.0, 0.6888888888888889] and parameters: {'logreg_c': 1.911058364274404e-10}. \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\britt\\Desktop\\YH\\Applicerad AI\\job_discrimination\\venv_job_discrimination\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "\u001b[32m[I 2022-12-20 16:55:09,975]\u001b[0m Trial 61 finished with values: [0.847457627118644, 0.5384615384615384, 0.0, 0.8333333333333334] and parameters: {'logreg_c': 47.35737029714375}. \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5384615384615384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-12-20 16:55:10,522]\u001b[0m Trial 62 finished with values: [0.8418079096045198, 0.5384615384615384, 0.0, 0.8333333333333334] and parameters: {'logreg_c': 958.150044515443}. \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5384615384615384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\britt\\Desktop\\YH\\Applicerad AI\\job_discrimination\\venv_job_discrimination\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "\u001b[32m[I 2022-12-20 16:55:11,311]\u001b[0m Trial 63 finished with values: [0.847457627118644, 0.5384615384615384, 0.0, 0.8333333333333334] and parameters: {'logreg_c': 0.16182334026444295}. \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5384615384615384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\britt\\Desktop\\YH\\Applicerad AI\\job_discrimination\\venv_job_discrimination\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\u001b[32m[I 2022-12-20 16:55:11,746]\u001b[0m Trial 64 finished with values: [0.5932203389830508, 0.0, 0.0, 0.6888888888888889] and parameters: {'logreg_c': 7.922367081773541e-09}. \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\britt\\Desktop\\YH\\Applicerad AI\\job_discrimination\\venv_job_discrimination\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "\u001b[32m[I 2022-12-20 16:55:12,523]\u001b[0m Trial 65 finished with values: [0.8418079096045198, 0.5384615384615384, 0.0, 0.8333333333333334] and parameters: {'logreg_c': 0.5178593750557182}. \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5384615384615384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\britt\\Desktop\\YH\\Applicerad AI\\job_discrimination\\venv_job_discrimination\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "\u001b[32m[I 2022-12-20 16:55:13,327]\u001b[0m Trial 66 finished with values: [0.8418079096045198, 0.5833333333333334, 0.0, 0.8387096774193549] and parameters: {'logreg_c': 0.016740946634370944}. \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5833333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-12-20 16:55:13,796]\u001b[0m Trial 67 finished with values: [0.8531073446327683, 0.5384615384615384, 0.0, 0.8333333333333334] and parameters: {'logreg_c': 4502.537578633287}. \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5384615384615384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-12-20 16:55:14,139]\u001b[0m Trial 68 finished with values: [0.8531073446327683, 0.5384615384615384, 0.0, 0.8333333333333334] and parameters: {'logreg_c': 56312.70030350103}. \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5384615384615384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-12-20 16:55:14,482]\u001b[0m Trial 69 finished with values: [0.847457627118644, 0.5384615384615384, 0.0, 0.8333333333333334] and parameters: {'logreg_c': 154185.8455610962}. \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5384615384615384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-12-20 16:55:14,948]\u001b[0m Trial 70 finished with values: [0.8531073446327683, 0.5384615384615384, 0.0, 0.8333333333333334] and parameters: {'logreg_c': 7583.753647155869}. \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5384615384615384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\britt\\Desktop\\YH\\Applicerad AI\\job_discrimination\\venv_job_discrimination\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\u001b[32m[I 2022-12-20 16:55:15,411]\u001b[0m Trial 71 finished with values: [0.5932203389830508, 0.0, 0.0, 0.6888888888888889] and parameters: {'logreg_c': 1.5182120090608364e-08}. \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\britt\\Desktop\\YH\\Applicerad AI\\job_discrimination\\venv_job_discrimination\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\u001b[32m[I 2022-12-20 16:55:15,878]\u001b[0m Trial 72 finished with values: [0.5932203389830508, 0.0, 0.0, 0.6888888888888889] and parameters: {'logreg_c': 9.487947876530682e-10}. \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\britt\\Desktop\\YH\\Applicerad AI\\job_discrimination\\venv_job_discrimination\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "\u001b[32m[I 2022-12-20 16:55:16,718]\u001b[0m Trial 73 finished with values: [0.847457627118644, 0.5384615384615384, 0.0, 0.8333333333333334] and parameters: {'logreg_c': 0.1843286032655299}. \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5384615384615384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-12-20 16:55:17,138]\u001b[0m Trial 74 finished with values: [0.847457627118644, 0.5384615384615384, 0.0, 0.8333333333333334] and parameters: {'logreg_c': 18445.218902420882}. \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5384615384615384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-12-20 16:55:17,526]\u001b[0m Trial 75 finished with values: [0.847457627118644, 0.5384615384615384, 0.0, 0.8333333333333334] and parameters: {'logreg_c': 217217841.91781038}. \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5384615384615384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\britt\\Desktop\\YH\\Applicerad AI\\job_discrimination\\venv_job_discrimination\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\u001b[32m[I 2022-12-20 16:55:17,944]\u001b[0m Trial 76 finished with values: [0.5932203389830508, 0.0, 0.0, 0.6888888888888889] and parameters: {'logreg_c': 2.4588704497540336e-10}. \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\britt\\Desktop\\YH\\Applicerad AI\\job_discrimination\\venv_job_discrimination\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\u001b[32m[I 2022-12-20 16:55:18,407]\u001b[0m Trial 77 finished with values: [0.5932203389830508, 0.0, 0.0, 0.6888888888888889] and parameters: {'logreg_c': 1.7722573498511458e-05}. \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\britt\\Desktop\\YH\\Applicerad AI\\job_discrimination\\venv_job_discrimination\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "\u001b[32m[I 2022-12-20 16:55:19,292]\u001b[0m Trial 78 finished with values: [0.8418079096045198, 0.5833333333333334, 0.0, 0.84375] and parameters: {'logreg_c': 0.011294278439596834}. \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5833333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\britt\\Desktop\\YH\\Applicerad AI\\job_discrimination\\venv_job_discrimination\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\u001b[32m[I 2022-12-20 16:55:19,771]\u001b[0m Trial 79 finished with values: [0.5932203389830508, 0.0, 0.0, 0.6888888888888889] and parameters: {'logreg_c': 1.7002798900059656e-09}. \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-12-20 16:55:20,146]\u001b[0m Trial 80 finished with values: [0.847457627118644, 0.5384615384615384, 0.0, 0.8333333333333334] and parameters: {'logreg_c': 2385447081.776751}. \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5384615384615384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\britt\\Desktop\\YH\\Applicerad AI\\job_discrimination\\venv_job_discrimination\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\britt\\Desktop\\YH\\Applicerad AI\\job_discrimination\\venv_job_discrimination\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\u001b[32m[I 2022-12-20 16:55:20,927]\u001b[0m Trial 81 finished with values: [0.8305084745762712, 0.7, 0.0, 0.8285714285714286] and parameters: {'logreg_c': 0.001903549745852523}. \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-12-20 16:55:21,270]\u001b[0m Trial 82 finished with values: [0.847457627118644, 0.5384615384615384, 0.0, 0.8333333333333334] and parameters: {'logreg_c': 2617340.5738402}. \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5384615384615384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-12-20 16:55:21,616]\u001b[0m Trial 83 finished with values: [0.847457627118644, 0.5384615384615384, 0.0, 0.8333333333333334] and parameters: {'logreg_c': 74481398.13733858}. \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5384615384615384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-12-20 16:55:21,961]\u001b[0m Trial 84 finished with values: [0.847457627118644, 0.5384615384615384, 0.0, 0.8333333333333334] and parameters: {'logreg_c': 1280309.5918072662}. \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5384615384615384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\britt\\Desktop\\YH\\Applicerad AI\\job_discrimination\\venv_job_discrimination\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\u001b[32m[I 2022-12-20 16:55:22,461]\u001b[0m Trial 85 finished with values: [0.7514124293785311, 0.8333333333333334, 0.0, 0.7692307692307693] and parameters: {'logreg_c': 0.00029414416546105315}. \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8333333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-12-20 16:55:22,942]\u001b[0m Trial 86 finished with values: [0.847457627118644, 0.5384615384615384, 0.0, 0.8333333333333334] and parameters: {'logreg_c': 2532.324209747791}. \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5384615384615384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\britt\\Desktop\\YH\\Applicerad AI\\job_discrimination\\venv_job_discrimination\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\u001b[32m[I 2022-12-20 16:55:23,240]\u001b[0m Trial 87 finished with values: [0.5932203389830508, 0.0, 0.0, 0.6888888888888889] and parameters: {'logreg_c': 4.0395120117571813e-10}. \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-12-20 16:55:23,568]\u001b[0m Trial 88 finished with values: [0.847457627118644, 0.5384615384615384, 0.0, 0.8333333333333334] and parameters: {'logreg_c': 2359544.4799811128}. \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5384615384615384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\britt\\Desktop\\YH\\Applicerad AI\\job_discrimination\\venv_job_discrimination\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "\u001b[32m[I 2022-12-20 16:55:24,352]\u001b[0m Trial 89 finished with values: [0.847457627118644, 0.5384615384615384, 0.0, 0.8333333333333334] and parameters: {'logreg_c': 0.2736134495412584}. \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5384615384615384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-12-20 16:55:24,692]\u001b[0m Trial 90 finished with values: [0.847457627118644, 0.5384615384615384, 0.0, 0.8333333333333334] and parameters: {'logreg_c': 5812943.722095417}. \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5384615384615384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-12-20 16:55:25,268]\u001b[0m Trial 91 finished with values: [0.847457627118644, 0.5384615384615384, 0.0, 0.8333333333333334] and parameters: {'logreg_c': 299284623.4510366}. \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5384615384615384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\britt\\Desktop\\YH\\Applicerad AI\\job_discrimination\\venv_job_discrimination\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "\u001b[32m[I 2022-12-20 16:55:26,031]\u001b[0m Trial 92 finished with values: [0.8305084745762712, 0.5833333333333334, 0.0, 0.84375] and parameters: {'logreg_c': 0.003914219645257656}. \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5833333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\britt\\Desktop\\YH\\Applicerad AI\\job_discrimination\\venv_job_discrimination\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "\u001b[32m[I 2022-12-20 16:55:26,855]\u001b[0m Trial 93 finished with values: [0.847457627118644, 0.5384615384615384, 0.0, 0.8333333333333334] and parameters: {'logreg_c': 1.2942781977142455}. \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5384615384615384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-12-20 16:55:27,216]\u001b[0m Trial 94 finished with values: [0.847457627118644, 0.5384615384615384, 0.0, 0.8333333333333334] and parameters: {'logreg_c': 2143972.6672931463}. \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5384615384615384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\britt\\Desktop\\YH\\Applicerad AI\\job_discrimination\\venv_job_discrimination\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "\u001b[32m[I 2022-12-20 16:55:27,982]\u001b[0m Trial 95 finished with values: [0.8361581920903954, 0.5833333333333334, 0.0, 0.84375] and parameters: {'logreg_c': 0.005470996752935094}. \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5833333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-12-20 16:55:28,370]\u001b[0m Trial 96 finished with values: [0.847457627118644, 0.5384615384615384, 0.0, 0.8333333333333334] and parameters: {'logreg_c': 187375169.15660498}. \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5384615384615384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-12-20 16:55:28,959]\u001b[0m Trial 97 finished with values: [0.8361581920903954, 0.5384615384615384, 0.0, 0.8333333333333334] and parameters: {'logreg_c': 767.8416748845608}. \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5384615384615384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\britt\\Desktop\\YH\\Applicerad AI\\job_discrimination\\venv_job_discrimination\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\u001b[32m[I 2022-12-20 16:55:29,336]\u001b[0m Trial 98 finished with values: [0.5932203389830508, 0.0, 0.0, 0.6888888888888889] and parameters: {'logreg_c': 1.9540212221814492e-06}. \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-12-20 16:55:29,696]\u001b[0m Trial 99 finished with values: [0.8531073446327683, 0.5384615384615384, 0.0, 0.8333333333333334] and parameters: {'logreg_c': 43439.53753760375}. \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5384615384615384\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Running it\n",
    "study = optuna.create_study(directions=[\"maximize\", \"maximize\", \"maximize\", \"maximize\"])\n",
    "study.optimize(objective, n_trials=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.853, Precision: 0.538, Recall: 0.0, F-score: 0.833\n",
      "Accuracy: 0.831, Precision: 0.636, Recall: 0.0, F-score: 0.848\n",
      "Accuracy: 0.853, Precision: 0.538, Recall: 0.0, F-score: 0.833\n",
      "Accuracy: 0.853, Precision: 0.538, Recall: 0.0, F-score: 0.833\n",
      "Accuracy: 0.853, Precision: 0.538, Recall: 0.0, F-score: 0.833\n",
      "Accuracy: 0.853, Precision: 0.538, Recall: 0.0, F-score: 0.833\n",
      "Accuracy: 0.853, Precision: 0.538, Recall: 0.0, F-score: 0.833\n",
      "Accuracy: 0.853, Precision: 0.538, Recall: 0.0, F-score: 0.833\n",
      "Accuracy: 0.842, Precision: 0.583, Recall: 0.0, F-score: 0.844\n",
      "Accuracy: 0.831, Precision: 0.7, Recall: 0.0, F-score: 0.829\n",
      "Accuracy: 0.751, Precision: 0.833, Recall: 0.0, F-score: 0.769\n",
      "Accuracy: 0.853, Precision: 0.538, Recall: 0.0, F-score: 0.833\n"
     ]
    }
   ],
   "source": [
    "for trial in study.best_trials:\n",
    "    print(f\"Accuracy: {round(trial.values[0], 3)}, Precision: {round(trial.values[1], 3)}, Recall: {round(trial.values[2], 3)}, F-score: {round(trial.values[3], 3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "A single best trial cannot be retrieved from a multi-objective study. Consider using Study.best_trials to retrieve a list containing the best trials.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[430], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m study\u001b[39m.\u001b[39;49mbest_value\n",
      "File \u001b[1;32mc:\\Users\\britt\\Desktop\\YH\\Applicerad AI\\job_discrimination\\venv_job_discrimination\\lib\\site-packages\\optuna\\study\\study.py:125\u001b[0m, in \u001b[0;36mStudy.best_value\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[39m@property\u001b[39m\n\u001b[0;32m    114\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mbest_value\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mfloat\u001b[39m:\n\u001b[0;32m    115\u001b[0m     \u001b[39m\"\"\"Return the best objective value in the study.\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \n\u001b[0;32m    117\u001b[0m \u001b[39m    .. note::\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    122\u001b[0m \n\u001b[0;32m    123\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 125\u001b[0m     best_value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbest_trial\u001b[39m.\u001b[39mvalue\n\u001b[0;32m    126\u001b[0m     \u001b[39massert\u001b[39;00m best_value \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    128\u001b[0m     \u001b[39mreturn\u001b[39;00m best_value\n",
      "File \u001b[1;32mc:\\Users\\britt\\Desktop\\YH\\Applicerad AI\\job_discrimination\\venv_job_discrimination\\lib\\site-packages\\optuna\\study\\study.py:149\u001b[0m, in \u001b[0;36mStudy.best_trial\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    132\u001b[0m \u001b[39m\"\"\"Return the best trial in the study.\u001b[39;00m\n\u001b[0;32m    133\u001b[0m \n\u001b[0;32m    134\u001b[0m \u001b[39m.. note::\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    145\u001b[0m \n\u001b[0;32m    146\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    148\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_multi_objective():\n\u001b[1;32m--> 149\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[0;32m    150\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mA single best trial cannot be retrieved from a multi-objective study. Consider \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    151\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39musing Study.best_trials to retrieve a list containing the best trials.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    152\u001b[0m     )\n\u001b[0;32m    154\u001b[0m \u001b[39mreturn\u001b[39;00m copy\u001b[39m.\u001b[39mdeepcopy(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_storage\u001b[39m.\u001b[39mget_best_trial(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_study_id))\n",
      "\u001b[1;31mRuntimeError\u001b[0m: A single best trial cannot be retrieved from a multi-objective study. Consider using Study.best_trials to retrieve a list containing the best trials."
     ]
    }
   ],
   "source": [
    "study.best_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "A single best trial cannot be retrieved from a multi-objective study. Consider using Study.best_trials to retrieve a list containing the best trials.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[431], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m study\u001b[39m.\u001b[39;49mbest_params\n",
      "File \u001b[1;32mc:\\Users\\britt\\Desktop\\YH\\Applicerad AI\\job_discrimination\\venv_job_discrimination\\lib\\site-packages\\optuna\\study\\study.py:111\u001b[0m, in \u001b[0;36mStudy.best_params\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[39m@property\u001b[39m\n\u001b[0;32m    100\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mbest_params\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Dict[\u001b[39mstr\u001b[39m, Any]:\n\u001b[0;32m    101\u001b[0m     \u001b[39m\"\"\"Return parameters of the best trial in the study.\u001b[39;00m\n\u001b[0;32m    102\u001b[0m \n\u001b[0;32m    103\u001b[0m \u001b[39m    .. note::\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    108\u001b[0m \n\u001b[0;32m    109\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 111\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbest_trial\u001b[39m.\u001b[39mparams\n",
      "File \u001b[1;32mc:\\Users\\britt\\Desktop\\YH\\Applicerad AI\\job_discrimination\\venv_job_discrimination\\lib\\site-packages\\optuna\\study\\study.py:149\u001b[0m, in \u001b[0;36mStudy.best_trial\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    132\u001b[0m \u001b[39m\"\"\"Return the best trial in the study.\u001b[39;00m\n\u001b[0;32m    133\u001b[0m \n\u001b[0;32m    134\u001b[0m \u001b[39m.. note::\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    145\u001b[0m \n\u001b[0;32m    146\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    148\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_multi_objective():\n\u001b[1;32m--> 149\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[0;32m    150\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mA single best trial cannot be retrieved from a multi-objective study. Consider \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    151\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39musing Study.best_trials to retrieve a list containing the best trials.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    152\u001b[0m     )\n\u001b[0;32m    154\u001b[0m \u001b[39mreturn\u001b[39;00m copy\u001b[39m.\u001b[39mdeepcopy(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_storage\u001b[39m.\u001b[39mget_best_trial(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_study_id))\n",
      "\u001b[1;31mRuntimeError\u001b[0m: A single best trial cannot be retrieved from a multi-objective study. Consider using Study.best_trials to retrieve a list containing the best trials."
     ]
    }
   ],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "\n",
    "    classifier_name = trial.suggest_categorical(\"classifier\", [\"LogReg\", \"RandomForest\", \"SVC\"])\n",
    "    \n",
    "    # Step 2. Setup values for the hyperparameters:\n",
    "    if classifier_name == 'LogReg':\n",
    "        #logreg_penalty = trial.suggest_categorical(\"logreg_penalty\", [\"l2\", None])\n",
    "        #logreg_tol = trial.suggest_float(\"logreg_tol\", 1e-5, 1, log=True)\n",
    "        logreg_c = trial.suggest_float(\"logreg_c\", 1e-10, 1e10, log=True)\n",
    "        logreg_c_weight = trial.suggest_categorical(\"logreg_c_weight\", [\"balanced\", None])\n",
    "        #logreg_max_iter = trial.suggest_int(\"logreg_max_iter\", 100, 300)\n",
    "        #logreg_warm_start = trial.suggest_categorical(\"logreg_warm_start\", [True, False])\n",
    "        classifier_obj = LogisticRegression(C=logreg_c, class_weight=logreg_c_weight)\n",
    "    elif classifier_name == \"RandomForest\":\n",
    "    #else:\n",
    "        rf_n_estimators = trial.suggest_int(\"rf_n_estimators\", 10, 1000)\n",
    "        rf_max_depth = trial.suggest_int(\"rf_max_depth\", 2, 32, log=True)\n",
    "        classifier_obj = RandomForestClassifier(max_depth=rf_max_depth, n_estimators=rf_n_estimators)\n",
    "    else:\n",
    "        svc_c = trial.suggest_float('svc_c', 1e-10, 1e10, log=True)\n",
    "        classifier_obj = SVC(C=svc_c, gamma='auto')\n",
    "\n",
    "    # Step 3: Scoring method:\n",
    "    score = cross_val_score(classifier_obj, X, y, n_jobs=-1, cv=3)\n",
    "    accuracy = score.mean()\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-12-20 16:35:29,071]\u001b[0m A new study created in memory with name: no-name-5f7a6b49-5dca-4c05-a682-6b23ce077a48\u001b[0m\n",
      "\u001b[32m[I 2022-12-20 16:35:29,640]\u001b[0m Trial 0 finished with value: 0.768361581920904 and parameters: {'classifier': 'RandomForest', 'rf_n_estimators': 228, 'rf_max_depth': 20}. Best is trial 0 with value: 0.768361581920904.\u001b[0m\n",
      "\u001b[32m[I 2022-12-20 16:35:29,811]\u001b[0m Trial 1 finished with value: 0.824858757062147 and parameters: {'classifier': 'SVC', 'svc_c': 34.88232710107524}. Best is trial 1 with value: 0.824858757062147.\u001b[0m\n",
      "\u001b[32m[I 2022-12-20 16:35:29,982]\u001b[0m Trial 2 finished with value: 0.824858757062147 and parameters: {'classifier': 'SVC', 'svc_c': 59111.98221912591}. Best is trial 1 with value: 0.824858757062147.\u001b[0m\n",
      "\u001b[32m[I 2022-12-20 16:35:31,259]\u001b[0m Trial 3 finished with value: 0.7570621468926554 and parameters: {'classifier': 'RandomForest', 'rf_n_estimators': 751, 'rf_max_depth': 7}. Best is trial 1 with value: 0.824858757062147.\u001b[0m\n",
      "\u001b[32m[I 2022-12-20 16:35:32,595]\u001b[0m Trial 4 finished with value: 0.7570621468926554 and parameters: {'classifier': 'RandomForest', 'rf_n_estimators': 820, 'rf_max_depth': 9}. Best is trial 1 with value: 0.824858757062147.\u001b[0m\n",
      "\u001b[32m[I 2022-12-20 16:35:32,843]\u001b[0m Trial 5 finished with value: 0.847457627118644 and parameters: {'classifier': 'LogReg', 'logreg_c': 3944935304.1515617, 'logreg_c_weight': 'balanced'}. Best is trial 5 with value: 0.847457627118644.\u001b[0m\n",
      "\u001b[32m[I 2022-12-20 16:35:33,045]\u001b[0m Trial 6 finished with value: 0.3559322033898305 and parameters: {'classifier': 'LogReg', 'logreg_c': 1.0806164309063599e-10, 'logreg_c_weight': 'balanced'}. Best is trial 5 with value: 0.847457627118644.\u001b[0m\n",
      "\u001b[32m[I 2022-12-20 16:35:33,215]\u001b[0m Trial 7 finished with value: 0.824858757062147 and parameters: {'classifier': 'SVC', 'svc_c': 629834613.7158284}. Best is trial 5 with value: 0.847457627118644.\u001b[0m\n",
      "\u001b[32m[I 2022-12-20 16:35:33,634]\u001b[0m Trial 8 finished with value: 0.8305084745762712 and parameters: {'classifier': 'LogReg', 'logreg_c': 0.00394356734596097, 'logreg_c_weight': 'balanced'}. Best is trial 5 with value: 0.847457627118644.\u001b[0m\n",
      "\u001b[32m[I 2022-12-20 16:35:33,836]\u001b[0m Trial 9 finished with value: 0.5932203389830508 and parameters: {'classifier': 'LogReg', 'logreg_c': 1.301831063559409e-10, 'logreg_c_weight': None}. Best is trial 5 with value: 0.847457627118644.\u001b[0m\n",
      "\u001b[32m[I 2022-12-20 16:35:34,055]\u001b[0m Trial 10 finished with value: 0.847457627118644 and parameters: {'classifier': 'LogReg', 'logreg_c': 1628788859.6956406, 'logreg_c_weight': 'balanced'}. Best is trial 5 with value: 0.847457627118644.\u001b[0m\n",
      "\u001b[32m[I 2022-12-20 16:35:34,274]\u001b[0m Trial 11 finished with value: 0.847457627118644 and parameters: {'classifier': 'LogReg', 'logreg_c': 7854604245.23384, 'logreg_c_weight': 'balanced'}. Best is trial 5 with value: 0.847457627118644.\u001b[0m\n",
      "\u001b[32m[I 2022-12-20 16:35:34,525]\u001b[0m Trial 12 finished with value: 0.847457627118644 and parameters: {'classifier': 'LogReg', 'logreg_c': 9521497856.316195, 'logreg_c_weight': 'balanced'}. Best is trial 5 with value: 0.847457627118644.\u001b[0m\n",
      "\u001b[32m[I 2022-12-20 16:35:34,742]\u001b[0m Trial 13 finished with value: 0.8531073446327683 and parameters: {'classifier': 'LogReg', 'logreg_c': 24142.193004171368, 'logreg_c_weight': 'balanced'}. Best is trial 13 with value: 0.8531073446327683.\u001b[0m\n",
      "\u001b[32m[I 2022-12-20 16:35:35,037]\u001b[0m Trial 14 finished with value: 0.847457627118644 and parameters: {'classifier': 'LogReg', 'logreg_c': 2988.6437208131397, 'logreg_c_weight': None}. Best is trial 13 with value: 0.8531073446327683.\u001b[0m\n",
      "\u001b[32m[I 2022-12-20 16:35:35,285]\u001b[0m Trial 15 finished with value: 0.8361581920903954 and parameters: {'classifier': 'LogReg', 'logreg_c': 6655.013382953869, 'logreg_c_weight': 'balanced'}. Best is trial 13 with value: 0.8531073446327683.\u001b[0m\n",
      "\u001b[32m[I 2022-12-20 16:35:35,549]\u001b[0m Trial 16 finished with value: 0.8361581920903954 and parameters: {'classifier': 'LogReg', 'logreg_c': 3248.8019462370166, 'logreg_c_weight': 'balanced'}. Best is trial 13 with value: 0.8531073446327683.\u001b[0m\n",
      "\u001b[32m[I 2022-12-20 16:35:35,828]\u001b[0m Trial 17 finished with value: 0.847457627118644 and parameters: {'classifier': 'LogReg', 'logreg_c': 2214.6289149300533, 'logreg_c_weight': None}. Best is trial 13 with value: 0.8531073446327683.\u001b[0m\n",
      "\u001b[32m[I 2022-12-20 16:35:35,983]\u001b[0m Trial 18 finished with value: 0.5932203389830508 and parameters: {'classifier': 'SVC', 'svc_c': 5.572109406409624e-09}. Best is trial 13 with value: 0.8531073446327683.\u001b[0m\n",
      "\u001b[32m[I 2022-12-20 16:35:36,201]\u001b[0m Trial 19 finished with value: 0.6949152542372881 and parameters: {'classifier': 'RandomForest', 'rf_n_estimators': 28, 'rf_max_depth': 2}. Best is trial 13 with value: 0.8531073446327683.\u001b[0m\n",
      "\u001b[32m[I 2022-12-20 16:35:36,450]\u001b[0m Trial 20 finished with value: 0.847457627118644 and parameters: {'classifier': 'LogReg', 'logreg_c': 2956494.529656202, 'logreg_c_weight': 'balanced'}. Best is trial 13 with value: 0.8531073446327683.\u001b[0m\n",
      "\u001b[32m[I 2022-12-20 16:35:36,884]\u001b[0m Trial 21 finished with value: 0.847457627118644 and parameters: {'classifier': 'LogReg', 'logreg_c': 0.1423806008343106, 'logreg_c_weight': None}. Best is trial 13 with value: 0.8531073446327683.\u001b[0m\n",
      "\u001b[32m[I 2022-12-20 16:35:37,103]\u001b[0m Trial 22 finished with value: 0.847457627118644 and parameters: {'classifier': 'LogReg', 'logreg_c': 2894242.83759495, 'logreg_c_weight': None}. Best is trial 13 with value: 0.8531073446327683.\u001b[0m\n",
      "\u001b[32m[I 2022-12-20 16:35:37,336]\u001b[0m Trial 23 finished with value: 0.847457627118644 and parameters: {'classifier': 'LogReg', 'logreg_c': 8056745.528966752, 'logreg_c_weight': 'balanced'}. Best is trial 13 with value: 0.8531073446327683.\u001b[0m\n",
      "\u001b[32m[I 2022-12-20 16:35:37,740]\u001b[0m Trial 24 finished with value: 0.8418079096045198 and parameters: {'classifier': 'LogReg', 'logreg_c': 0.011527050731719952, 'logreg_c_weight': None}. Best is trial 13 with value: 0.8531073446327683.\u001b[0m\n",
      "\u001b[32m[I 2022-12-20 16:35:37,989]\u001b[0m Trial 25 finished with value: 0.847457627118644 and parameters: {'classifier': 'LogReg', 'logreg_c': 2610369.660414241, 'logreg_c_weight': None}. Best is trial 13 with value: 0.8531073446327683.\u001b[0m\n",
      "\u001b[32m[I 2022-12-20 16:35:38,236]\u001b[0m Trial 26 finished with value: 0.847457627118644 and parameters: {'classifier': 'LogReg', 'logreg_c': 4398896.900050632, 'logreg_c_weight': 'balanced'}. Best is trial 13 with value: 0.8531073446327683.\u001b[0m\n",
      "\u001b[32m[I 2022-12-20 16:35:38,671]\u001b[0m Trial 27 finished with value: 0.847457627118644 and parameters: {'classifier': 'LogReg', 'logreg_c': 4.35587305465766, 'logreg_c_weight': None}. Best is trial 13 with value: 0.8531073446327683.\u001b[0m\n",
      "\u001b[32m[I 2022-12-20 16:35:38,827]\u001b[0m Trial 28 finished with value: 0.5932203389830508 and parameters: {'classifier': 'SVC', 'svc_c': 2.063076433562489e-10}. Best is trial 13 with value: 0.8531073446327683.\u001b[0m\n",
      "\u001b[32m[I 2022-12-20 16:35:39,495]\u001b[0m Trial 29 finished with value: 0.7005649717514125 and parameters: {'classifier': 'RandomForest', 'rf_n_estimators': 433, 'rf_max_depth': 2}. Best is trial 13 with value: 0.8531073446327683.\u001b[0m\n",
      "\u001b[32m[I 2022-12-20 16:35:41,125]\u001b[0m Trial 30 finished with value: 0.7627118644067797 and parameters: {'classifier': 'RandomForest', 'rf_n_estimators': 1000, 'rf_max_depth': 26}. Best is trial 13 with value: 0.8531073446327683.\u001b[0m\n",
      "\u001b[32m[I 2022-12-20 16:35:41,358]\u001b[0m Trial 31 finished with value: 0.8531073446327683 and parameters: {'classifier': 'LogReg', 'logreg_c': 41198.58948395069, 'logreg_c_weight': None}. Best is trial 13 with value: 0.8531073446327683.\u001b[0m\n",
      "\u001b[32m[I 2022-12-20 16:35:41,761]\u001b[0m Trial 32 finished with value: 0.847457627118644 and parameters: {'classifier': 'LogReg', 'logreg_c': 33.867718065460146, 'logreg_c_weight': None}. Best is trial 13 with value: 0.8531073446327683.\u001b[0m\n",
      "\u001b[32m[I 2022-12-20 16:35:41,995]\u001b[0m Trial 33 finished with value: 0.8531073446327683 and parameters: {'classifier': 'LogReg', 'logreg_c': 49798.8731941565, 'logreg_c_weight': None}. Best is trial 13 with value: 0.8531073446327683.\u001b[0m\n",
      "\u001b[32m[I 2022-12-20 16:35:42,165]\u001b[0m Trial 34 finished with value: 0.5932203389830508 and parameters: {'classifier': 'SVC', 'svc_c': 6.696935094752906e-05}. Best is trial 13 with value: 0.8531073446327683.\u001b[0m\n",
      "\u001b[32m[I 2022-12-20 16:35:42,478]\u001b[0m Trial 35 finished with value: 0.8361581920903954 and parameters: {'classifier': 'LogReg', 'logreg_c': 878.858618649744, 'logreg_c_weight': None}. Best is trial 13 with value: 0.8531073446327683.\u001b[0m\n",
      "\u001b[32m[I 2022-12-20 16:35:42,698]\u001b[0m Trial 36 finished with value: 0.847457627118644 and parameters: {'classifier': 'LogReg', 'logreg_c': 169735.35553640206, 'logreg_c_weight': None}. Best is trial 13 with value: 0.8531073446327683.\u001b[0m\n",
      "\u001b[32m[I 2022-12-20 16:35:43,500]\u001b[0m Trial 37 finished with value: 0.7514124293785311 and parameters: {'classifier': 'RandomForest', 'rf_n_estimators': 520, 'rf_max_depth': 4}. Best is trial 13 with value: 0.8531073446327683.\u001b[0m\n",
      "\u001b[32m[I 2022-12-20 16:35:43,901]\u001b[0m Trial 38 finished with value: 0.847457627118644 and parameters: {'classifier': 'LogReg', 'logreg_c': 103.17543744462469, 'logreg_c_weight': None}. Best is trial 13 with value: 0.8531073446327683.\u001b[0m\n",
      "\u001b[32m[I 2022-12-20 16:35:44,071]\u001b[0m Trial 39 finished with value: 0.5932203389830508 and parameters: {'classifier': 'SVC', 'svc_c': 0.0023932243833863385}. Best is trial 13 with value: 0.8531073446327683.\u001b[0m\n",
      "\u001b[32m[I 2022-12-20 16:35:44,489]\u001b[0m Trial 40 finished with value: 0.847457627118644 and parameters: {'classifier': 'LogReg', 'logreg_c': 40.14824085645901, 'logreg_c_weight': None}. Best is trial 13 with value: 0.8531073446327683.\u001b[0m\n",
      "\u001b[32m[I 2022-12-20 16:35:44,753]\u001b[0m Trial 41 finished with value: 0.847457627118644 and parameters: {'classifier': 'LogReg', 'logreg_c': 149305.4102538748, 'logreg_c_weight': None}. Best is trial 13 with value: 0.8531073446327683.\u001b[0m\n",
      "\u001b[32m[I 2022-12-20 16:35:44,987]\u001b[0m Trial 42 finished with value: 0.8531073446327683 and parameters: {'classifier': 'LogReg', 'logreg_c': 57448.965402050526, 'logreg_c_weight': None}. Best is trial 13 with value: 0.8531073446327683.\u001b[0m\n",
      "\u001b[32m[I 2022-12-20 16:35:45,206]\u001b[0m Trial 43 finished with value: 0.847457627118644 and parameters: {'classifier': 'LogReg', 'logreg_c': 87548.35239147862, 'logreg_c_weight': None}. Best is trial 13 with value: 0.8531073446327683.\u001b[0m\n",
      "\u001b[32m[I 2022-12-20 16:35:45,628]\u001b[0m Trial 44 finished with value: 0.847457627118644 and parameters: {'classifier': 'LogReg', 'logreg_c': 0.43586819336418176, 'logreg_c_weight': None}. Best is trial 13 with value: 0.8531073446327683.\u001b[0m\n",
      "\u001b[32m[I 2022-12-20 16:35:45,875]\u001b[0m Trial 45 finished with value: 0.847457627118644 and parameters: {'classifier': 'LogReg', 'logreg_c': 117413067.80973445, 'logreg_c_weight': None}. Best is trial 13 with value: 0.8531073446327683.\u001b[0m\n",
      "\u001b[32m[I 2022-12-20 16:35:46,091]\u001b[0m Trial 46 finished with value: 0.847457627118644 and parameters: {'classifier': 'LogReg', 'logreg_c': 122994690.51143208, 'logreg_c_weight': None}. Best is trial 13 with value: 0.8531073446327683.\u001b[0m\n",
      "\u001b[32m[I 2022-12-20 16:35:46,309]\u001b[0m Trial 47 finished with value: 0.847457627118644 and parameters: {'classifier': 'LogReg', 'logreg_c': 47334818.49827045, 'logreg_c_weight': 'balanced'}. Best is trial 13 with value: 0.8531073446327683.\u001b[0m\n",
      "\u001b[32m[I 2022-12-20 16:35:46,527]\u001b[0m Trial 48 finished with value: 0.847457627118644 and parameters: {'classifier': 'LogReg', 'logreg_c': 65398.9090379209, 'logreg_c_weight': None}. Best is trial 13 with value: 0.8531073446327683.\u001b[0m\n",
      "\u001b[32m[I 2022-12-20 16:35:46,731]\u001b[0m Trial 49 finished with value: 0.7853107344632768 and parameters: {'classifier': 'RandomForest', 'rf_n_estimators': 13, 'rf_max_depth': 13}. Best is trial 13 with value: 0.8531073446327683.\u001b[0m\n",
      "\u001b[32m[I 2022-12-20 16:35:46,995]\u001b[0m Trial 50 finished with value: 0.6836158192090395 and parameters: {'classifier': 'LogReg', 'logreg_c': 9.742896660317474e-05, 'logreg_c_weight': None}. Best is trial 13 with value: 0.8531073446327683.\u001b[0m\n",
      "\u001b[32m[I 2022-12-20 16:35:47,212]\u001b[0m Trial 51 finished with value: 0.847457627118644 and parameters: {'classifier': 'LogReg', 'logreg_c': 264376.40306145546, 'logreg_c_weight': 'balanced'}. Best is trial 13 with value: 0.8531073446327683.\u001b[0m\n",
      "\u001b[32m[I 2022-12-20 16:35:47,430]\u001b[0m Trial 52 finished with value: 0.847457627118644 and parameters: {'classifier': 'LogReg', 'logreg_c': 3829999.383797703, 'logreg_c_weight': 'balanced'}. Best is trial 13 with value: 0.8531073446327683.\u001b[0m\n",
      "\u001b[32m[I 2022-12-20 16:35:47,680]\u001b[0m Trial 53 finished with value: 0.847457627118644 and parameters: {'classifier': 'LogReg', 'logreg_c': 1008430.4540437098, 'logreg_c_weight': 'balanced'}. Best is trial 13 with value: 0.8531073446327683.\u001b[0m\n",
      "\u001b[32m[I 2022-12-20 16:35:47,897]\u001b[0m Trial 54 finished with value: 0.8531073446327683 and parameters: {'classifier': 'LogReg', 'logreg_c': 19647.80055749694, 'logreg_c_weight': 'balanced'}. Best is trial 13 with value: 0.8531073446327683.\u001b[0m\n",
      "\u001b[32m[I 2022-12-20 16:35:48,115]\u001b[0m Trial 55 finished with value: 0.8531073446327683 and parameters: {'classifier': 'LogReg', 'logreg_c': 22380.338137516064, 'logreg_c_weight': 'balanced'}. Best is trial 13 with value: 0.8531073446327683.\u001b[0m\n",
      "\u001b[32m[I 2022-12-20 16:35:48,286]\u001b[0m Trial 56 finished with value: 0.824858757062147 and parameters: {'classifier': 'SVC', 'svc_c': 6029107076.843349}. Best is trial 13 with value: 0.8531073446327683.\u001b[0m\n",
      "\u001b[32m[I 2022-12-20 16:35:48,489]\u001b[0m Trial 57 finished with value: 0.8531073446327683 and parameters: {'classifier': 'LogReg', 'logreg_c': 17890.233279844404, 'logreg_c_weight': 'balanced'}. Best is trial 13 with value: 0.8531073446327683.\u001b[0m\n",
      "\u001b[32m[I 2022-12-20 16:35:48,816]\u001b[0m Trial 58 finished with value: 0.8418079096045198 and parameters: {'classifier': 'LogReg', 'logreg_c': 781.3825676904013, 'logreg_c_weight': 'balanced'}. Best is trial 13 with value: 0.8531073446327683.\u001b[0m\n",
      "\u001b[32m[I 2022-12-20 16:35:49,049]\u001b[0m Trial 59 finished with value: 0.8531073446327683 and parameters: {'classifier': 'LogReg', 'logreg_c': 16909.60754030131, 'logreg_c_weight': 'balanced'}. Best is trial 13 with value: 0.8531073446327683.\u001b[0m\n",
      "\u001b[32m[I 2022-12-20 16:35:49,234]\u001b[0m Trial 60 finished with value: 0.3559322033898305 and parameters: {'classifier': 'LogReg', 'logreg_c': 4.68819085926028e-09, 'logreg_c_weight': 'balanced'}. Best is trial 13 with value: 0.8531073446327683.\u001b[0m\n",
      "\u001b[32m[I 2022-12-20 16:35:49,468]\u001b[0m Trial 61 finished with value: 0.8531073446327683 and parameters: {'classifier': 'LogReg', 'logreg_c': 10721.52717615596, 'logreg_c_weight': 'balanced'}. Best is trial 13 with value: 0.8531073446327683.\u001b[0m\n",
      "\u001b[32m[I 2022-12-20 16:35:49,733]\u001b[0m Trial 62 finished with value: 0.8531073446327683 and parameters: {'classifier': 'LogReg', 'logreg_c': 11312.517306668982, 'logreg_c_weight': 'balanced'}. Best is trial 13 with value: 0.8531073446327683.\u001b[0m\n",
      "\u001b[32m[I 2022-12-20 16:35:50,077]\u001b[0m Trial 63 finished with value: 0.8418079096045198 and parameters: {'classifier': 'LogReg', 'logreg_c': 271.8932450096806, 'logreg_c_weight': 'balanced'}. Best is trial 13 with value: 0.8531073446327683.\u001b[0m\n",
      "\u001b[32m[I 2022-12-20 16:35:50,465]\u001b[0m Trial 64 finished with value: 0.8418079096045198 and parameters: {'classifier': 'LogReg', 'logreg_c': 7.0548128259100995, 'logreg_c_weight': 'balanced'}. Best is trial 13 with value: 0.8531073446327683.\u001b[0m\n",
      "\u001b[32m[I 2022-12-20 16:35:50,713]\u001b[0m Trial 65 finished with value: 0.8531073446327683 and parameters: {'classifier': 'LogReg', 'logreg_c': 22543.97893257324, 'logreg_c_weight': 'balanced'}. Best is trial 13 with value: 0.8531073446327683.\u001b[0m\n",
      "\u001b[32m[I 2022-12-20 16:35:51,024]\u001b[0m Trial 66 finished with value: 0.8418079096045198 and parameters: {'classifier': 'LogReg', 'logreg_c': 2327.596632304979, 'logreg_c_weight': 'balanced'}. Best is trial 13 with value: 0.8531073446327683.\u001b[0m\n",
      "\u001b[32m[I 2022-12-20 16:35:51,911]\u001b[0m Trial 67 finished with value: 0.7344632768361583 and parameters: {'classifier': 'RandomForest', 'rf_n_estimators': 477, 'rf_max_depth': 4}. Best is trial 13 with value: 0.8531073446327683.\u001b[0m\n",
      "\u001b[32m[I 2022-12-20 16:35:52,172]\u001b[0m Trial 68 finished with value: 0.847457627118644 and parameters: {'classifier': 'LogReg', 'logreg_c': 517563.6295903657, 'logreg_c_weight': 'balanced'}. Best is trial 13 with value: 0.8531073446327683.\u001b[0m\n",
      "\u001b[32m[I 2022-12-20 16:35:52,358]\u001b[0m Trial 69 finished with value: 0.824858757062147 and parameters: {'classifier': 'SVC', 'svc_c': 17592.726859712726}. Best is trial 13 with value: 0.8531073446327683.\u001b[0m\n",
      "\u001b[32m[I 2022-12-20 16:35:52,620]\u001b[0m Trial 70 finished with value: 0.8531073446327683 and parameters: {'classifier': 'LogReg', 'logreg_c': 6161.036782540227, 'logreg_c_weight': 'balanced'}. Best is trial 13 with value: 0.8531073446327683.\u001b[0m\n",
      "\u001b[32m[I 2022-12-20 16:35:52,899]\u001b[0m Trial 71 finished with value: 0.8531073446327683 and parameters: {'classifier': 'LogReg', 'logreg_c': 16056.64432556908, 'logreg_c_weight': 'balanced'}. Best is trial 13 with value: 0.8531073446327683.\u001b[0m\n",
      "\u001b[32m[I 2022-12-20 16:35:53,209]\u001b[0m Trial 72 finished with value: 0.847457627118644 and parameters: {'classifier': 'LogReg', 'logreg_c': 7348.513033328982, 'logreg_c_weight': 'balanced'}. Best is trial 13 with value: 0.8531073446327683.\u001b[0m\n",
      "\u001b[32m[I 2022-12-20 16:35:53,472]\u001b[0m Trial 73 finished with value: 0.847457627118644 and parameters: {'classifier': 'LogReg', 'logreg_c': 18543957.955992647, 'logreg_c_weight': 'balanced'}. Best is trial 13 with value: 0.8531073446327683.\u001b[0m\n",
      "\u001b[32m[I 2022-12-20 16:35:53,878]\u001b[0m Trial 74 finished with value: 0.8418079096045198 and parameters: {'classifier': 'LogReg', 'logreg_c': 352.8719407232066, 'logreg_c_weight': 'balanced'}. Best is trial 13 with value: 0.8531073446327683.\u001b[0m\n",
      "\u001b[32m[I 2022-12-20 16:35:54,203]\u001b[0m Trial 75 finished with value: 0.8418079096045198 and parameters: {'classifier': 'LogReg', 'logreg_c': 5012.076247858971, 'logreg_c_weight': 'balanced'}. Best is trial 13 with value: 0.8531073446327683.\u001b[0m\n",
      "\u001b[32m[I 2022-12-20 16:35:54,422]\u001b[0m Trial 76 finished with value: 0.847457627118644 and parameters: {'classifier': 'LogReg', 'logreg_c': 29939.38987274841, 'logreg_c_weight': 'balanced'}. Best is trial 13 with value: 0.8531073446327683.\u001b[0m\n",
      "\u001b[32m[I 2022-12-20 16:35:54,640]\u001b[0m Trial 77 finished with value: 0.847457627118644 and parameters: {'classifier': 'LogReg', 'logreg_c': 726051.7571095609, 'logreg_c_weight': 'balanced'}. Best is trial 13 with value: 0.8531073446327683.\u001b[0m\n",
      "\u001b[32m[I 2022-12-20 16:35:55,012]\u001b[0m Trial 78 finished with value: 0.8418079096045198 and parameters: {'classifier': 'LogReg', 'logreg_c': 699.9361691681088, 'logreg_c_weight': 'balanced'}. Best is trial 13 with value: 0.8531073446327683.\u001b[0m\n",
      "\u001b[32m[I 2022-12-20 16:35:55,259]\u001b[0m Trial 79 finished with value: 0.847457627118644 and parameters: {'classifier': 'LogReg', 'logreg_c': 124623.92342141861, 'logreg_c_weight': None}. Best is trial 13 with value: 0.8531073446327683.\u001b[0m\n",
      "\u001b[32m[I 2022-12-20 16:35:55,726]\u001b[0m Trial 80 finished with value: 0.7288135593220338 and parameters: {'classifier': 'RandomForest', 'rf_n_estimators': 239, 'rf_max_depth': 4}. Best is trial 13 with value: 0.8531073446327683.\u001b[0m\n",
      "\u001b[32m[I 2022-12-20 16:35:56,089]\u001b[0m Trial 81 finished with value: 0.8361581920903954 and parameters: {'classifier': 'LogReg', 'logreg_c': 3099.857112867351, 'logreg_c_weight': 'balanced'}. Best is trial 13 with value: 0.8531073446327683.\u001b[0m\n",
      "\u001b[32m[I 2022-12-20 16:35:56,322]\u001b[0m Trial 82 finished with value: 0.847457627118644 and parameters: {'classifier': 'LogReg', 'logreg_c': 29229.28773724256, 'logreg_c_weight': 'balanced'}. Best is trial 13 with value: 0.8531073446327683.\u001b[0m\n",
      "\u001b[32m[I 2022-12-20 16:35:56,755]\u001b[0m Trial 83 finished with value: 0.8418079096045198 and parameters: {'classifier': 'LogReg', 'logreg_c': 132.98915052430416, 'logreg_c_weight': 'balanced'}. Best is trial 13 with value: 0.8531073446327683.\u001b[0m\n",
      "\u001b[32m[I 2022-12-20 16:35:56,988]\u001b[0m Trial 84 finished with value: 0.847457627118644 and parameters: {'classifier': 'LogReg', 'logreg_c': 426844.50152453315, 'logreg_c_weight': None}. Best is trial 13 with value: 0.8531073446327683.\u001b[0m\n",
      "\u001b[32m[I 2022-12-20 16:35:57,391]\u001b[0m Trial 85 finished with value: 0.8418079096045198 and parameters: {'classifier': 'LogReg', 'logreg_c': 10.039779210761363, 'logreg_c_weight': 'balanced'}. Best is trial 13 with value: 0.8531073446327683.\u001b[0m\n",
      "\u001b[32m[I 2022-12-20 16:35:57,608]\u001b[0m Trial 86 finished with value: 0.847457627118644 and parameters: {'classifier': 'LogReg', 'logreg_c': 39983.74986275572, 'logreg_c_weight': None}. Best is trial 13 with value: 0.8531073446327683.\u001b[0m\n",
      "\u001b[32m[I 2022-12-20 16:35:57,765]\u001b[0m Trial 87 finished with value: 0.5932203389830508 and parameters: {'classifier': 'SVC', 'svc_c': 5.62719430074182e-05}. Best is trial 13 with value: 0.8531073446327683.\u001b[0m\n",
      "\u001b[32m[I 2022-12-20 16:35:58,015]\u001b[0m Trial 88 finished with value: 0.8587570621468926 and parameters: {'classifier': 'LogReg', 'logreg_c': 8914.264350019694, 'logreg_c_weight': 'balanced'}. Best is trial 88 with value: 0.8587570621468926.\u001b[0m\n",
      "\u001b[32m[I 2022-12-20 16:35:58,250]\u001b[0m Trial 89 finished with value: 0.847457627118644 and parameters: {'classifier': 'LogReg', 'logreg_c': 846758320.2770513, 'logreg_c_weight': None}. Best is trial 88 with value: 0.8587570621468926.\u001b[0m\n",
      "\u001b[32m[I 2022-12-20 16:35:58,514]\u001b[0m Trial 90 finished with value: 0.8531073446327683 and parameters: {'classifier': 'LogReg', 'logreg_c': 9325.809920206006, 'logreg_c_weight': 'balanced'}. Best is trial 88 with value: 0.8587570621468926.\u001b[0m\n",
      "\u001b[32m[I 2022-12-20 16:35:58,901]\u001b[0m Trial 91 finished with value: 0.8418079096045198 and parameters: {'classifier': 'LogReg', 'logreg_c': 1207.6154441559945, 'logreg_c_weight': 'balanced'}. Best is trial 88 with value: 0.8587570621468926.\u001b[0m\n",
      "\u001b[32m[I 2022-12-20 16:35:59,167]\u001b[0m Trial 92 finished with value: 0.847457627118644 and parameters: {'classifier': 'LogReg', 'logreg_c': 80699.84392187052, 'logreg_c_weight': 'balanced'}. Best is trial 88 with value: 0.8587570621468926.\u001b[0m\n",
      "\u001b[32m[I 2022-12-20 16:35:59,508]\u001b[0m Trial 93 finished with value: 0.8587570621468926 and parameters: {'classifier': 'LogReg', 'logreg_c': 8197.955203313815, 'logreg_c_weight': 'balanced'}. Best is trial 88 with value: 0.8587570621468926.\u001b[0m\n",
      "\u001b[32m[I 2022-12-20 16:35:59,775]\u001b[0m Trial 94 finished with value: 0.847457627118644 and parameters: {'classifier': 'LogReg', 'logreg_c': 881454.7449985235, 'logreg_c_weight': None}. Best is trial 88 with value: 0.8587570621468926.\u001b[0m\n",
      "\u001b[32m[I 2022-12-20 16:36:00,073]\u001b[0m Trial 95 finished with value: 0.8531073446327683 and parameters: {'classifier': 'LogReg', 'logreg_c': 8792.29691203399, 'logreg_c_weight': 'balanced'}. Best is trial 88 with value: 0.8587570621468926.\u001b[0m\n",
      "\u001b[32m[I 2022-12-20 16:36:00,522]\u001b[0m Trial 96 finished with value: 0.847457627118644 and parameters: {'classifier': 'LogReg', 'logreg_c': 82.37249776933027, 'logreg_c_weight': None}. Best is trial 88 with value: 0.8587570621468926.\u001b[0m\n",
      "\u001b[32m[I 2022-12-20 16:36:00,836]\u001b[0m Trial 97 finished with value: 0.8418079096045198 and parameters: {'classifier': 'LogReg', 'logreg_c': 3061.5351245663583, 'logreg_c_weight': 'balanced'}. Best is trial 88 with value: 0.8587570621468926.\u001b[0m\n",
      "\u001b[32m[I 2022-12-20 16:36:01,270]\u001b[0m Trial 98 finished with value: 0.8418079096045198 and parameters: {'classifier': 'LogReg', 'logreg_c': 25.54868260345727, 'logreg_c_weight': 'balanced'}. Best is trial 88 with value: 0.8587570621468926.\u001b[0m\n",
      "\u001b[32m[I 2022-12-20 16:36:02,405]\u001b[0m Trial 99 finished with value: 0.7570621468926554 and parameters: {'classifier': 'RandomForest', 'rf_n_estimators': 657, 'rf_max_depth': 13}. Best is trial 88 with value: 0.8587570621468926.\u001b[0m\n",
      "\u001b[32m[I 2022-12-20 16:36:02,621]\u001b[0m Trial 100 finished with value: 0.847457627118644 and parameters: {'classifier': 'LogReg', 'logreg_c': 25801.551199800408, 'logreg_c_weight': 'balanced'}. Best is trial 88 with value: 0.8587570621468926.\u001b[0m\n",
      "\u001b[32m[I 2022-12-20 16:36:02,868]\u001b[0m Trial 101 finished with value: 0.847457627118644 and parameters: {'classifier': 'LogReg', 'logreg_c': 231340.57892916867, 'logreg_c_weight': 'balanced'}. Best is trial 88 with value: 0.8587570621468926.\u001b[0m\n",
      "\u001b[32m[I 2022-12-20 16:36:03,085]\u001b[0m Trial 102 finished with value: 0.847457627118644 and parameters: {'classifier': 'LogReg', 'logreg_c': 98617.04889953286, 'logreg_c_weight': 'balanced'}. Best is trial 88 with value: 0.8587570621468926.\u001b[0m\n",
      "\u001b[32m[I 2022-12-20 16:36:03,384]\u001b[0m Trial 103 finished with value: 0.8418079096045198 and parameters: {'classifier': 'LogReg', 'logreg_c': 1051.7438150320263, 'logreg_c_weight': 'balanced'}. Best is trial 88 with value: 0.8587570621468926.\u001b[0m\n",
      "\u001b[32m[I 2022-12-20 16:36:03,604]\u001b[0m Trial 104 finished with value: 0.847457627118644 and parameters: {'classifier': 'LogReg', 'logreg_c': 1653653.4409169185, 'logreg_c_weight': None}. Best is trial 88 with value: 0.8587570621468926.\u001b[0m\n",
      "\u001b[32m[I 2022-12-20 16:36:03,774]\u001b[0m Trial 105 finished with value: 0.6836158192090395 and parameters: {'classifier': 'SVC', 'svc_c': 0.4872929859311496}. Best is trial 88 with value: 0.8587570621468926.\u001b[0m\n",
      "\u001b[32m[I 2022-12-20 16:36:03,991]\u001b[0m Trial 106 finished with value: 0.847457627118644 and parameters: {'classifier': 'LogReg', 'logreg_c': 8086473.0529765785, 'logreg_c_weight': 'balanced'}. Best is trial 88 with value: 0.8587570621468926.\u001b[0m\n",
      "\u001b[32m[I 2022-12-20 16:36:04,207]\u001b[0m Trial 107 finished with value: 0.8531073446327683 and parameters: {'classifier': 'LogReg', 'logreg_c': 20898.61054607778, 'logreg_c_weight': 'balanced'}. Best is trial 88 with value: 0.8587570621468926.\u001b[0m\n",
      "\u001b[32m[I 2022-12-20 16:36:04,440]\u001b[0m Trial 108 finished with value: 0.847457627118644 and parameters: {'classifier': 'LogReg', 'logreg_c': 15787.548475516349, 'logreg_c_weight': 'balanced'}. Best is trial 88 with value: 0.8587570621468926.\u001b[0m\n",
      "\u001b[32m[I 2022-12-20 16:36:04,765]\u001b[0m Trial 109 finished with value: 0.8418079096045198 and parameters: {'classifier': 'LogReg', 'logreg_c': 2089.0482661138585, 'logreg_c_weight': 'balanced'}. Best is trial 88 with value: 0.8587570621468926.\u001b[0m\n",
      "\u001b[32m[I 2022-12-20 16:36:04,986]\u001b[0m Trial 110 finished with value: 0.847457627118644 and parameters: {'classifier': 'LogReg', 'logreg_c': 159677.5473314565, 'logreg_c_weight': None}. Best is trial 88 with value: 0.8587570621468926.\u001b[0m\n",
      "\u001b[32m[I 2022-12-20 16:36:05,279]\u001b[0m Trial 111 finished with value: 0.8418079096045198 and parameters: {'classifier': 'LogReg', 'logreg_c': 4479.8541139835725, 'logreg_c_weight': 'balanced'}. Best is trial 88 with value: 0.8587570621468926.\u001b[0m\n",
      "\u001b[32m[I 2022-12-20 16:36:05,528]\u001b[0m Trial 112 finished with value: 0.847457627118644 and parameters: {'classifier': 'LogReg', 'logreg_c': 65271.67400702298, 'logreg_c_weight': 'balanced'}. Best is trial 88 with value: 0.8587570621468926.\u001b[0m\n",
      "\u001b[32m[I 2022-12-20 16:36:05,809]\u001b[0m Trial 113 finished with value: 0.8531073446327683 and parameters: {'classifier': 'LogReg', 'logreg_c': 10042.78117873741, 'logreg_c_weight': 'balanced'}. Best is trial 88 with value: 0.8587570621468926.\u001b[0m\n",
      "\u001b[32m[I 2022-12-20 16:36:06,150]\u001b[0m Trial 114 finished with value: 0.8418079096045198 and parameters: {'classifier': 'LogReg', 'logreg_c': 273.87332797028216, 'logreg_c_weight': 'balanced'}. Best is trial 88 with value: 0.8587570621468926.\u001b[0m\n",
      "\u001b[32m[I 2022-12-20 16:36:06,384]\u001b[0m Trial 115 finished with value: 0.5932203389830508 and parameters: {'classifier': 'LogReg', 'logreg_c': 8.476356342308925e-06, 'logreg_c_weight': None}. Best is trial 88 with value: 0.8587570621468926.\u001b[0m\n",
      "\u001b[32m[I 2022-12-20 16:36:06,616]\u001b[0m Trial 116 finished with value: 0.847457627118644 and parameters: {'classifier': 'LogReg', 'logreg_c': 319597.7698437035, 'logreg_c_weight': 'balanced'}. Best is trial 88 with value: 0.8587570621468926.\u001b[0m\n",
      "\u001b[32m[I 2022-12-20 16:36:06,868]\u001b[0m Trial 117 finished with value: 0.8587570621468926 and parameters: {'classifier': 'LogReg', 'logreg_c': 7814.504442101829, 'logreg_c_weight': 'balanced'}. Best is trial 88 with value: 0.8587570621468926.\u001b[0m\n",
      "\u001b[32m[I 2022-12-20 16:36:08,418]\u001b[0m Trial 118 finished with value: 0.7514124293785311 and parameters: {'classifier': 'RandomForest', 'rf_n_estimators': 984, 'rf_max_depth': 28}. Best is trial 88 with value: 0.8587570621468926.\u001b[0m\n",
      "\u001b[32m[I 2022-12-20 16:36:08,792]\u001b[0m Trial 119 finished with value: 0.8418079096045198 and parameters: {'classifier': 'LogReg', 'logreg_c': 482.2821372290615, 'logreg_c_weight': 'balanced'}. Best is trial 88 with value: 0.8587570621468926.\u001b[0m\n",
      "\u001b[32m[I 2022-12-20 16:36:09,011]\u001b[0m Trial 120 finished with value: 0.8531073446327683 and parameters: {'classifier': 'LogReg', 'logreg_c': 44864.6422098925, 'logreg_c_weight': None}. Best is trial 88 with value: 0.8587570621468926.\u001b[0m\n",
      "\u001b[32m[I 2022-12-20 16:36:09,226]\u001b[0m Trial 121 finished with value: 0.8531073446327683 and parameters: {'classifier': 'LogReg', 'logreg_c': 56425.37879492046, 'logreg_c_weight': None}. Best is trial 88 with value: 0.8587570621468926.\u001b[0m\n",
      "\u001b[32m[I 2022-12-20 16:36:09,540]\u001b[0m Trial 122 finished with value: 0.8418079096045198 and parameters: {'classifier': 'LogReg', 'logreg_c': 1777.973327239059, 'logreg_c_weight': None}. Best is trial 88 with value: 0.8587570621468926.\u001b[0m\n",
      "\u001b[32m[I 2022-12-20 16:36:09,804]\u001b[0m Trial 123 finished with value: 0.8531073446327683 and parameters: {'classifier': 'LogReg', 'logreg_c': 10583.48430748994, 'logreg_c_weight': 'balanced'}. Best is trial 88 with value: 0.8587570621468926.\u001b[0m\n",
      "\u001b[32m[I 2022-12-20 16:36:10,021]\u001b[0m Trial 124 finished with value: 0.847457627118644 and parameters: {'classifier': 'LogReg', 'logreg_c': 25734.939127164147, 'logreg_c_weight': 'balanced'}. Best is trial 88 with value: 0.8587570621468926.\u001b[0m\n",
      "\u001b[32m[I 2022-12-20 16:36:10,318]\u001b[0m Trial 125 finished with value: 0.847457627118644 and parameters: {'classifier': 'LogReg', 'logreg_c': 5656.949372936479, 'logreg_c_weight': 'balanced'}. Best is trial 88 with value: 0.8587570621468926.\u001b[0m\n",
      "\u001b[32m[I 2022-12-20 16:36:10,550]\u001b[0m Trial 126 finished with value: 0.847457627118644 and parameters: {'classifier': 'LogReg', 'logreg_c': 222490.2373963601, 'logreg_c_weight': 'balanced'}. Best is trial 88 with value: 0.8587570621468926.\u001b[0m\n",
      "\u001b[32m[I 2022-12-20 16:36:10,720]\u001b[0m Trial 127 finished with value: 0.5932203389830508 and parameters: {'classifier': 'SVC', 'svc_c': 1.042385716285873e-07}. Best is trial 88 with value: 0.8587570621468926.\u001b[0m\n",
      "\u001b[32m[I 2022-12-20 16:36:11,018]\u001b[0m Trial 128 finished with value: 0.8531073446327683 and parameters: {'classifier': 'LogReg', 'logreg_c': 52601.773059280364, 'logreg_c_weight': None}. Best is trial 88 with value: 0.8587570621468926.\u001b[0m\n",
      "\u001b[32m[I 2022-12-20 16:36:11,264]\u001b[0m Trial 129 finished with value: 0.8531073446327683 and parameters: {'classifier': 'LogReg', 'logreg_c': 15873.306367623296, 'logreg_c_weight': 'balanced'}. Best is trial 88 with value: 0.8587570621468926.\u001b[0m\n",
      "\u001b[32m[I 2022-12-20 16:36:11,480]\u001b[0m Trial 130 finished with value: 0.8531073446327683 and parameters: {'classifier': 'LogReg', 'logreg_c': 16110.007831579385, 'logreg_c_weight': 'balanced'}. Best is trial 88 with value: 0.8587570621468926.\u001b[0m\n",
      "\u001b[32m[I 2022-12-20 16:36:11,792]\u001b[0m Trial 131 finished with value: 0.8418079096045198 and parameters: {'classifier': 'LogReg', 'logreg_c': 4630.465583736337, 'logreg_c_weight': 'balanced'}. Best is trial 88 with value: 0.8587570621468926.\u001b[0m\n",
      "\u001b[32m[I 2022-12-20 16:36:12,044]\u001b[0m Trial 132 finished with value: 0.8587570621468926 and parameters: {'classifier': 'LogReg', 'logreg_c': 9450.262558440309, 'logreg_c_weight': 'balanced'}. Best is trial 88 with value: 0.8587570621468926.\u001b[0m\n",
      "\u001b[32m[I 2022-12-20 16:36:12,306]\u001b[0m Trial 133 finished with value: 0.8587570621468926 and parameters: {'classifier': 'LogReg', 'logreg_c': 7235.9240012216715, 'logreg_c_weight': 'balanced'}. Best is trial 88 with value: 0.8587570621468926.\u001b[0m\n",
      "\u001b[32m[I 2022-12-20 16:36:12,599]\u001b[0m Trial 134 finished with value: 0.8361581920903954 and parameters: {'classifier': 'LogReg', 'logreg_c': 1788.8995725543432, 'logreg_c_weight': 'balanced'}. Best is trial 88 with value: 0.8587570621468926.\u001b[0m\n",
      "\u001b[32m[I 2022-12-20 16:36:12,880]\u001b[0m Trial 135 finished with value: 0.847457627118644 and parameters: {'classifier': 'LogReg', 'logreg_c': 81018.67545150913, 'logreg_c_weight': 'balanced'}. Best is trial 88 with value: 0.8587570621468926.\u001b[0m\n",
      "\u001b[32m[I 2022-12-20 16:36:13,315]\u001b[0m Trial 136 finished with value: 0.8418079096045198 and parameters: {'classifier': 'LogReg', 'logreg_c': 158.35990497812207, 'logreg_c_weight': 'balanced'}. Best is trial 88 with value: 0.8587570621468926.\u001b[0m\n",
      "\u001b[32m[I 2022-12-20 16:36:13,672]\u001b[0m Trial 137 finished with value: 0.8418079096045198 and parameters: {'classifier': 'LogReg', 'logreg_c': 620.3517972590164, 'logreg_c_weight': 'balanced'}. Best is trial 88 with value: 0.8587570621468926.\u001b[0m\n",
      "\u001b[32m[I 2022-12-20 16:36:13,999]\u001b[0m Trial 138 finished with value: 0.8531073446327683 and parameters: {'classifier': 'LogReg', 'logreg_c': 6055.444913122152, 'logreg_c_weight': 'balanced'}. Best is trial 88 with value: 0.8587570621468926.\u001b[0m\n",
      "\u001b[32m[I 2022-12-20 16:36:14,233]\u001b[0m Trial 139 finished with value: 0.847457627118644 and parameters: {'classifier': 'LogReg', 'logreg_c': 1627618.4592101492, 'logreg_c_weight': 'balanced'}. Best is trial 88 with value: 0.8587570621468926.\u001b[0m\n",
      "\u001b[32m[I 2022-12-20 16:36:14,530]\u001b[0m Trial 140 finished with value: 0.8531073446327683 and parameters: {'classifier': 'LogReg', 'logreg_c': 6083.992755541445, 'logreg_c_weight': 'balanced'}. Best is trial 88 with value: 0.8587570621468926.\u001b[0m\n",
      "\u001b[32m[I 2022-12-20 16:36:14,855]\u001b[0m Trial 141 finished with value: 0.8361581920903954 and parameters: {'classifier': 'LogReg', 'logreg_c': 979.3153285802214, 'logreg_c_weight': 'balanced'}. Best is trial 88 with value: 0.8587570621468926.\u001b[0m\n",
      "\u001b[32m[I 2022-12-20 16:36:15,119]\u001b[0m Trial 142 finished with value: 0.8531073446327683 and parameters: {'classifier': 'LogReg', 'logreg_c': 62112.0236291996, 'logreg_c_weight': None}. Best is trial 88 with value: 0.8587570621468926.\u001b[0m\n",
      "\u001b[32m[I 2022-12-20 16:36:15,399]\u001b[0m Trial 143 finished with value: 0.847457627118644 and parameters: {'classifier': 'LogReg', 'logreg_c': 623525.4698275087, 'logreg_c_weight': 'balanced'}. Best is trial 88 with value: 0.8587570621468926.\u001b[0m\n",
      "\u001b[32m[I 2022-12-20 16:36:15,665]\u001b[0m Trial 144 finished with value: 0.847457627118644 and parameters: {'classifier': 'LogReg', 'logreg_c': 9255.707662346531, 'logreg_c_weight': 'balanced'}. Best is trial 88 with value: 0.8587570621468926.\u001b[0m\n",
      "\u001b[32m[I 2022-12-20 16:36:15,912]\u001b[0m Trial 145 finished with value: 0.847457627118644 and parameters: {'classifier': 'LogReg', 'logreg_c': 159554.95300941853, 'logreg_c_weight': 'balanced'}. Best is trial 88 with value: 0.8587570621468926.\u001b[0m\n",
      "\u001b[32m[I 2022-12-20 16:36:16,239]\u001b[0m Trial 146 finished with value: 0.8418079096045198 and parameters: {'classifier': 'LogReg', 'logreg_c': 3278.8998323227343, 'logreg_c_weight': 'balanced'}. Best is trial 88 with value: 0.8587570621468926.\u001b[0m\n",
      "\u001b[32m[I 2022-12-20 16:36:16,473]\u001b[0m Trial 147 finished with value: 0.847457627118644 and parameters: {'classifier': 'LogReg', 'logreg_c': 27815.584473959352, 'logreg_c_weight': 'balanced'}. Best is trial 88 with value: 0.8587570621468926.\u001b[0m\n",
      "\u001b[32m[I 2022-12-20 16:36:16,974]\u001b[0m Trial 148 finished with value: 0.7175141242937854 and parameters: {'classifier': 'RandomForest', 'rf_n_estimators': 278, 'rf_max_depth': 3}. Best is trial 88 with value: 0.8587570621468926.\u001b[0m\n",
      "\u001b[32m[I 2022-12-20 16:36:17,254]\u001b[0m Trial 149 finished with value: 0.847457627118644 and parameters: {'classifier': 'LogReg', 'logreg_c': 5570.882080008812, 'logreg_c_weight': 'balanced'}. Best is trial 88 with value: 0.8587570621468926.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FrozenTrial(number=88, values=[0.8587570621468926], datetime_start=datetime.datetime(2022, 12, 20, 16, 35, 57, 766862), datetime_complete=datetime.datetime(2022, 12, 20, 16, 35, 58, 15046), params={'classifier': 'LogReg', 'logreg_c': 8914.264350019694, 'logreg_c_weight': 'balanced'}, distributions={'classifier': CategoricalDistribution(choices=('LogReg', 'RandomForest', 'SVC')), 'logreg_c': FloatDistribution(high=10000000000.0, log=True, low=1e-10, step=None), 'logreg_c_weight': CategoricalDistribution(choices=('balanced', None))}, user_attrs={}, system_attrs={}, intermediate_values={}, trial_id=88, state=TrialState.COMPLETE, value=None)"
      ]
     },
     "execution_count": 406,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8587570621468926"
      ]
     },
     "execution_count": 407,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier': 'LogReg',\n",
       " 'logreg_c': 8914.264350019694,\n",
       " 'logreg_c_weight': 'balanced'}"
      ]
     },
     "execution_count": 408,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC(C=726.7419950350762, gamma='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8022598870056498"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = cross_val_score(svc, X, y, n_jobs=-1, cv=3)\n",
    "score.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.79661017, 0.81355932, 0.79661017])"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 0, 0, 2, 2, 2, 1, 0, 2, 0, 0, 0, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 1, 2, 2, 2, 2, 2, 0, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 1, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 0, 0, 2, 2, 2, 0, 2, 2, 2,\n",
       "       2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2,\n",
       "       1], dtype=int64)"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = cross_val_predict(svc, X, y, n_jobs=-1, cv=2)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg2 = LogisticRegression(C=8914.264350019694, class_weight=\"balanced\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-16 {color: black;background-color: white;}#sk-container-id-16 pre{padding: 0;}#sk-container-id-16 div.sk-toggleable {background-color: white;}#sk-container-id-16 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-16 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-16 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-16 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-16 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-16 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-16 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-16 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-16 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-16 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-16 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-16 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-16 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-16 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-16 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-16 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-16 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-16 div.sk-item {position: relative;z-index: 1;}#sk-container-id-16 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-16 div.sk-item::before, #sk-container-id-16 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-16 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-16 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-16 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-16 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-16 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-16 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-16 div.sk-label-container {text-align: center;}#sk-container-id-16 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-16 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-16\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(C=726.7419950350762, gamma=&#x27;auto&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" checked><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=726.7419950350762, gamma=&#x27;auto&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(C=726.7419950350762, gamma='auto')"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 0, 2, 2, 2, 0, 2, 0, 2, 0, 2, 2, 0, 0, 2, 2, 2, 2, 2, 2, 1, 2,\n",
       "       2], dtype=int64)"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = svc.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-18 {color: black;background-color: white;}#sk-container-id-18 pre{padding: 0;}#sk-container-id-18 div.sk-toggleable {background-color: white;}#sk-container-id-18 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-18 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-18 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-18 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-18 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-18 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-18 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-18 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-18 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-18 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-18 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-18 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-18 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-18 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-18 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-18 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-18 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-18 div.sk-item {position: relative;z-index: 1;}#sk-container-id-18 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-18 div.sk-item::before, #sk-container-id-18 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-18 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-18 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-18 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-18 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-18 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-18 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-18 div.sk-label-container {text-align: center;}#sk-container-id-18 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-18 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-18\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=8914.264350019694, class_weight=&#x27;balanced&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" checked><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=8914.264350019694, class_weight=&#x27;balanced&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(C=8914.264350019694, class_weight='balanced')"
      ]
     },
     "execution_count": 410,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 2, 2, 0, 2, 0, 2, 2, 0, 0, 0, 2, 2, 2, 2, 2, 2, 0, 2, 1, 2,\n",
       "       2, 2, 0, 2, 2, 2, 2, 1, 2, 0, 0, 2, 0, 2, 0, 2, 2, 2, 0, 2, 2, 2,\n",
       "       2], dtype=int64)"
      ]
     },
     "execution_count": 411,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = logreg2.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_true=y_test, y_pred=y_pred, labels=svc.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfIAAAG2CAYAAACEWASqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8o6BhiAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAwqklEQVR4nO3deXhU9fn//9ckIZOELBAgCYGAILKVTREpLgiVstgfgtCf1eKngSJ+1AQFRIUqu5qqrVCUgnUh0oJLq6CgpUWUAAXkA4KKQkpCkCAEQSQhUZIwc75/RKYd2TKZmZw5c56P6zrXxZyc5Y4R7tz3+33ex2EYhiEAAGBJEWYHAAAA6o5EDgCAhZHIAQCwMBI5AAAWRiIHAMDCSOQAAFgYiRwAAAsjkQMAYGEkcgAALIxEDgCAhZHIAQAIgpycHPXq1UsJCQlKSUnR8OHDlZ+f73VMv3795HA4vLa77rrLp/uQyAEACIK8vDxlZWVpy5YtWrNmjaqrqzVw4EBVVFR4HTdu3DgdPnzYsz355JM+3ScqkEEDAIAaq1ev9vqcm5urlJQUbd++XX379vXsj4uLU1paWp3vY+lE7na7dejQISUkJMjhcJgdDgDAR4Zh6OTJk0pPT1dERPCaxKdOnVJVVZXf1zEM46x843Q65XQ6L3puaWmpJCk5Odlr/9KlS/WXv/xFaWlpGjp0qKZNm6a4uDifgrKs4uJiQxIbGxsbm8W34uLioOWK7777zkhLiQxInPHx8WftmzFjxkVjcLlcxs9+9jPjmmuu8dr/3HPPGatXrzY++eQT4y9/+YvRokUL4+abb/bp+7N0RZ6QkCBJ6jHsEUU2iDE5GgRbo3/uMTsE1KfmKWZHgHpw2lWpvIIFnn/Pg6GqqkolX7n0xfZLlJhQ96q/7KRbrXvuV3FxsRITEz37a1ONZ2VladeuXdq4caPX/jvvvNPz565du6p58+a64YYbVFhYqEsvvbRWcVk6kZ9pb0Q2iFEUiTzsRTmizQ4B9Sny4v84InzUx/BofIJD8Ql1v49bNecmJiZ6JfKLyc7O1qpVq7R+/Xq1bNnygsf27t1bklRQUGCPRA4AQG25DLdchn/n+8IwDI0fP17Lly/XunXr1KZNm4ues3PnTklS8+bNa30fEjkAwBbcMuRW3TO5r+dmZWVp2bJleuutt5SQkKCSkhJJUlJSkmJjY1VYWKhly5bpxhtvVJMmTfTJJ59o4sSJ6tu3r7p161br+5DIAQAIgoULF0qqWfTlvy1evFijR49WdHS03nvvPc2bN08VFRXKyMjQyJEj9cgjj/h0HxI5AMAW3HLLt+b42ef7wjAuXMFnZGQoLy/Pj4hqkMgBALbgMgy5LpJcL3Z+KGKJVgAALIyKHABgC/U92a2+kMgBALbgliFXGCZyWusAAFgYFTkAwBZorQMAYGHMWgcAACGHihwAYAvu7zd/zg9FJHIAgC24/Jy17s+5wUQiBwDYgsuQn28/C1wsgcQYOQAAFkZFDgCwBcbIAQCwMLcccsnh1/mhiNY6AAAWRkUOALAFt1Gz+XN+KCKRAwBsweVna92fc4OJ1joAABZGRQ4AsIVwrchJ5AAAW3AbDrkNP2at+3FuMNFaBwDAwqjIAQC2QGsdAAALcylCLj8a0a4AxhJIJHIAgC0Yfo6RG4yRAwCAQKMiBwDYAmPkAABYmMuIkMvwY4w8RJdopbUOAICFUZEDAGzBLYfcftSvboVmSU4iBwDYQriOkdNaBwDAwqjIAQC24P9kN1rrAACYpmaM3I+XptBaBwAAgUZFDgCwBbefa60zax0AABMxRg4AgIW5FRGWz5EzRg4AgIVRkQMAbMFlOOTy41Wk/pwbTCRyAIAtuPyc7OaitQ4AAAKNihwAYAtuI0JuP2atu5m1DgCAeWitAwCAkENFDgCwBbf8m3nuDlwoAUUiBwDYgv8LwoRmEzs0owIAALVCRQ4AsAX/11oPzdqXRA4AsIVwfR85idxC3nhkqZonl5+9f2Nn/f7N60yICMHS5cpSjRx7UO1+VK4mKVWak9VJm9c2NTssBMGNQwv1s5v2KTW1QpL0xReJeuXPnbRta3OTIws/VOQw3di5IxQR8Z/nGNumHdf8u9/R+x9famJUCIaYWJeK9jTUP99I1bRnd5sdDoLo2LFYLX6+iw59GS+HQ7ph4BeaNnuTxv/vAB34Isns8GABIfHrxYIFC3TJJZcoJiZGvXv31tatW80OKSSdqIjV8ZNxnu2aH32hg8cStaOQ39zDzbYNyVryh0u0+T2q8HC3dXO6tm1trkNfJujLgwla8lIXnfouSh07Hzc7tLBzZkEYf7ZQZHpUr732miZNmqQZM2boo48+Uvfu3TVo0CB99dVXZocW0qIiXRp0RYFWfdhBCtFxGwC+iYgw1Ld/sWJiXNr9eROzwwk7bsPh9xaKTE/kTz/9tMaNG6cxY8aoc+fOWrRokeLi4vTSSy+ZHVpI69tlv+JjK/Xu/3UwOxQAfrqkTaneWLVcb61+U9kTPtKcGX1U/EWi2WHBIkwdI6+qqtL27ds1depUz76IiAgNGDBAmzdvPuv4yspKVVZWej6XlZXVS5yhaGjvPdqyJ0PHyhqaHQoAPx0sTlD2nT9Vw4bVurbvQd3/0P/pwUn9SOYB5vazPc6CMOdw7NgxuVwupaameu1PTU1VSUnJWcfn5OQoKSnJs2VkZNRXqCElrfFJXdn+S63c0snsUAAEwOnTETp8KF4Fexsr98Wu2lfYSMNG7DU7rLBz5u1n/myhKDSjOo+pU6eqtLTUsxUXF5sdkil+dlW+vimP1abdrcwOBUAQREQYatAgVFf2RqgxtbXetGlTRUZG6siRI177jxw5orS0tLOOdzqdcjqd9RVeSHI4DP2sV77+/n/t5XJb6vcw+CAmzqX0Vt95Pqe2rFTbjuU6WRqlo4djTIwMgTZ67KfatjVNX30Vp7i40+r3kwPq2v2opk1hbYhAc8khlx+Tg/05N5hMTeTR0dHq2bOn1q5dq+HDh0uS3G631q5dq+zsbDNDC1m9LjuotORyrdrKJLdwdlmXk3piyaeez3dO3SdJWrM8RXOn8rMPJ0mNK3X/lP9TcvIpVVQ0UNG+JE2bcp12bE+9+Mnwib/t8VBtrZu+IMykSZOUmZmpK6+8UldddZXmzZuniooKjRkzxuzQQtLWf2fo6kn/a3YYCLJPtzbSjR2pyOzgD7+70uwQYHGmJ/Jf/OIXOnr0qKZPn66SkhL16NFDq1evPmsCHAAA/nDJv/a4K3ChBJTpiVySsrOzaaUDAIKK1joAABYWri9NCc2oAACwuJycHPXq1UsJCQlKSUnR8OHDlZ+f73XMqVOnlJWVpSZNmig+Pl4jR44860muiyGRAwBswfj+feR13Qwfx9fz8vKUlZWlLVu2aM2aNaqurtbAgQNVUVHhOWbixIlauXKl/vrXvyovL0+HDh3SiBEjfLoPrXUAgC3Ud2t99erVXp9zc3OVkpKi7du3q2/fviotLdWLL76oZcuW6Sc/+YkkafHixerUqZO2bNmiH//4x7W6DxU5AAA+KCsr89r++x0gF1JaWipJSk5OliRt375d1dXVGjBggOeYjh07qlWrVud838j5kMgBALYQqNeYZmRkeL33Iycn5+L3drs1YcIEXXPNNerSpYskqaSkRNHR0WrUqJHXsed738j50FoHANiCy8+3n505t7i4WImJ/3kzXW2WDs/KytKuXbu0cePGOt//fEjkAAD4IDEx0SuRX0x2drZWrVql9evXq2XLlp79aWlpqqqq0okTJ7yq8vO9b+R8aK0DAGwhUK312jIMQ9nZ2Vq+fLnef/99tWnTxuvrPXv2VIMGDbR27VrPvvz8fB04cEB9+vSp9X2oyAEAtuBWhNx+1K++npuVlaVly5bprbfeUkJCgmfcOykpSbGxsUpKStLYsWM1adIkJScnKzExUePHj1efPn1qPWNdIpEDABAUCxculCT169fPa//ixYs1evRoSdLcuXMVERGhkSNHqrKyUoMGDdIf//hHn+5DIgcA2ILLcMjlY3v8h+f7wjCMix4TExOjBQsWaMGCBXUNi0QOALCHuoxz//D8UEQiBwDYguHn288MXpoCAAACjYocAGALLjnk8vHFJz88PxSRyAEAtuA2/Bvndl987popaK0DAGBhVOQAAFtw+znZzZ9zg4lEDgCwBbcccvsxzu3PucEUmr9eAACAWqEiBwDYQn2v7FZfSOQAAFsI1zHy0IwKAADUChU5AMAW3PJzrfUQnexGIgcA2ILh56x1g0QOAIB5wvXtZ4yRAwBgYVTkAABbCNdZ6yRyAIAt0FoHAAAhh4ocAGAL4brWOokcAGALtNYBAEDIoSIHANhCuFbkJHIAgC2EayKntQ4AgIVRkQMAbCFcK3ISOQDAFgz59wiZEbhQAopEDgCwhXCtyBkjBwDAwqjIAQC2EK4VOYkcAGAL4ZrIaa0DAGBhVOQAAFsI14qcRA4AsAXDcMjwIxn7c24w0VoHAMDCqMgBALbA+8gBALCwcB0jp7UOAICFUZEDAGwhXCe7kcgBALYQrq11EjkAwBbCtSJnjBwAAAsLi4q80T/3KMoRbXYYCDJXWZnZIaAeRSUmmB0C6oHDXVlv9zL8bK2HakUeFokcAICLMSQZhn/nhyJa6wAAWBgVOQDAFtxyyMHKbgAAWBOz1gEAQMihIgcA2ILbcMjBgjAAAFiTYfg5az1Ep63TWgcAwMKoyAEAthCuk91I5AAAWyCRAwBgYeE62Y0xcgAALIyKHABgC+E6a51EDgCwhZpE7s8YeQCDCSBa6wAAWBgVOQDAFpi1DgCAhRny753iIdpZp7UOAICVUZEDAGyB1joAAFYWpr11WusAAHv4viKv6yYfK/L169dr6NChSk9Pl8Ph0IoVK7y+Pnr0aDkcDq9t8ODBPn9bJHIAAIKgoqJC3bt314IFC857zODBg3X48GHP9sorr/h8H1rrAABbqO+V3YYMGaIhQ4Zc8Bin06m0tLS6ByUqcgCATfjTVv/viXJlZWVeW2VlZZ1jWrdunVJSUtShQwfdfffd+vrrr32+BokcAAAfZGRkKCkpybPl5OTU6TqDBw/WkiVLtHbtWj3xxBPKy8vTkCFD5HK5fLoOrXUAgD3UYcLaWedLKi4uVmJiome30+ms0+VuvfVWz5+7du2qbt266dJLL9W6det0ww031Po6VOQAAFs4M0buzyZJiYmJXltdE/kPtW3bVk2bNlVBQYFP55HIAQAIAQcPHtTXX3+t5s2b+3QerXUAgD3U84Iw5eXlXtV1UVGRdu7cqeTkZCUnJ2vWrFkaOXKk0tLSVFhYqAcffFDt2rXToEGDfLpPrRL522+/XesL3nTTTT4FAABAfajvJVq3bdum/v37ez5PmjRJkpSZmamFCxfqk08+0csvv6wTJ04oPT1dAwcO1Jw5c3xu1dcqkQ8fPrxWF3M4HD7PtgMAIBz169dPxgUePv/HP/4RkPvUKpG73e6A3AwAAFOF6Hrp/vBrjPzUqVOKiYkJVCwAAARNuL79zOdZ6y6XS3PmzFGLFi0UHx+vffv2SZKmTZumF198MeABAgAQEEYAthDkcyJ/7LHHlJubqyeffFLR0dGe/V26dNELL7wQ0OAAAMCF+ZzIlyxZoj/96U8aNWqUIiMjPfu7d++uPXv2BDQ4AAACxxGALfT4PEb+5Zdfql27dmftd7vdqq6uDkhQAAAEXD0/R15ffK7IO3furA0bNpy1/29/+5suv/zygAQFAABqx+eKfPr06crMzNSXX34pt9utN998U/n5+VqyZIlWrVoVjBgBAPAfFXmNYcOGaeXKlXrvvffUsGFDTZ8+Xbt379bKlSv105/+NBgxAgDgvzNvP/NnC0F1eo78uuuu05o1awIdCwAA8FGdF4TZtm2bdu/eLalm3Lxnz54BCwoAgED771eR1vX8UORzIj948KBuu+02/etf/1KjRo0kSSdOnNDVV1+tV199VS1btgx0jAAA+I8x8hp33HGHqqurtXv3bh0/flzHjx/X7t275Xa7dccddwQjRgAAcB4+V+R5eXnatGmTOnTo4NnXoUMHPfPMM7ruuusCGhwAAAHj74S1cJnslpGRcc6FX1wul9LT0wMSFAAAgeYwajZ/zg9FPrfWn3rqKY0fP17btm3z7Nu2bZvuu+8+/e53vwtocAAABEyYvjSlVhV548aN5XD8p6VQUVGh3r17Kyqq5vTTp08rKipKv/71rzV8+PCgBAoAAM5Wq0Q+b968IIcBAECQ2XmMPDMzM9hxAAAQXGH6+FmdF4SRpFOnTqmqqsprX2Jiol8BAQCA2vN5sltFRYWys7OVkpKihg0bqnHjxl4bAAAhKUwnu/mcyB988EG9//77WrhwoZxOp1544QXNmjVL6enpWrJkSTBiBADAf2GayH1ura9cuVJLlixRv379NGbMGF133XVq166dWrduraVLl2rUqFHBiBMAAJyDzxX58ePH1bZtW0k14+HHjx+XJF177bVav359YKMDACBQeI1pjbZt26qoqEitWrVSx44d9frrr+uqq67SypUrPS9RQXB0ubJUI8ceVLsflatJSpXmZHXS5rVNzQ4LQTJ09DH9/O6vlNzstPZ9Hqs/PtJC+TvjzA4LAfb/Zxbo6v5H1LJ1uaoqI7X708Za/EwHfXkg3uzQwg4ru31vzJgx+vjjjyVJU6ZM0YIFCxQTE6OJEyfqgQceCHiA+I+YWJeK9jTUH2dfanYoCLLrb/pGd844pKVPpylrUHvt+zxGjy3bp6QmZy+PDGvresVxvfPX1rp/7NV6ZPxViop069FntsoZc9rs0GARPlfkEydO9Px5wIAB2rNnj7Zv36527dqpW7duPl1r/fr1euqpp7R9+3YdPnxYy5cvZ2W4C9i2IVnbNiSbHQbqwYg7j2n1smT987Wan/f8h1rqqhvKNOi243r92VSTo0MgTb/vKq/PT8/uplf+uVbtOpXpsx38fQ+oMH2O3OeK/Idat26tESNG+JzEpZpH2bp3764FCxb4GwYQNqIauHVZt2/10YYEzz7DcGjHhgR17vmtiZGhPjSMr6nEy0sbmBwJrKJWFfn8+fNrfcF777231scOGTJEQ4YMqfXxgB0kJrsUGSWdOOr91/ObY1HKaFdpUlSoDw6HoTsnfa7PdjbWF/sSLn4CfOKQn2PkAYsksGqVyOfOnVurizkcDp8Sua8qKytVWfmff8jKysqCdi8AqG93P/iZWrct1wN3/tjsUGAhtUrkRUVFwY6jVnJycjRr1iyzwwCCqux4pFynpUbNvCc7NW56Wt8c9WtVZYSwuyZ/pquu/UoP/e+P9fVXsWaHE57C9KUpfo+R16epU6eqtLTUsxUXF5sdEhBwp6sjtPeTOF1+7UnPPofDUI9ry/X5dh4/Cz+G7pr8mfr0K9Fv7umtI4f4GQcNK7uZz+l0yul0mh2GaWLiXEpv9Z3nc2rLSrXtWK6TpVE6ejjGxMgQaG/+qakmzyvWvz+OU/6OON087qhi4tz656vMYg439zz4ma4fdEhzJvfUd99GqXGTmuHDivIoVVVGmhwdrMBSidzuLutyUk8s+dTz+c6p+yRJa5anaO7UDmaFhSDIe7uxkpq49KsHStS42Wnt+yxWD49qoxPHmMkcbn728wOSpCee+9Br/9xZ3fTeOy3NCCl8henjZ6Ym8vLychUUFHg+FxUVaefOnUpOTlarVq1MjCw0fbq1kW7seJ3ZYaCevL24qd5ezMp94e5nV91odgi2Ea4ru5mayLdt26b+/ft7Pk+aNEmSlJmZqdzcXJOiAgDAOuo02W3Dhg26/fbb1adPH3355ZeSpD//+c/auHGjT9fp16+fDMM4ayOJAwACLkwnu/mcyN944w0NGjRIsbGx2rFjh+e57tLSUj3++OMBDxAAgIAgkdd49NFHtWjRIj3//PNq0OA/E2+uueYaffTRRwENDgAAXJjPY+T5+fnq27fvWfuTkpJ04sSJQMQEAEDAhetkN58r8rS0NK+Z5mds3LhRbdu2DUhQAAAE3JmV3fzZQpDPiXzcuHG677779OGHH8rhcOjQoUNaunSpJk+erLvvvjsYMQIA4L8wHSP3ubU+ZcoUud1u3XDDDfr222/Vt29fOZ1OTZ48WePHjw9GjAAA4Dx8TuQOh0MPP/ywHnjgARUUFKi8vFydO3dWfHx8MOIDACAgwnWMvM4LwkRHR6tz586BjAUAgOBhidYa/fv3l8Nx/gH/999/36+AAABA7fmcyHv06OH1ubq6Wjt37tSuXbuUmZkZqLgAAAgsP1vrYVORz50795z7Z86cqfLycr8DAgAgKMK0tV6ntdbP5fbbb9dLL70UqMsBAIBaCNjbzzZv3qyYmJhAXQ4AgMAK04rc50Q+YsQIr8+GYejw4cPatm2bpk2bFrDAAAAIJB4/+15SUpLX54iICHXo0EGzZ8/WwIEDAxYYAAC4OJ8Sucvl0pgxY9S1a1c1btw4WDEBAIBa8mmyW2RkpAYOHMhbzgAA1hOma637PGu9S5cu2rdvXzBiAQAgaM6MkfuzhSKfE/mjjz6qyZMna9WqVTp8+LDKysq8NgAAUH9qPUY+e/Zs3X///brxxhslSTfddJPXUq2GYcjhcMjlcgU+SgAAAiFEq2p/1DqRz5o1S3fddZc++OCDYMYDAEBw2P05csOo+Q6uv/76oAUDAAB849PjZxd66xkAAKGMBWEktW/f/qLJ/Pjx434FBABAUNi9tS7VjJP/cGU3AABgHp8S+a233qqUlJRgxQIAQNCEa2u91s+RMz4OALC0el7Zbf369Ro6dKjS09PlcDi0YsUK73AMQ9OnT1fz5s0VGxurAQMGaO/evT5/W7VO5GdmrQMAgIurqKhQ9+7dtWDBgnN+/cknn9T8+fO1aNEiffjhh2rYsKEGDRqkU6dO+XSfWrfW3W63TxcGACCk1PNktyFDhmjIkCHnvpRhaN68eXrkkUc0bNgwSdKSJUuUmpqqFStW6NZbb631fXxeohUAACsK1FrrP1yavLKy0udYioqKVFJSogEDBnj2JSUlqXfv3tq8ebNP1yKRAwDsIUBj5BkZGUpKSvJsOTk5PodSUlIiSUpNTfXan5qa6vlabfk0ax0AALsrLi5WYmKi57PT6TQxGipyAIBdBKgiT0xM9NrqksjT0tIkSUeOHPHaf+TIEc/XaotEDgCwhVB6H3mbNm2UlpamtWvXevaVlZXpww8/VJ8+fXy6Fq11AACCoLy8XAUFBZ7PRUVF2rlzp5KTk9WqVStNmDBBjz76qC677DK1adNG06ZNU3p6uoYPH+7TfUjkAAB7qOfHz7Zt26b+/ft7Pk+aNEmSlJmZqdzcXD344IOqqKjQnXfeqRMnTujaa6/V6tWrFRMT49N9SOQAAFuo7yVa+/Xrd8HF1BwOh2bPnq3Zs2fXPSgxRg4AgKVRkQMA7IHXmAIAYGFhmshprQMAYGFU5AAAW3B8v/lzfigikQMA7CFMW+skcgCALdT342f1hTFyAAAsjIocAGAPtNYBALC4EE3G/qC1DgCAhVGRAwBsIVwnu5HIAQD2EKZj5LTWAQCwMCpyAIAt0FoHAMDKaK0DAIBQExYVeeXll8oVFWN2GAgy57a9ZoeAevTO1nfMDgH1oOykW43b18+9aK0DAGBlYdpaJ5EDAOwhTBM5Y+QAAFgYFTkAwBYYIwcAwMporQMAgFBDRQ4AsAWHYchh1L2s9ufcYCKRAwDsgdY6AAAINVTkAABbYNY6AABWRmsdAACEGipyAIAt0FoHAMDKwrS1TiIHANhCuFbkjJEDAGBhVOQAAHugtQ4AgLWFanvcH7TWAQCwMCpyAIA9GEbN5s/5IYhEDgCwBWatAwCAkENFDgCwB2atAwBgXQ53zebP+aGI1joAABZGRQ4AsAda6wAAWFe4zlonkQMA7CFMnyNnjBwAAAujIgcA2AKtdQAArCxMJ7vRWgcAwMKoyAEAtkBrHQAAK2PWOgAACDVU5AAAW6C1DgCAlTFrHQAAhBoqcgCALdBaBwDAytxGzebP+SGIRA4AsAfGyAEAQKihIgcA2IJDfo6RByySwCKRAwDsgZXdAABAqCGRAwBs4czjZ/5svpg5c6YcDofX1rFjx4B/X7TWAQD2YMKs9R/96Ed67733PJ+jogKfdknkAAAESVRUlNLS0oJ6D1rrAABbcBiG35sklZWVeW2VlZXnvefevXuVnp6utm3batSoUTpw4EDAvy8SOQDAHtwB2CRlZGQoKSnJs+Xk5Jzzdr1791Zubq5Wr16thQsXqqioSNddd51OnjwZ0G+L1joAAD4oLi5WYmKi57PT6TzncUOGDPH8uVu3burdu7dat26t119/XWPHjg1YPCRyAIAt/Hd7vK7nS1JiYqJXIq+tRo0aqX379iooKKhzDOdCax0AYA9GADY/lJeXq7CwUM2bN/fvQj9AIgcA2MOZld382XwwefJk5eXlaf/+/dq0aZNuvvlmRUZG6rbbbgvot0VrHQCAIDh48KBuu+02ff3112rWrJmuvfZabdmyRc2aNQvofUjkAABbqMvqbD883xevvvpq3W/mAxK5RfxqxEfKHLHTa9+BQ0ka8+BIcwJCUHW5slQjxx5Uux+Vq0lKleZkddLmtU3NDgt+evWZFP3r3UYqLnAqOsatzld+q7EPH1JGu/88h/zAyHb6ZHO813k3/s8x3ffEwfoON/yE6UtTTE3kOTk5evPNN7Vnzx7Fxsbq6quv1hNPPKEOHTqYGVbIKipupAd+O9jz2eViikO4iol1qWhPQ/3zjVRNe3a32eEgQD7ZHK+ho4+pfY9v5Tot5f62uX5z26V6Pm+PYuLcnuOGjDqmXz1Q4vnsjHWf63KAJJMTeV5enrKystSrVy+dPn1av/nNbzRw4EB9/vnnatiwoZmhhSSXO0LflMaZHQbqwbYNydq2IdnsMBBgjy/b5/X5/nkH9IuuXbX3k1h1/XGFZ78z1lByyun6Di/sOdw1mz/nhyJTE/nq1au9Pufm5iolJUXbt29X3759TYoqdLVILdNrz7yiqupIfb43RS++fqW++jr+4icCCEkVZZGSpIRGLq/9H7zZWO+/0ViNU6r145+W6ZcTShQTF5ptXUuhtR58paWlkqTk5HNXIpWVlV5r2paVldVLXKFgT0EzPfmn63TwcJKSG32rX928U/OmvaOxU0bou1MNzA4PgI/cbmnRjBb6Ua9yXdLxlGd//5u/UUrLKjVJrVbR7li9+FhzHSx0avqL+80LFiEtZBK52+3WhAkTdM0116hLly7nPCYnJ0ezZs2q58hCw9ZPMjx/3lecrN2FzbRs3uvq17tIf89rb2JkAOri2d+01Bd7YvX7FXu99t94+9eeP7fpdErJKdV66JZ2OrQ/WumXVNV3mOHFhNeY1oeQmS2VlZWlXbt2XXC6/tSpU1VaWurZiouL6zHC0FLxrVMHS5KUnmqfrgQQLp79TQt9uCZRT/6tQM3Sqy94bMcrvpUkHdp/7vW8UXuBevtZqAmJijw7O1urVq3S+vXr1bJly/Me53Q6z7s4vd3EOKuVnlKm905canYoAGrJMKQFD7fQptVJeupvBUprdfEKu3BXrCQpOeXCCR/2ZWoiNwxD48eP1/Lly7Vu3Tq1adPGzHBC2v/etlWbd2ToyLF4NWn8rUaP2CG3O0Lvb25rdmgIgpg4l9Jbfef5nNqyUm07lutkaZSOHo4xMTL449nftNQHyxtr5uJ9io136/hXNf8EN0xwyRlr6ND+aH2wvLGuuqFMCY1dKvo8Rs/NbKGuPy5X286nLnJ1XBST3QIvKytLy5Yt01tvvaWEhASVlNQ8N5mUlKTY2FgzQws5zZIr9HDWOiXGV6r0ZIx25acqe+b/p9KT/HcKR5d1Oaknlnzq+Xzn1JrHltYsT9HcqayzYFWrXq5Z1OeBkZd57b9/7gEN/MVxRTUwtGNDgpa/0Eynvo1Qs/RqXXvjCd024YgZ4YYfQ553itf5/BDkMAzzfsVwOBzn3L948WKNHj36oueXlZUpKSlJ114/Q1FRVCnhzrlt78UPQth4d896s0NAPSg76Vbj9vtUWlpap1eD1uoe3+eKn1w+RVGRdc8Vp12n9P6O3wY11rowvbUOAADqLiQmuwEAEHSG/BwjD1gkAUUiBwDYQ5hOdguZ58gBAIDvqMgBAPbglnTuOda1Pz8EkcgBALbg7+psobqyG611AAAsjIocAGAPYTrZjUQOALCHME3ktNYBALAwKnIAgD2EaUVOIgcA2AOPnwEAYF08fgYAAEIOFTkAwB4YIwcAwMLchuTwIxm7QzOR01oHAMDCqMgBAPZAax0AACvzM5ErNBM5rXUAACyMihwAYA+01gEAsDC3Ib/a48xaBwAAgUZFDgCwB8Nds/lzfggikQMA7IExcgAALIwxcgAAEGqoyAEA9kBrHQAACzPkZyIPWCQBRWsdAAALoyIHANgDrXUAACzM7Zbkx7Pg7tB8jpzWOgAAFkZFDgCwB1rrAABYWJgmclrrAABYGBU5AMAewnSJVhI5AMAWDMMtw483mPlzbjCRyAEA9mAY/lXVjJEDAIBAoyIHANiD4ecYeYhW5CRyAIA9uN2Sw49x7hAdI6e1DgCAhVGRAwDsgdY6AADWZbjdMvxorYfq42e01gEAsDAqcgCAPdBaBwDAwtyG5Ai/RE5rHQAAC6MiBwDYg2FI8uc58tCsyEnkAABbMNyGDD9a6waJHAAAExlu+VeR8/gZAAC2s2DBAl1yySWKiYlR7969tXXr1oBen0QOALAFw234vfnqtdde06RJkzRjxgx99NFH6t69uwYNGqSvvvoqYN8XiRwAYA+G2//NR08//bTGjRunMWPGqHPnzlq0aJHi4uL00ksvBezbsvQY+ZmJB6dPV5ocCepDpFFldgioR2UnQ3M8EoFVVl7zc66PiWSnVe3XejCnVS1JKisr89rvdDrldDrPOr6qqkrbt2/X1KlTPfsiIiI0YMAAbd68ue6B/IClE/nJkyclSVv+9VuTIwEQaI3bmx0B6tPJkyeVlJQUlGtHR0crLS1NG0ve9fta8fHxysjI8No3Y8YMzZw586xjjx07JpfLpdTUVK/9qamp2rNnj9+xnGHpRJ6enq7i4mIlJCTI4XCYHU69KSsrU0ZGhoqLi5WYmGh2OAgiftb2YdeftWEYOnnypNLT04N2j5iYGBUVFamqyv+unmEYZ+Wbc1Xj9cnSiTwiIkItW7Y0OwzTJCYm2uovvJ3xs7YPO/6sg1WJ/7eYmBjFxMQE/T7/rWnTpoqMjNSRI0e89h85ckRpaWkBuw+T3QAACILo6Gj17NlTa9eu9exzu91au3at+vTpE7D7WLoiBwAglE2aNEmZmZm68sorddVVV2nevHmqqKjQmDFjAnYPErkFOZ1OzZgxw/RxGQQfP2v74Gcdnn7xi1/o6NGjmj59ukpKStSjRw+tXr36rAlw/nAYobp4LAAAuCjGyAEAsDASOQAAFkYiBwDAwkjkAABYGIncYoL9OjyEhvXr12vo0KFKT0+Xw+HQihUrzA4JQZKTk6NevXopISFBKSkpGj58uPLz880OCxZCIreQ+ngdHkJDRUWFunfvrgULFpgdCoIsLy9PWVlZ2rJli9asWaPq6moNHDhQFRUVZocGi+DxMwvp3bu3evXqpWeffVZSzQpBGRkZGj9+vKZMmWJydAgWh8Oh5cuXa/jw4WaHgnpw9OhRpaSkKC8vT3379jU7HFgAFblFnHkd3oABAzz7gvE6PADmKi0tlSQlJyebHAmsgkRuERd6HV5JSYlJUQEIJLfbrQkTJuiaa65Rly5dzA4HFsESrQAQIrKysrRr1y5t3LjR7FBgISRyi6iv1+EBMEd2drZWrVql9evX2/r1zPAdrXWLqK/X4QGoX4ZhKDs7W8uXL9f777+vNm3amB0SLIaK3ELq43V4CA3l5eUqKCjwfC4qKtLOnTuVnJysVq1amRgZAi0rK0vLli3TW2+9pYSEBM+cl6SkJMXGxpocHayAx88s5tlnn9VTTz3leR3e/Pnz1bt3b7PDQoCtW7dO/fv3P2t/ZmamcnNz6z8gBI3D4Tjn/sWLF2v06NH1GwwsiUQOAICFMUYOAICFkcgBALAwEjkAABZGIgcAwMJI5AAAWBiJHAAACyORAwBgYSRywE+jR4/2eld4v379NGHChHqPY926dXI4HDpx4sR5j3E4HFqxYkWtrzlz5kz16NHDr7j2798vh8OhnTt3+nUdAOdGIkdYGj16tBwOhxwOh6Kjo9WuXTvNnj1bp0+fDvq933zzTc2ZM6dWx9Ym+QLAhbDWOsLW4MGDtXjxYlVWVurdd99VVlaWGjRooKlTp551bFVVlaKjowNy3+Tk5IBcBwBqg4ocYcvpdCotLU2tW7fW3XffrQEDBujtt9+W9J92+GOPPab09HR16NBBklRcXKxbbrlFjRo1UnJysoYNG6b9+/d7rulyuTRp0iQ1atRITZo00YMPPqgfrnL8w9Z6ZWWlHnroIWVkZMjpdKpdu3Z68cUXtX//fs966o0bN5bD4fCsre12u5WTk6M2bdooNjZW3bt319/+9jev+7z77rtq3769YmNj1b9/f684a+uhhx5S+/btFRcXp7Zt22ratGmqrq4+67jnnntOGRkZiouL0y233KLS0lKvr7/wwgvq1KmTYmJi1LFjR/3xj3/0ORYAdUMih23ExsaqqqrK83nt2rXKz8/XmjVrtGrVKlVXV2vQoEFKSEjQhg0b9K9//Uvx8fEaPHiw57zf//73ys3N1UsvvaSNGzfq+PHjWr58+QXv+6tf/UqvvPKK5s+fr927d+u5555TfHy8MjIy9MYbb0iS8vPzdfjwYf3hD3+QJOXk5GjJkiVatGiRPvvsM02cOFG333678vLyJNX8wjFixAgNHTpUO3fu1B133KEpU6b4/N8kISFBubm5+vzzz/WHP/xBzz//vObOnet1TEFBgV5//XWtXLlSq1ev1o4dO3TPPfd4vr506VJNnz5djz32mHbv3q3HH39c06ZN08svv+xzPADqwADCUGZmpjFs2DDDMAzD7XYba9asMZxOpzF58mTP11NTU43KykrPOX/+85+NDh06GG6327OvsrLSiI2NNf7xj38YhmEYzZs3N5588knP16urq42WLVt67mUYhnH99dcb9913n2EYhpGfn29IMtasWXPOOD/44ANDkvHNN9949p06dcqIi4szNm3a5HXs2LFjjdtuu80wDMOYOnWq0blzZ6+vP/TQQ2dd64ckGcuXLz/v15966imjZ8+ens8zZswwIiMjjYMHD3r2/f3vfzciIiKMw4cPG4ZhGJdeeqmxbNkyr+vMmTPH6NOnj2EYhlFUVGRIMnbs2HHe+wKoO8bIEbZWrVql+Ph4VVdXy+1265e//KVmzpzp+XrXrl29xsU//vhjFRQUKCEhwes6p06dUmFhoUpLS3X48GGv18ZGRUXpyiuvPKu9fsbOnTsVGRmp66+/vtZxFxQU6Ntvv9VPf/pTr/1VVVW6/PLLJUm7d+8+6/W1ffr0qfU9znjttdc0f/58FRYWqry8XKdPn1ZiYqLXMa1atVKLFi287uN2u5Wfn6+EhAQVFhZq7NixGjdunOeY06dPKykpyed4APiORI6w1b9/fy1cuFDR0dFKT09XVJT3/+4NGzb0+lxeXq6ePXtq6dKlZ12rWbNmdYohNjbW53PKy8slSe+8845XApVqxv0DZfPmzRo1apRmzZqlQYMGKSkpSa+++qp+//vf+xzr888/f9YvFpGRkQGLFcD5kcgRtho2bKh27drV+vgrrrhCr732mlJSUs6qSs9o3ry5PvzwQ/Xt21dSTeW5fft2XXHFFec8vmvXrnK73crLy9OAAQPO+vqZjoDL5fLs69y5s5xOpw4cOHDeSr5Tp06eiXtnbNmy5eLf5H/ZtGmTWrdurYcfftiz74svvjjruAMHDujQoUNKT0/33CciIkIdOnRQamqq0tPTtW/fPo0aNcqn+wMIDCa7Ad8bNWqUmjZtqmHDhmnDhg0qKirSunXrdO+99+rgwYOSpPvuu0+//e1vtWLFCu3Zs0f33HPPBZ8Bv+SSS5SZmalf//rXWrFiheear7/+uiSpdevWcjgcWrVqlY4ePary8nIlJCRo8uTJmjhxol5++WUVFhbqo48+0jPPPOOZQHbXXXdp7969euCBB5Sfn69ly5YpNzfXp+/3sssu04EDB/Tqq6+qsLBQ8+fPP+fEvZiYGGVmZurjjz/Whg0bdO+99+qWW25RWlqaJGnWrFnKycnR/Pnz9e9//1uffvqpFi9erKefftqneADUDYkc+F5cXJzWr1+vVq1aacSIEerUqZPGjh2rU6dOeSr0+++/X//zP/+jzMxM9enTRwkJCbr55psveN2FCxfq5z//ue655x517NhR48aNU0VFhSSpRYsWmjVrlqZMmaLU1FRlZ2dLkubMmaNp06YpJydHnTp10uDBg/XOO++oTZs2kmrGrd944w2tWLFC3bt316JFi/T444/79P3edNNNmjhxorKzs9WjRw9t2rRJ06ZNO+u4du3aacSIEbrxxhs1cOBAdevWzevxsjvuuEMvvPCCFi9erK5du+r6669Xbm6uJ1YAweUwzjdLBwAAhDwqcgAALIxEDgCAhZHIAQCwMBI5AAAWRiIHAMDCSOQAAFgYiRwAAAsjkQMAYGEkcgAALIxEDgCAhZHIAQCwMBI5AAAW9v8AY50IokZbAzQAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=svc.classes_)\n",
    "plot.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7111111111111111"
      ]
     },
     "execution_count": 414,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = logreg2.score(X_test, y_test)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "\n",
    "    C = trial.suggest_float(\"C\", 1e-7, 10.0, log=True)\n",
    "    c_weight = trial.suggest_categorical(\"c_weight\", [\"balanced\", None])\n",
    "\n",
    "    clf = LogisticRegression(C=C, class_weight=c_weight)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    return clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-12-22 08:58:15,195]\u001b[0m A new study created in memory with name: no-name-67146a68-297c-462e-95c1-5f1839b525e3\u001b[0m\n",
      "\u001b[32m[I 2022-12-22 08:58:15,671]\u001b[0m Trial 0 finished with value: 0.7333333333333333 and parameters: {'C': 1.2211873712739172, 'c_weight': None}. Best is trial 0 with value: 0.7333333333333333.\u001b[0m\n",
      "\u001b[32m[I 2022-12-22 08:58:15,900]\u001b[0m Trial 1 finished with value: 0.7333333333333333 and parameters: {'C': 0.00015441967711788047, 'c_weight': 'balanced'}. Best is trial 0 with value: 0.7333333333333333.\u001b[0m\n",
      "\u001b[32m[I 2022-12-22 08:58:16,356]\u001b[0m Trial 2 finished with value: 0.7333333333333333 and parameters: {'C': 0.00128520543915033, 'c_weight': 'balanced'}. Best is trial 0 with value: 0.7333333333333333.\u001b[0m\n",
      "\u001b[32m[I 2022-12-22 08:58:16,808]\u001b[0m Trial 3 finished with value: 0.7555555555555555 and parameters: {'C': 0.02283873061470798, 'c_weight': None}. Best is trial 3 with value: 0.7555555555555555.\u001b[0m\n",
      "\u001b[32m[I 2022-12-22 08:58:17,191]\u001b[0m Trial 4 finished with value: 0.7111111111111111 and parameters: {'C': 0.0032322167110369077, 'c_weight': 'balanced'}. Best is trial 3 with value: 0.7555555555555555.\u001b[0m\n",
      "\u001b[32m[I 2022-12-22 08:58:17,664]\u001b[0m Trial 5 finished with value: 0.7333333333333333 and parameters: {'C': 0.015872178969837204, 'c_weight': 'balanced'}. Best is trial 3 with value: 0.7555555555555555.\u001b[0m\n",
      "\u001b[32m[I 2022-12-22 08:58:17,691]\u001b[0m Trial 6 finished with value: 0.4 and parameters: {'C': 5.443354593506726e-07, 'c_weight': 'balanced'}. Best is trial 3 with value: 0.7555555555555555.\u001b[0m\n",
      "\u001b[32m[I 2022-12-22 08:58:17,824]\u001b[0m Trial 7 finished with value: 0.7333333333333333 and parameters: {'C': 7.72448748830597e-05, 'c_weight': 'balanced'}. Best is trial 3 with value: 0.7555555555555555.\u001b[0m\n",
      "\u001b[32m[I 2022-12-22 08:58:17,934]\u001b[0m Trial 8 finished with value: 0.7333333333333333 and parameters: {'C': 2.4735030600437067e-06, 'c_weight': 'balanced'}. Best is trial 3 with value: 0.7555555555555555.\u001b[0m\n",
      "\u001b[32m[I 2022-12-22 08:58:18,323]\u001b[0m Trial 9 finished with value: 0.7555555555555555 and parameters: {'C': 0.014083448220147003, 'c_weight': None}. Best is trial 3 with value: 0.7555555555555555.\u001b[0m\n",
      "\u001b[32m[I 2022-12-22 08:58:18,691]\u001b[0m Trial 10 finished with value: 0.7111111111111111 and parameters: {'C': 6.085964414856483, 'c_weight': None}. Best is trial 3 with value: 0.7555555555555555.\u001b[0m\n",
      "\u001b[32m[I 2022-12-22 08:58:19,049]\u001b[0m Trial 11 finished with value: 0.7555555555555555 and parameters: {'C': 0.14207482590085177, 'c_weight': None}. Best is trial 3 with value: 0.7555555555555555.\u001b[0m\n",
      "\u001b[32m[I 2022-12-22 08:58:19,412]\u001b[0m Trial 12 finished with value: 0.7555555555555555 and parameters: {'C': 0.076460696370078, 'c_weight': None}. Best is trial 3 with value: 0.7555555555555555.\u001b[0m\n",
      "\u001b[32m[I 2022-12-22 08:58:19,775]\u001b[0m Trial 13 finished with value: 0.7555555555555555 and parameters: {'C': 0.10313856793235847, 'c_weight': None}. Best is trial 3 with value: 0.7555555555555555.\u001b[0m\n",
      "\u001b[32m[I 2022-12-22 08:58:20,013]\u001b[0m Trial 14 finished with value: 0.5111111111111111 and parameters: {'C': 5.6699057610308485e-05, 'c_weight': None}. Best is trial 3 with value: 0.7555555555555555.\u001b[0m\n",
      "\u001b[32m[I 2022-12-22 08:58:20,383]\u001b[0m Trial 15 finished with value: 0.7555555555555555 and parameters: {'C': 0.008554341019913762, 'c_weight': None}. Best is trial 3 with value: 0.7555555555555555.\u001b[0m\n",
      "\u001b[32m[I 2022-12-22 08:58:20,746]\u001b[0m Trial 16 finished with value: 0.7333333333333333 and parameters: {'C': 0.8104391995995778, 'c_weight': None}. Best is trial 3 with value: 0.7555555555555555.\u001b[0m\n",
      "\u001b[32m[I 2022-12-22 08:58:21,113]\u001b[0m Trial 17 finished with value: 0.7555555555555555 and parameters: {'C': 0.1961772918965143, 'c_weight': None}. Best is trial 3 with value: 0.7555555555555555.\u001b[0m\n",
      "\u001b[32m[I 2022-12-22 08:58:21,499]\u001b[0m Trial 18 finished with value: 0.7333333333333333 and parameters: {'C': 0.7374592696397181, 'c_weight': None}. Best is trial 3 with value: 0.7555555555555555.\u001b[0m\n",
      "\u001b[32m[I 2022-12-22 08:58:21,868]\u001b[0m Trial 19 finished with value: 0.7555555555555555 and parameters: {'C': 0.006777733726574991, 'c_weight': None}. Best is trial 3 with value: 0.7555555555555555.\u001b[0m\n",
      "\u001b[32m[I 2022-12-22 08:58:22,090]\u001b[0m Trial 20 finished with value: 0.7333333333333333 and parameters: {'C': 0.0003330759585550942, 'c_weight': None}. Best is trial 3 with value: 0.7555555555555555.\u001b[0m\n",
      "\u001b[32m[I 2022-12-22 08:58:22,456]\u001b[0m Trial 21 finished with value: 0.7555555555555555 and parameters: {'C': 0.0412965222076789, 'c_weight': None}. Best is trial 3 with value: 0.7555555555555555.\u001b[0m\n",
      "\u001b[32m[I 2022-12-22 08:58:22,823]\u001b[0m Trial 22 finished with value: 0.7555555555555555 and parameters: {'C': 0.02735079527088257, 'c_weight': None}. Best is trial 3 with value: 0.7555555555555555.\u001b[0m\n",
      "\u001b[32m[I 2022-12-22 08:58:23,279]\u001b[0m Trial 23 finished with value: 0.7333333333333333 and parameters: {'C': 0.24669575756791953, 'c_weight': None}. Best is trial 3 with value: 0.7555555555555555.\u001b[0m\n",
      "\u001b[32m[I 2022-12-22 08:58:23,645]\u001b[0m Trial 24 finished with value: 0.7111111111111111 and parameters: {'C': 8.710000812792748, 'c_weight': None}. Best is trial 3 with value: 0.7555555555555555.\u001b[0m\n",
      "\u001b[32m[I 2022-12-22 08:58:23,945]\u001b[0m Trial 25 finished with value: 0.7555555555555555 and parameters: {'C': 0.0013336945736723495, 'c_weight': None}. Best is trial 3 with value: 0.7555555555555555.\u001b[0m\n",
      "\u001b[32m[I 2022-12-22 08:58:24,310]\u001b[0m Trial 26 finished with value: 0.7555555555555555 and parameters: {'C': 0.03879637599273386, 'c_weight': None}. Best is trial 3 with value: 0.7555555555555555.\u001b[0m\n",
      "\u001b[32m[I 2022-12-22 08:58:24,440]\u001b[0m Trial 27 finished with value: 0.4888888888888889 and parameters: {'C': 7.682362071578691e-06, 'c_weight': None}. Best is trial 3 with value: 0.7555555555555555.\u001b[0m\n",
      "\u001b[32m[I 2022-12-22 08:58:24,735]\u001b[0m Trial 28 finished with value: 0.7555555555555555 and parameters: {'C': 0.0017569628467675232, 'c_weight': None}. Best is trial 3 with value: 0.7555555555555555.\u001b[0m\n",
      "\u001b[32m[I 2022-12-22 08:58:25,031]\u001b[0m Trial 29 finished with value: 0.7333333333333333 and parameters: {'C': 0.000959461689397523, 'c_weight': None}. Best is trial 3 with value: 0.7555555555555555.\u001b[0m\n",
      "\u001b[32m[I 2022-12-22 08:58:25,391]\u001b[0m Trial 30 finished with value: 0.7777777777777778 and parameters: {'C': 0.004052319622429073, 'c_weight': None}. Best is trial 30 with value: 0.7777777777777778.\u001b[0m\n",
      "\u001b[32m[I 2022-12-22 08:58:25,750]\u001b[0m Trial 31 finished with value: 0.7555555555555555 and parameters: {'C': 0.0016129520120208001, 'c_weight': None}. Best is trial 30 with value: 0.7777777777777778.\u001b[0m\n",
      "\u001b[32m[I 2022-12-22 08:58:26,099]\u001b[0m Trial 32 finished with value: 0.7555555555555555 and parameters: {'C': 0.005545857008672336, 'c_weight': None}. Best is trial 30 with value: 0.7777777777777778.\u001b[0m\n",
      "\u001b[32m[I 2022-12-22 08:58:26,293]\u001b[0m Trial 33 finished with value: 0.7333333333333333 and parameters: {'C': 0.00035065372625979685, 'c_weight': None}. Best is trial 30 with value: 0.7777777777777778.\u001b[0m\n",
      "\u001b[32m[I 2022-12-22 08:58:26,652]\u001b[0m Trial 34 finished with value: 0.7333333333333333 and parameters: {'C': 0.4225351370189133, 'c_weight': None}. Best is trial 30 with value: 0.7777777777777778.\u001b[0m\n",
      "\u001b[32m[I 2022-12-22 08:58:27,012]\u001b[0m Trial 35 finished with value: 0.7555555555555555 and parameters: {'C': 0.07327824939677575, 'c_weight': None}. Best is trial 30 with value: 0.7777777777777778.\u001b[0m\n",
      "\u001b[32m[I 2022-12-22 08:58:27,372]\u001b[0m Trial 36 finished with value: 0.7333333333333333 and parameters: {'C': 2.387400896342157, 'c_weight': 'balanced'}. Best is trial 30 with value: 0.7777777777777778.\u001b[0m\n",
      "\u001b[32m[I 2022-12-22 08:58:27,827]\u001b[0m Trial 37 finished with value: 0.7555555555555555 and parameters: {'C': 0.04247766673175269, 'c_weight': None}. Best is trial 30 with value: 0.7777777777777778.\u001b[0m\n",
      "\u001b[32m[I 2022-12-22 08:58:28,185]\u001b[0m Trial 38 finished with value: 0.7333333333333333 and parameters: {'C': 0.0051635242819548025, 'c_weight': 'balanced'}. Best is trial 30 with value: 0.7777777777777778.\u001b[0m\n",
      "\u001b[32m[I 2022-12-22 08:58:28,446]\u001b[0m Trial 39 finished with value: 0.7333333333333333 and parameters: {'C': 0.0004837458100858956, 'c_weight': None}. Best is trial 30 with value: 0.7777777777777778.\u001b[0m\n",
      "\u001b[32m[I 2022-12-22 08:58:28,544]\u001b[0m Trial 40 finished with value: 0.7333333333333333 and parameters: {'C': 9.187505210487177e-05, 'c_weight': 'balanced'}. Best is trial 30 with value: 0.7777777777777778.\u001b[0m\n",
      "\u001b[32m[I 2022-12-22 08:58:28,902]\u001b[0m Trial 41 finished with value: 0.7555555555555555 and parameters: {'C': 0.017055810194372786, 'c_weight': None}. Best is trial 30 with value: 0.7777777777777778.\u001b[0m\n",
      "\u001b[32m[I 2022-12-22 08:58:29,262]\u001b[0m Trial 42 finished with value: 0.7555555555555555 and parameters: {'C': 0.023153109425924124, 'c_weight': None}. Best is trial 30 with value: 0.7777777777777778.\u001b[0m\n",
      "\u001b[32m[I 2022-12-22 08:58:29,620]\u001b[0m Trial 43 finished with value: 0.7555555555555555 and parameters: {'C': 0.005028617073693225, 'c_weight': None}. Best is trial 30 with value: 0.7777777777777778.\u001b[0m\n",
      "\u001b[32m[I 2022-12-22 08:58:29,974]\u001b[0m Trial 44 finished with value: 0.7555555555555555 and parameters: {'C': 0.05960021736256638, 'c_weight': None}. Best is trial 30 with value: 0.7777777777777778.\u001b[0m\n",
      "\u001b[32m[I 2022-12-22 08:58:30,334]\u001b[0m Trial 45 finished with value: 0.7555555555555555 and parameters: {'C': 0.019769145999472118, 'c_weight': None}. Best is trial 30 with value: 0.7777777777777778.\u001b[0m\n",
      "\u001b[32m[I 2022-12-22 08:58:30,645]\u001b[0m Trial 46 finished with value: 0.7333333333333333 and parameters: {'C': 0.014727257607607278, 'c_weight': 'balanced'}. Best is trial 30 with value: 0.7777777777777778.\u001b[0m\n",
      "\u001b[32m[I 2022-12-22 08:58:31,002]\u001b[0m Trial 47 finished with value: 0.7777777777777778 and parameters: {'C': 0.0035765652140418657, 'c_weight': None}. Best is trial 30 with value: 0.7777777777777778.\u001b[0m\n",
      "\u001b[32m[I 2022-12-22 08:58:31,266]\u001b[0m Trial 48 finished with value: 0.7333333333333333 and parameters: {'C': 0.001196683145040612, 'c_weight': None}. Best is trial 30 with value: 0.7777777777777778.\u001b[0m\n",
      "\u001b[32m[I 2022-12-22 08:58:31,501]\u001b[0m Trial 49 finished with value: 0.4888888888888889 and parameters: {'C': 2.5723458514261133e-05, 'c_weight': None}. Best is trial 30 with value: 0.7777777777777778.\u001b[0m\n",
      "\u001b[32m[I 2022-12-22 08:58:31,862]\u001b[0m Trial 50 finished with value: 0.7555555555555555 and parameters: {'C': 0.05667944859546918, 'c_weight': None}. Best is trial 30 with value: 0.7777777777777778.\u001b[0m\n",
      "\u001b[32m[I 2022-12-22 08:58:32,223]\u001b[0m Trial 51 finished with value: 0.7555555555555555 and parameters: {'C': 0.0025486044867576788, 'c_weight': None}. Best is trial 30 with value: 0.7777777777777778.\u001b[0m\n",
      "\u001b[32m[I 2022-12-22 08:58:32,360]\u001b[0m Trial 52 finished with value: 0.4888888888888889 and parameters: {'C': 2.7852321284499354e-07, 'c_weight': None}. Best is trial 30 with value: 0.7777777777777778.\u001b[0m\n",
      "\u001b[32m[I 2022-12-22 08:58:32,707]\u001b[0m Trial 53 finished with value: 0.7555555555555555 and parameters: {'C': 0.0020063308272184155, 'c_weight': None}. Best is trial 30 with value: 0.7777777777777778.\u001b[0m\n",
      "\u001b[32m[I 2022-12-22 08:58:32,962]\u001b[0m Trial 54 finished with value: 0.7333333333333333 and parameters: {'C': 0.0008847467180814366, 'c_weight': None}. Best is trial 30 with value: 0.7777777777777778.\u001b[0m\n",
      "\u001b[32m[I 2022-12-22 08:58:33,302]\u001b[0m Trial 55 finished with value: 0.7555555555555555 and parameters: {'C': 0.0024323273706415138, 'c_weight': None}. Best is trial 30 with value: 0.7777777777777778.\u001b[0m\n",
      "\u001b[32m[I 2022-12-22 08:58:33,467]\u001b[0m Trial 56 finished with value: 0.6444444444444445 and parameters: {'C': 0.00017008147288964212, 'c_weight': None}. Best is trial 30 with value: 0.7777777777777778.\u001b[0m\n",
      "\u001b[32m[I 2022-12-22 08:58:33,861]\u001b[0m Trial 57 finished with value: 0.7333333333333333 and parameters: {'C': 0.008848814231970599, 'c_weight': 'balanced'}. Best is trial 30 with value: 0.7777777777777778.\u001b[0m\n",
      "\u001b[32m[I 2022-12-22 08:58:34,225]\u001b[0m Trial 58 finished with value: 0.7777777777777778 and parameters: {'C': 0.003861370817082751, 'c_weight': None}. Best is trial 30 with value: 0.7777777777777778.\u001b[0m\n",
      "\u001b[32m[I 2022-12-22 08:58:34,580]\u001b[0m Trial 59 finished with value: 0.7777777777777778 and parameters: {'C': 0.003696265468894365, 'c_weight': None}. Best is trial 30 with value: 0.7777777777777778.\u001b[0m\n",
      "\u001b[32m[I 2022-12-22 08:58:35,031]\u001b[0m Trial 60 finished with value: 0.7777777777777778 and parameters: {'C': 0.00449987654750606, 'c_weight': None}. Best is trial 30 with value: 0.7777777777777778.\u001b[0m\n",
      "\u001b[32m[I 2022-12-22 08:58:35,361]\u001b[0m Trial 61 finished with value: 0.7777777777777778 and parameters: {'C': 0.003815339871755372, 'c_weight': None}. Best is trial 30 with value: 0.7777777777777778.\u001b[0m\n",
      "\u001b[32m[I 2022-12-22 08:58:35,733]\u001b[0m Trial 62 finished with value: 0.7777777777777778 and parameters: {'C': 0.0034727436439521146, 'c_weight': None}. Best is trial 30 with value: 0.7777777777777778.\u001b[0m\n",
      "\u001b[32m[I 2022-12-22 08:58:35,993]\u001b[0m Trial 63 finished with value: 0.7333333333333333 and parameters: {'C': 0.0007156935571950721, 'c_weight': None}. Best is trial 30 with value: 0.7777777777777778.\u001b[0m\n",
      "\u001b[32m[I 2022-12-22 08:58:36,350]\u001b[0m Trial 64 finished with value: 0.7555555555555555 and parameters: {'C': 0.004332915774638124, 'c_weight': None}. Best is trial 30 with value: 0.7777777777777778.\u001b[0m\n",
      "\u001b[32m[I 2022-12-22 08:58:36,701]\u001b[0m Trial 65 finished with value: 0.7555555555555555 and parameters: {'C': 0.011977783384829983, 'c_weight': None}. Best is trial 30 with value: 0.7777777777777778.\u001b[0m\n",
      "\u001b[32m[I 2022-12-22 08:58:36,893]\u001b[0m Trial 66 finished with value: 0.6888888888888889 and parameters: {'C': 0.00021691317907024973, 'c_weight': None}. Best is trial 30 with value: 0.7777777777777778.\u001b[0m\n",
      "\u001b[32m[I 2022-12-22 08:58:37,210]\u001b[0m Trial 67 finished with value: 0.7777777777777778 and parameters: {'C': 0.0030228231979629876, 'c_weight': None}. Best is trial 30 with value: 0.7777777777777778.\u001b[0m\n",
      "\u001b[32m[I 2022-12-22 08:58:37,449]\u001b[0m Trial 68 finished with value: 0.7333333333333333 and parameters: {'C': 0.0006290963557489389, 'c_weight': None}. Best is trial 30 with value: 0.7777777777777778.\u001b[0m\n",
      "\u001b[32m[I 2022-12-22 08:58:37,811]\u001b[0m Trial 69 finished with value: 0.7555555555555555 and parameters: {'C': 0.00912642305661769, 'c_weight': None}. Best is trial 30 with value: 0.7777777777777778.\u001b[0m\n",
      "\u001b[32m[I 2022-12-22 08:58:38,264]\u001b[0m Trial 70 finished with value: 0.7777777777777778 and parameters: {'C': 0.0028228140148383366, 'c_weight': None}. Best is trial 30 with value: 0.7777777777777778.\u001b[0m\n",
      "\u001b[32m[I 2022-12-22 08:58:38,631]\u001b[0m Trial 71 finished with value: 0.7555555555555555 and parameters: {'C': 0.0025901834414795446, 'c_weight': None}. Best is trial 30 with value: 0.7777777777777778.\u001b[0m\n",
      "\u001b[32m[I 2022-12-22 08:58:38,991]\u001b[0m Trial 72 finished with value: 0.7555555555555555 and parameters: {'C': 0.008009124737495002, 'c_weight': None}. Best is trial 30 with value: 0.7777777777777778.\u001b[0m\n",
      "\u001b[32m[I 2022-12-22 08:58:39,353]\u001b[0m Trial 73 finished with value: 0.7777777777777778 and parameters: {'C': 0.0034498191282607803, 'c_weight': None}. Best is trial 30 with value: 0.7777777777777778.\u001b[0m\n",
      "\u001b[32m[I 2022-12-22 08:58:39,559]\u001b[0m Trial 74 finished with value: 0.7333333333333333 and parameters: {'C': 0.00033269448133416146, 'c_weight': None}. Best is trial 30 with value: 0.7777777777777778.\u001b[0m\n",
      "\u001b[32m[I 2022-12-22 08:58:39,824]\u001b[0m Trial 75 finished with value: 0.7555555555555555 and parameters: {'C': 0.001240621181375535, 'c_weight': None}. Best is trial 30 with value: 0.7777777777777778.\u001b[0m\n",
      "\u001b[32m[I 2022-12-22 08:58:40,182]\u001b[0m Trial 76 finished with value: 0.7555555555555555 and parameters: {'C': 0.030031823000149446, 'c_weight': None}. Best is trial 30 with value: 0.7777777777777778.\u001b[0m\n",
      "\u001b[32m[I 2022-12-22 08:58:40,544]\u001b[0m Trial 77 finished with value: 0.7333333333333333 and parameters: {'C': 0.004792980572447257, 'c_weight': 'balanced'}. Best is trial 30 with value: 0.7777777777777778.\u001b[0m\n",
      "\u001b[32m[I 2022-12-22 08:58:40,903]\u001b[0m Trial 78 finished with value: 0.7555555555555555 and parameters: {'C': 0.011187244975509518, 'c_weight': None}. Best is trial 30 with value: 0.7777777777777778.\u001b[0m\n",
      "\u001b[32m[I 2022-12-22 08:58:41,353]\u001b[0m Trial 79 finished with value: 0.7555555555555555 and parameters: {'C': 0.11462627199909971, 'c_weight': None}. Best is trial 30 with value: 0.7777777777777778.\u001b[0m\n",
      "\u001b[32m[I 2022-12-22 08:58:41,560]\u001b[0m Trial 80 finished with value: 0.7333333333333333 and parameters: {'C': 0.0004647298947682041, 'c_weight': None}. Best is trial 30 with value: 0.7777777777777778.\u001b[0m\n",
      "\u001b[32m[I 2022-12-22 08:58:41,921]\u001b[0m Trial 81 finished with value: 0.7777777777777778 and parameters: {'C': 0.0028109534905854804, 'c_weight': None}. Best is trial 30 with value: 0.7777777777777778.\u001b[0m\n",
      "\u001b[32m[I 2022-12-22 08:58:42,286]\u001b[0m Trial 82 finished with value: 0.7777777777777778 and parameters: {'C': 0.0031292198015694665, 'c_weight': None}. Best is trial 30 with value: 0.7777777777777778.\u001b[0m\n",
      "\u001b[32m[I 2022-12-22 08:58:42,600]\u001b[0m Trial 83 finished with value: 0.7555555555555555 and parameters: {'C': 0.0018159042699393702, 'c_weight': None}. Best is trial 30 with value: 0.7777777777777778.\u001b[0m\n",
      "\u001b[32m[I 2022-12-22 08:58:42,962]\u001b[0m Trial 84 finished with value: 0.7555555555555555 and parameters: {'C': 0.007169917573980994, 'c_weight': None}. Best is trial 30 with value: 0.7777777777777778.\u001b[0m\n",
      "\u001b[32m[I 2022-12-22 08:58:43,280]\u001b[0m Trial 85 finished with value: 0.7555555555555555 and parameters: {'C': 0.0015681675117416825, 'c_weight': None}. Best is trial 30 with value: 0.7777777777777778.\u001b[0m\n",
      "\u001b[32m[I 2022-12-22 08:58:43,576]\u001b[0m Trial 86 finished with value: 0.7333333333333333 and parameters: {'C': 0.0009560290767458558, 'c_weight': None}. Best is trial 30 with value: 0.7777777777777778.\u001b[0m\n",
      "\u001b[32m[I 2022-12-22 08:58:43,943]\u001b[0m Trial 87 finished with value: 0.7777777777777778 and parameters: {'C': 0.002885945848514038, 'c_weight': None}. Best is trial 30 with value: 0.7777777777777778.\u001b[0m\n",
      "\u001b[32m[I 2022-12-22 08:58:44,368]\u001b[0m Trial 88 finished with value: 0.7777777777777778 and parameters: {'C': 0.0036740170575659315, 'c_weight': None}. Best is trial 30 with value: 0.7777777777777778.\u001b[0m\n",
      "\u001b[32m[I 2022-12-22 08:58:44,648]\u001b[0m Trial 89 finished with value: 0.7333333333333333 and parameters: {'C': 0.013250939087275856, 'c_weight': 'balanced'}. Best is trial 30 with value: 0.7777777777777778.\u001b[0m\n",
      "\u001b[32m[I 2022-12-22 08:58:45,010]\u001b[0m Trial 90 finished with value: 0.7555555555555555 and parameters: {'C': 0.006407761410437184, 'c_weight': None}. Best is trial 30 with value: 0.7777777777777778.\u001b[0m\n",
      "\u001b[32m[I 2022-12-22 08:58:45,372]\u001b[0m Trial 91 finished with value: 0.7777777777777778 and parameters: {'C': 0.0031102619409834596, 'c_weight': None}. Best is trial 30 with value: 0.7777777777777778.\u001b[0m\n",
      "\u001b[32m[I 2022-12-22 08:58:45,732]\u001b[0m Trial 92 finished with value: 0.7777777777777778 and parameters: {'C': 0.003943831506883551, 'c_weight': None}. Best is trial 30 with value: 0.7777777777777778.\u001b[0m\n",
      "\u001b[32m[I 2022-12-22 08:58:46,018]\u001b[0m Trial 93 finished with value: 0.7333333333333333 and parameters: {'C': 0.001210774987471192, 'c_weight': None}. Best is trial 30 with value: 0.7777777777777778.\u001b[0m\n",
      "\u001b[32m[I 2022-12-22 08:58:46,362]\u001b[0m Trial 94 finished with value: 0.7555555555555555 and parameters: {'C': 0.002042037745823747, 'c_weight': None}. Best is trial 30 with value: 0.7777777777777778.\u001b[0m\n",
      "\u001b[32m[I 2022-12-22 08:58:46,726]\u001b[0m Trial 95 finished with value: 0.7555555555555555 and parameters: {'C': 0.005857605889945559, 'c_weight': None}. Best is trial 30 with value: 0.7777777777777778.\u001b[0m\n",
      "\u001b[32m[I 2022-12-22 08:58:47,089]\u001b[0m Trial 96 finished with value: 0.7555555555555555 and parameters: {'C': 0.020042443398415405, 'c_weight': None}. Best is trial 30 with value: 0.7777777777777778.\u001b[0m\n",
      "\u001b[32m[I 2022-12-22 08:58:47,346]\u001b[0m Trial 97 finished with value: 0.7333333333333333 and parameters: {'C': 0.0005761479055124202, 'c_weight': None}. Best is trial 30 with value: 0.7777777777777778.\u001b[0m\n",
      "\u001b[32m[I 2022-12-22 08:58:47,709]\u001b[0m Trial 98 finished with value: 0.7555555555555555 and parameters: {'C': 0.03071373038973141, 'c_weight': None}. Best is trial 30 with value: 0.7777777777777778.\u001b[0m\n",
      "\u001b[32m[I 2022-12-22 08:58:47,940]\u001b[0m Trial 99 finished with value: 0.7333333333333333 and parameters: {'C': 0.0008273192020217239, 'c_weight': None}. Best is trial 30 with value: 0.7777777777777778.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7777777777777778\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "print(study.best_trial.value)  # Show the best value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.004052319622429073, 'c_weight': None}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detailed_objective(trial):\n",
    "    # Use same code objective to reproduce the best model\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "\n",
    "    C = trial.suggest_float(\"C\", 1e-7, 10.0, log=True)\n",
    "    c_weight = trial.suggest_categorical(\"c_weight\", [\"balanced\", None])\n",
    "\n",
    "    clf = LogisticRegression(C=C, class_weight=c_weight)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # calculate more evaluation metrics\n",
    "    pred = clf.predict(X_test)\n",
    "\n",
    "    acc = accuracy_score(pred, y_test)\n",
    "    recall = recall_score(pred, y_test, average=\"weighted\")\n",
    "    precision = precision_score(pred, y_test, average=\"weighted\")\n",
    "    f1 = f1_score(pred, y_test, average=\"weighted\")\n",
    "\n",
    "    return acc, f1, recall, precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7777777777777778,\n",
       " 0.8248888888888888,\n",
       " 0.7777777777777778,\n",
       " 0.8877665544332211)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detailed_objective(study.best_trial)  # calculate acc, f1, recall, and precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "\n",
    "    C = trial.suggest_float(\"C\", 1e-7, 10.0, log=True)\n",
    "    c_weight = trial.suggest_categorical(\"c_weight\", [\"balanced\", None])\n",
    "\n",
    "    clf = LogisticRegression(C=C, class_weight=c_weight)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    pred = clf.predict(X_test)\n",
    "\n",
    "    acc = accuracy_score(pred, y_test)\n",
    "    recall = recall_score(pred, y_test, average=\"weighted\")\n",
    "    precision = precision_score(pred, y_test, average=\"weighted\")\n",
    "    f1 = f1_score(pred, y_test, average=\"weighted\")\n",
    "\n",
    "    return acc, f1, recall, precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-12-22 09:01:14,934]\u001b[0m A new study created in memory with name: no-name-f511ae16-556c-4541-a24d-d8ca5b8b6db2\u001b[0m\n",
      "\u001b[32m[I 2022-12-22 09:01:15,340]\u001b[0m Trial 0 finished with values: [0.7333333333333333, 0.7766579569491103, 0.7333333333333333, 0.8254769921436588] and parameters: {'C': 0.1817396676605602, 'c_weight': 'balanced'}. \u001b[0m\n",
      "\u001b[32m[I 2022-12-22 09:01:15,772]\u001b[0m Trial 1 finished with values: [0.7111111111111111, 0.7541041041041041, 0.7111111111111111, 0.8039281705948372] and parameters: {'C': 0.756685056748626, 'c_weight': None}. \u001b[0m\n",
      "\u001b[32m[I 2022-12-22 09:01:15,921]\u001b[0m Trial 2 finished with values: [0.4888888888888889, 0.6567164179104478, 0.4888888888888889, 1.0] and parameters: {'C': 6.0059332588676985e-06, 'c_weight': None}. \u001b[0m\n",
      "\u001b[32m[I 2022-12-22 09:01:16,469]\u001b[0m Trial 3 finished with values: [0.7777777777777778, 0.8248888888888888, 0.7777777777777778, 0.8877665544332211] and parameters: {'C': 0.00334141326704672, 'c_weight': None}. \u001b[0m\n",
      "\u001b[32m[I 2022-12-22 09:01:16,543]\u001b[0m Trial 4 finished with values: [0.7333333333333333, 0.7446332737030411, 0.7333333333333333, 0.7628282828282829] and parameters: {'C': 1.194393977748893e-06, 'c_weight': 'balanced'}. \u001b[0m\n",
      "\u001b[32m[I 2022-12-22 09:01:16,624]\u001b[0m Trial 5 finished with values: [0.7333333333333333, 0.7446332737030411, 0.7333333333333333, 0.7628282828282829] and parameters: {'C': 2.172791402918669e-06, 'c_weight': 'balanced'}. \u001b[0m\n",
      "\u001b[32m[I 2022-12-22 09:01:16,779]\u001b[0m Trial 6 finished with values: [0.4888888888888889, 0.6567164179104478, 0.4888888888888889, 1.0] and parameters: {'C': 5.727408720496117e-07, 'c_weight': None}. \u001b[0m\n",
      "\u001b[32m[I 2022-12-22 09:01:16,811]\u001b[0m Trial 7 finished with values: [0.4, 0.5714285714285715, 0.4, 1.0] and parameters: {'C': 1.840077908867879e-07, 'c_weight': 'balanced'}. \u001b[0m\n",
      "\u001b[32m[I 2022-12-22 09:01:17,213]\u001b[0m Trial 8 finished with values: [0.7555555555555555, 0.8010010010010009, 0.7555555555555555, 0.8536475869809202] and parameters: {'C': 0.030271041160129467, 'c_weight': 'balanced'}. \u001b[0m\n",
      "\u001b[32m[I 2022-12-22 09:01:17,429]\u001b[0m Trial 9 finished with values: [0.7333333333333333, 0.7483573274270948, 0.7333333333333333, 0.7769023569023569] and parameters: {'C': 0.00015753112698944135, 'c_weight': 'balanced'}. \u001b[0m\n",
      "\u001b[32m[I 2022-12-22 09:01:17,828]\u001b[0m Trial 10 finished with values: [0.7333333333333333, 0.7766579569491103, 0.7333333333333333, 0.8254769921436588] and parameters: {'C': 0.5126914863309172, 'c_weight': 'balanced'}. \u001b[0m\n",
      "\u001b[32m[I 2022-12-22 09:01:18,184]\u001b[0m Trial 11 finished with values: [0.7333333333333333, 0.7766579569491103, 0.7333333333333333, 0.8254769921436588] and parameters: {'C': 0.012953011222330033, 'c_weight': 'balanced'}. \u001b[0m\n",
      "\u001b[32m[I 2022-12-22 09:01:18,618]\u001b[0m Trial 12 finished with values: [0.7333333333333333, 0.7786848072562359, 0.7333333333333333, 0.8343434343434344] and parameters: {'C': 1.8295680431244765, 'c_weight': None}. \u001b[0m\n",
      "\u001b[32m[I 2022-12-22 09:01:18,986]\u001b[0m Trial 13 finished with values: [0.7333333333333333, 0.7786848072562359, 0.7333333333333333, 0.8343434343434344] and parameters: {'C': 1.509905762656397, 'c_weight': None}. \u001b[0m\n",
      "\u001b[32m[I 2022-12-22 09:01:19,113]\u001b[0m Trial 14 finished with values: [0.4, 0.5714285714285715, 0.4, 1.0] and parameters: {'C': 7.027458354432215e-07, 'c_weight': 'balanced'}. \u001b[0m\n",
      "\u001b[32m[I 2022-12-22 09:01:19,140]\u001b[0m Trial 15 finished with values: [0.4, 0.5714285714285715, 0.4, 1.0] and parameters: {'C': 5.16867925962473e-07, 'c_weight': 'balanced'}. \u001b[0m\n",
      "\u001b[32m[I 2022-12-22 09:01:19,511]\u001b[0m Trial 16 finished with values: [0.7555555555555555, 0.8010010010010009, 0.7555555555555555, 0.8536475869809202] and parameters: {'C': 0.11488618279798761, 'c_weight': None}. \u001b[0m\n",
      "\u001b[32m[I 2022-12-22 09:01:19,906]\u001b[0m Trial 17 finished with values: [0.7555555555555555, 0.8009070294784582, 0.7555555555555555, 0.8565656565656566] and parameters: {'C': 0.0063605468888149755, 'c_weight': None}. \u001b[0m\n",
      "\u001b[32m[I 2022-12-22 09:01:20,058]\u001b[0m Trial 18 finished with values: [0.4888888888888889, 0.6567164179104478, 0.4888888888888889, 1.0] and parameters: {'C': 1.0946557027804699e-07, 'c_weight': None}. \u001b[0m\n",
      "\u001b[32m[I 2022-12-22 09:01:20,130]\u001b[0m Trial 19 finished with values: [0.7333333333333333, 0.7446332737030411, 0.7333333333333333, 0.7628282828282829] and parameters: {'C': 7.515169624392001e-06, 'c_weight': 'balanced'}. \u001b[0m\n",
      "\u001b[32m[I 2022-12-22 09:01:20,201]\u001b[0m Trial 20 finished with values: [0.7333333333333333, 0.7446332737030411, 0.7333333333333333, 0.7628282828282829] and parameters: {'C': 1.4117217252320634e-06, 'c_weight': 'balanced'}. \u001b[0m\n",
      "\u001b[32m[I 2022-12-22 09:01:20,545]\u001b[0m Trial 21 finished with values: [0.7333333333333333, 0.7661375661375662, 0.7333333333333333, 0.8175084175084174] and parameters: {'C': 0.0010515644285543685, 'c_weight': 'balanced'}. \u001b[0m\n",
      "\u001b[32m[I 2022-12-22 09:01:20,914]\u001b[0m Trial 22 finished with values: [0.7111111111111111, 0.7541041041041041, 0.7111111111111111, 0.8039281705948372] and parameters: {'C': 9.192267743569236, 'c_weight': None}. \u001b[0m\n",
      "\u001b[32m[I 2022-12-22 09:01:20,940]\u001b[0m Trial 23 finished with values: [0.4, 0.5714285714285715, 0.4, 1.0] and parameters: {'C': 1.9206615632673494e-07, 'c_weight': 'balanced'}. \u001b[0m\n",
      "\u001b[32m[I 2022-12-22 09:01:21,170]\u001b[0m Trial 24 finished with values: [0.4888888888888889, 0.6567164179104478, 0.4888888888888889, 1.0] and parameters: {'C': 4.213347000944026e-06, 'c_weight': None}. \u001b[0m\n",
      "\u001b[32m[I 2022-12-22 09:01:21,295]\u001b[0m Trial 25 finished with values: [0.4888888888888889, 0.6567164179104478, 0.4888888888888889, 1.0] and parameters: {'C': 1.82938418284745e-05, 'c_weight': None}. \u001b[0m\n",
      "\u001b[32m[I 2022-12-22 09:01:21,541]\u001b[0m Trial 26 finished with values: [0.7111111111111111, 0.7444444444444445, 0.7111111111111111, 0.7851851851851852] and parameters: {'C': 0.0004152670639392383, 'c_weight': 'balanced'}. \u001b[0m\n",
      "\u001b[32m[I 2022-12-22 09:01:21,746]\u001b[0m Trial 27 finished with values: [0.7333333333333333, 0.779245283018868, 0.7333333333333333, 0.864983164983165] and parameters: {'C': 0.00031303085297272365, 'c_weight': None}. \u001b[0m\n",
      "\u001b[32m[I 2022-12-22 09:01:21,906]\u001b[0m Trial 28 finished with values: [0.5333333333333333, 0.6557264957264958, 0.5333333333333333, 0.9604938271604938] and parameters: {'C': 8.182328977043016e-05, 'c_weight': None}. \u001b[0m\n",
      "\u001b[32m[I 2022-12-22 09:01:22,265]\u001b[0m Trial 29 finished with values: [0.7333333333333333, 0.7766579569491103, 0.7333333333333333, 0.8254769921436588] and parameters: {'C': 1.5603952906633851, 'c_weight': 'balanced'}. \u001b[0m\n",
      "\u001b[32m[I 2022-12-22 09:01:22,396]\u001b[0m Trial 30 finished with values: [0.4888888888888889, 0.6567164179104478, 0.4888888888888889, 1.0] and parameters: {'C': 4.408083750717457e-07, 'c_weight': None}. \u001b[0m\n",
      "\u001b[32m[I 2022-12-22 09:01:22,687]\u001b[0m Trial 31 finished with values: [0.7333333333333333, 0.7661375661375662, 0.7333333333333333, 0.8175084175084174] and parameters: {'C': 0.0008084906550875212, 'c_weight': 'balanced'}. \u001b[0m\n",
      "\u001b[32m[I 2022-12-22 09:01:22,828]\u001b[0m Trial 32 finished with values: [0.4888888888888889, 0.6567164179104478, 0.4888888888888889, 1.0] and parameters: {'C': 1.5370852538400068e-07, 'c_weight': None}. \u001b[0m\n",
      "\u001b[32m[I 2022-12-22 09:01:22,986]\u001b[0m Trial 33 finished with values: [0.7333333333333333, 0.7446332737030411, 0.7333333333333333, 0.7628282828282829] and parameters: {'C': 2.9546024858190094e-06, 'c_weight': 'balanced'}. \u001b[0m\n",
      "\u001b[32m[I 2022-12-22 09:01:23,354]\u001b[0m Trial 34 finished with values: [0.7111111111111111, 0.7541041041041041, 0.7111111111111111, 0.8039281705948372] and parameters: {'C': 6.503076977226656, 'c_weight': 'balanced'}. \u001b[0m\n",
      "\u001b[32m[I 2022-12-22 09:01:23,718]\u001b[0m Trial 35 finished with values: [0.7333333333333333, 0.7766579569491103, 0.7333333333333333, 0.8254769921436588] and parameters: {'C': 1.1620578756892097, 'c_weight': 'balanced'}. \u001b[0m\n",
      "\u001b[32m[I 2022-12-22 09:01:23,944]\u001b[0m Trial 36 finished with values: [0.7333333333333333, 0.779245283018868, 0.7333333333333333, 0.864983164983165] and parameters: {'C': 0.00044584478638845423, 'c_weight': None}. \u001b[0m\n",
      "\u001b[32m[I 2022-12-22 09:01:24,008]\u001b[0m Trial 37 finished with values: [0.7333333333333333, 0.7446332737030411, 0.7333333333333333, 0.7628282828282829] and parameters: {'C': 2.824885318106291e-06, 'c_weight': 'balanced'}. \u001b[0m\n",
      "\u001b[32m[I 2022-12-22 09:01:24,370]\u001b[0m Trial 38 finished with values: [0.7333333333333333, 0.7766579569491103, 0.7333333333333333, 0.8254769921436588] and parameters: {'C': 1.6745210533295076, 'c_weight': 'balanced'}. \u001b[0m\n",
      "\u001b[32m[I 2022-12-22 09:01:24,395]\u001b[0m Trial 39 finished with values: [0.4, 0.5714285714285715, 0.4, 1.0] and parameters: {'C': 7.052208286393748e-07, 'c_weight': 'balanced'}. \u001b[0m\n",
      "\u001b[32m[I 2022-12-22 09:01:24,422]\u001b[0m Trial 40 finished with values: [0.4, 0.5714285714285715, 0.4, 1.0] and parameters: {'C': 4.0163409491923076e-07, 'c_weight': 'balanced'}. \u001b[0m\n",
      "\u001b[32m[I 2022-12-22 09:01:24,786]\u001b[0m Trial 41 finished with values: [0.7555555555555555, 0.8010010010010009, 0.7555555555555555, 0.8536475869809202] and parameters: {'C': 0.041857324574661396, 'c_weight': 'balanced'}. \u001b[0m\n",
      "\u001b[32m[I 2022-12-22 09:01:24,952]\u001b[0m Trial 42 finished with values: [0.7333333333333333, 0.7446332737030411, 0.7333333333333333, 0.7628282828282829] and parameters: {'C': 8.839305013689581e-06, 'c_weight': 'balanced'}. \u001b[0m\n",
      "\u001b[32m[I 2022-12-22 09:01:25,331]\u001b[0m Trial 43 finished with values: [0.7333333333333333, 0.7786848072562359, 0.7333333333333333, 0.8343434343434344] and parameters: {'C': 0.4687762991052327, 'c_weight': None}. \u001b[0m\n",
      "\u001b[32m[I 2022-12-22 09:01:25,468]\u001b[0m Trial 44 finished with values: [0.4888888888888889, 0.6567164179104478, 0.4888888888888889, 1.0] and parameters: {'C': 1.6929020417717633e-05, 'c_weight': None}. \u001b[0m\n",
      "\u001b[32m[I 2022-12-22 09:01:25,599]\u001b[0m Trial 45 finished with values: [0.4888888888888889, 0.6567164179104478, 0.4888888888888889, 1.0] and parameters: {'C': 1.791587296177834e-05, 'c_weight': None}. \u001b[0m\n",
      "\u001b[32m[I 2022-12-22 09:01:25,664]\u001b[0m Trial 46 finished with values: [0.7333333333333333, 0.7446332737030411, 0.7333333333333333, 0.7628282828282829] and parameters: {'C': 1.3501025598183218e-06, 'c_weight': 'balanced'}. \u001b[0m\n",
      "\u001b[32m[I 2022-12-22 09:01:25,792]\u001b[0m Trial 47 finished with values: [0.4888888888888889, 0.6567164179104478, 0.4888888888888889, 1.0] and parameters: {'C': 3.8952288928811387e-07, 'c_weight': None}. \u001b[0m\n",
      "\u001b[32m[I 2022-12-22 09:01:26,157]\u001b[0m Trial 48 finished with values: [0.7111111111111111, 0.742975987899414, 0.7111111111111111, 0.7865319865319864] and parameters: {'C': 0.0019566168019184977, 'c_weight': 'balanced'}. \u001b[0m\n",
      "\u001b[32m[I 2022-12-22 09:01:26,254]\u001b[0m Trial 49 finished with values: [0.7333333333333333, 0.7483573274270948, 0.7333333333333333, 0.7769023569023569] and parameters: {'C': 8.310013771484163e-05, 'c_weight': 'balanced'}. \u001b[0m\n",
      "\u001b[32m[I 2022-12-22 09:01:26,627]\u001b[0m Trial 50 finished with values: [0.7555555555555555, 0.8010010010010009, 0.7555555555555555, 0.8536475869809202] and parameters: {'C': 0.1817396676605602, 'c_weight': None}. \u001b[0m\n",
      "\u001b[32m[I 2022-12-22 09:01:26,902]\u001b[0m Trial 51 finished with values: [0.7333333333333333, 0.7808857808857809, 0.7333333333333333, 0.8585858585858587] and parameters: {'C': 0.0010515644285543685, 'c_weight': None}. \u001b[0m\n",
      "\u001b[32m[I 2022-12-22 09:01:26,980]\u001b[0m Trial 52 finished with values: [0.7333333333333333, 0.7446332737030411, 0.7333333333333333, 0.7628282828282829] and parameters: {'C': 1.515190430474441e-05, 'c_weight': 'balanced'}. \u001b[0m\n",
      "\u001b[32m[I 2022-12-22 09:01:27,203]\u001b[0m Trial 53 finished with values: [0.7333333333333333, 0.779245283018868, 0.7333333333333333, 0.864983164983165] and parameters: {'C': 0.00044584478638845423, 'c_weight': None}. \u001b[0m\n",
      "\u001b[32m[I 2022-12-22 09:01:27,560]\u001b[0m Trial 54 finished with values: [0.7555555555555555, 0.8010010010010009, 0.7555555555555555, 0.8536475869809202] and parameters: {'C': 0.17380555619863927, 'c_weight': None}. \u001b[0m\n",
      "\u001b[32m[I 2022-12-22 09:01:27,914]\u001b[0m Trial 55 finished with values: [0.7555555555555555, 0.8009070294784582, 0.7555555555555555, 0.8565656565656566] and parameters: {'C': 0.0063605468888149755, 'c_weight': None}. \u001b[0m\n",
      "\u001b[32m[I 2022-12-22 09:01:28,117]\u001b[0m Trial 56 finished with values: [0.4888888888888889, 0.6567164179104478, 0.4888888888888889, 1.0] and parameters: {'C': 2.9546024858190094e-06, 'c_weight': None}. \u001b[0m\n",
      "\u001b[32m[I 2022-12-22 09:01:28,476]\u001b[0m Trial 57 finished with values: [0.7555555555555555, 0.8009070294784582, 0.7555555555555555, 0.8565656565656566] and parameters: {'C': 0.0063605468888149755, 'c_weight': None}. \u001b[0m\n",
      "\u001b[32m[I 2022-12-22 09:01:28,573]\u001b[0m Trial 58 finished with values: [0.7333333333333333, 0.7483573274270948, 0.7333333333333333, 0.7769023569023569] and parameters: {'C': 4.682329858340847e-05, 'c_weight': 'balanced'}. \u001b[0m\n",
      "\u001b[32m[I 2022-12-22 09:01:28,701]\u001b[0m Trial 59 finished with values: [0.4888888888888889, 0.6567164179104478, 0.4888888888888889, 1.0] and parameters: {'C': 6.343201371043475e-07, 'c_weight': None}. \u001b[0m\n",
      "\u001b[32m[I 2022-12-22 09:01:28,764]\u001b[0m Trial 60 finished with values: [0.7333333333333333, 0.7446332737030411, 0.7333333333333333, 0.7628282828282829] and parameters: {'C': 2.824885318106291e-06, 'c_weight': 'balanced'}. \u001b[0m\n",
      "\u001b[32m[I 2022-12-22 09:01:28,843]\u001b[0m Trial 61 finished with values: [0.7333333333333333, 0.7446332737030411, 0.7333333333333333, 0.7628282828282829] and parameters: {'C': 1.82938418284745e-05, 'c_weight': 'balanced'}. \u001b[0m\n",
      "\u001b[32m[I 2022-12-22 09:01:28,869]\u001b[0m Trial 62 finished with values: [0.4, 0.5714285714285715, 0.4, 1.0] and parameters: {'C': 1.3593861254793556e-07, 'c_weight': 'balanced'}. \u001b[0m\n",
      "\u001b[32m[I 2022-12-22 09:01:29,019]\u001b[0m Trial 63 finished with values: [0.4888888888888889, 0.6567164179104478, 0.4888888888888889, 1.0] and parameters: {'C': 1.0946557027804699e-07, 'c_weight': None}. \u001b[0m\n",
      "\u001b[32m[I 2022-12-22 09:01:29,094]\u001b[0m Trial 64 finished with values: [0.7333333333333333, 0.7446332737030411, 0.7333333333333333, 0.7628282828282829] and parameters: {'C': 2.384069864427158e-05, 'c_weight': 'balanced'}. \u001b[0m\n",
      "\u001b[32m[I 2022-12-22 09:01:29,431]\u001b[0m Trial 65 finished with values: [0.7777777777777778, 0.8248888888888888, 0.7777777777777778, 0.8877665544332211] and parameters: {'C': 0.003521405324906963, 'c_weight': None}. \u001b[0m\n",
      "\u001b[32m[I 2022-12-22 09:01:29,580]\u001b[0m Trial 66 finished with values: [0.4888888888888889, 0.6567164179104478, 0.4888888888888889, 1.0] and parameters: {'C': 1.0946557027804699e-07, 'c_weight': None}. \u001b[0m\n",
      "\u001b[32m[I 2022-12-22 09:01:29,939]\u001b[0m Trial 67 finished with values: [0.7777777777777778, 0.8248888888888888, 0.7777777777777778, 0.8877665544332211] and parameters: {'C': 0.00334141326704672, 'c_weight': None}. \u001b[0m\n",
      "\u001b[32m[I 2022-12-22 09:01:30,389]\u001b[0m Trial 68 finished with values: [0.7111111111111111, 0.7541041041041041, 0.7111111111111111, 0.8039281705948372] and parameters: {'C': 6.503076977226656, 'c_weight': None}. \u001b[0m\n",
      "\u001b[32m[I 2022-12-22 09:01:30,413]\u001b[0m Trial 69 finished with values: [0.4, 0.5714285714285715, 0.4, 1.0] and parameters: {'C': 7.052208286393748e-07, 'c_weight': 'balanced'}. \u001b[0m\n",
      "\u001b[32m[I 2022-12-22 09:01:30,776]\u001b[0m Trial 70 finished with values: [0.7333333333333333, 0.7786848072562359, 0.7333333333333333, 0.8343434343434344] and parameters: {'C': 0.595012401842864, 'c_weight': None}. \u001b[0m\n",
      "\u001b[32m[I 2022-12-22 09:01:30,801]\u001b[0m Trial 71 finished with values: [0.4, 0.5714285714285715, 0.4, 1.0] and parameters: {'C': 1.9329242481567762e-07, 'c_weight': 'balanced'}. \u001b[0m\n",
      "\u001b[32m[I 2022-12-22 09:01:31,159]\u001b[0m Trial 72 finished with values: [0.7111111111111111, 0.7541041041041041, 0.7111111111111111, 0.8039281705948372] and parameters: {'C': 4.451944795088444, 'c_weight': None}. \u001b[0m\n",
      "\u001b[32m[I 2022-12-22 09:01:31,431]\u001b[0m Trial 73 finished with values: [0.7333333333333333, 0.767908237221907, 0.7333333333333333, 0.8149270482603815] and parameters: {'C': 0.0007825740978741476, 'c_weight': 'balanced'}. \u001b[0m\n",
      "\u001b[32m[I 2022-12-22 09:01:31,554]\u001b[0m Trial 74 finished with values: [0.4888888888888889, 0.6567164179104478, 0.4888888888888889, 1.0] and parameters: {'C': 3.5430773284483997e-06, 'c_weight': None}. \u001b[0m\n",
      "\u001b[32m[I 2022-12-22 09:01:31,823]\u001b[0m Trial 75 finished with values: [0.7111111111111111, 0.7444444444444445, 0.7111111111111111, 0.7851851851851852] and parameters: {'C': 0.00043063708072781516, 'c_weight': 'balanced'}. \u001b[0m\n",
      "\u001b[32m[I 2022-12-22 09:01:31,953]\u001b[0m Trial 76 finished with values: [0.4888888888888889, 0.6567164179104478, 0.4888888888888889, 1.0] and parameters: {'C': 2.4772861244359134e-05, 'c_weight': None}. \u001b[0m\n",
      "\u001b[32m[I 2022-12-22 09:01:32,314]\u001b[0m Trial 77 finished with values: [0.7555555555555555, 0.8009070294784582, 0.7555555555555555, 0.8565656565656566] and parameters: {'C': 0.01172579814781858, 'c_weight': None}. \u001b[0m\n",
      "\u001b[32m[I 2022-12-22 09:01:32,685]\u001b[0m Trial 78 finished with values: [0.7111111111111111, 0.7524340393905612, 0.7111111111111111, 0.7993265993265993] and parameters: {'C': 0.00334141326704672, 'c_weight': 'balanced'}. \u001b[0m\n",
      "\u001b[32m[I 2022-12-22 09:01:33,133]\u001b[0m Trial 79 finished with values: [0.7555555555555555, 0.8010010010010009, 0.7555555555555555, 0.8536475869809202] and parameters: {'C': 0.11729180761038792, 'c_weight': None}. \u001b[0m\n",
      "\u001b[32m[I 2022-12-22 09:01:33,491]\u001b[0m Trial 80 finished with values: [0.7333333333333333, 0.7786848072562359, 0.7333333333333333, 0.8343434343434344] and parameters: {'C': 2.0383571484700505, 'c_weight': None}. \u001b[0m\n",
      "\u001b[32m[I 2022-12-22 09:01:33,847]\u001b[0m Trial 81 finished with values: [0.7555555555555555, 0.8010010010010009, 0.7555555555555555, 0.8536475869809202] and parameters: {'C': 0.12904533182447486, 'c_weight': None}. \u001b[0m\n",
      "\u001b[32m[I 2022-12-22 09:01:33,972]\u001b[0m Trial 82 finished with values: [0.4888888888888889, 0.6567164179104478, 0.4888888888888889, 1.0] and parameters: {'C': 1.265595025547944e-05, 'c_weight': None}. \u001b[0m\n",
      "\u001b[32m[I 2022-12-22 09:01:34,337]\u001b[0m Trial 83 finished with values: [0.7777777777777778, 0.8248888888888888, 0.7777777777777778, 0.8877665544332211] and parameters: {'C': 0.003479807667371505, 'c_weight': None}. \u001b[0m\n",
      "\u001b[32m[I 2022-12-22 09:01:34,700]\u001b[0m Trial 84 finished with values: [0.7555555555555555, 0.8010010010010009, 0.7555555555555555, 0.8536475869809202] and parameters: {'C': 0.02752613391839711, 'c_weight': None}. \u001b[0m\n",
      "\u001b[32m[I 2022-12-22 09:01:35,056]\u001b[0m Trial 85 finished with values: [0.7333333333333333, 0.7766579569491103, 0.7333333333333333, 0.8254769921436588] and parameters: {'C': 1.1621162206777587, 'c_weight': 'balanced'}. \u001b[0m\n",
      "\u001b[32m[I 2022-12-22 09:01:35,082]\u001b[0m Trial 86 finished with values: [0.4, 0.5714285714285715, 0.4, 1.0] and parameters: {'C': 1.9206615632673494e-07, 'c_weight': 'balanced'}. \u001b[0m\n",
      "\u001b[32m[I 2022-12-22 09:01:35,446]\u001b[0m Trial 87 finished with values: [0.7333333333333333, 0.7766579569491103, 0.7333333333333333, 0.8254769921436588] and parameters: {'C': 3.515703714318807, 'c_weight': 'balanced'}. \u001b[0m\n",
      "\u001b[32m[I 2022-12-22 09:01:35,471]\u001b[0m Trial 88 finished with values: [0.4, 0.5714285714285715, 0.4, 1.0] and parameters: {'C': 7.052208286393748e-07, 'c_weight': 'balanced'}. \u001b[0m\n",
      "\u001b[32m[I 2022-12-22 09:01:35,924]\u001b[0m Trial 89 finished with values: [0.7333333333333333, 0.7786848072562359, 0.7333333333333333, 0.8343434343434344] and parameters: {'C': 1.5603952906633851, 'c_weight': None}. \u001b[0m\n",
      "\u001b[32m[I 2022-12-22 09:01:35,949]\u001b[0m Trial 90 finished with values: [0.4, 0.5714285714285715, 0.4, 1.0] and parameters: {'C': 4.408083750717457e-07, 'c_weight': 'balanced'}. \u001b[0m\n",
      "\u001b[32m[I 2022-12-22 09:01:36,034]\u001b[0m Trial 91 finished with values: [0.7333333333333333, 0.7446332737030411, 0.7333333333333333, 0.7628282828282829] and parameters: {'C': 1.2383069184915904e-05, 'c_weight': 'balanced'}. \u001b[0m\n",
      "\u001b[32m[I 2022-12-22 09:01:36,392]\u001b[0m Trial 92 finished with values: [0.7777777777777778, 0.8248888888888888, 0.7777777777777778, 0.8877665544332211] and parameters: {'C': 0.00334141326704672, 'c_weight': None}. \u001b[0m\n",
      "\u001b[32m[I 2022-12-22 09:01:36,755]\u001b[0m Trial 93 finished with values: [0.7333333333333333, 0.7766579569491103, 0.7333333333333333, 0.8254769921436588] and parameters: {'C': 1.5603952906633851, 'c_weight': 'balanced'}. \u001b[0m\n",
      "\u001b[32m[I 2022-12-22 09:01:37,116]\u001b[0m Trial 94 finished with values: [0.7555555555555555, 0.8010010010010009, 0.7555555555555555, 0.8536475869809202] and parameters: {'C': 0.12362597067378263, 'c_weight': None}. \u001b[0m\n",
      "\u001b[32m[I 2022-12-22 09:01:37,476]\u001b[0m Trial 95 finished with values: [0.7333333333333333, 0.7766579569491103, 0.7333333333333333, 0.8254769921436588] and parameters: {'C': 0.5126914863309172, 'c_weight': 'balanced'}. \u001b[0m\n",
      "\u001b[32m[I 2022-12-22 09:01:37,839]\u001b[0m Trial 96 finished with values: [0.7555555555555555, 0.8010010010010009, 0.7555555555555555, 0.8536475869809202] and parameters: {'C': 0.030271041160129467, 'c_weight': 'balanced'}. \u001b[0m\n",
      "\u001b[32m[I 2022-12-22 09:01:37,861]\u001b[0m Trial 97 finished with values: [0.4, 0.5714285714285715, 0.4, 1.0] and parameters: {'C': 1.0946557027804699e-07, 'c_weight': 'balanced'}. \u001b[0m\n",
      "\u001b[32m[I 2022-12-22 09:01:38,090]\u001b[0m Trial 98 finished with values: [0.4888888888888889, 0.6567164179104478, 0.4888888888888889, 1.0] and parameters: {'C': 1.5918444402001894e-07, 'c_weight': None}. \u001b[0m\n",
      "\u001b[32m[I 2022-12-22 09:01:38,452]\u001b[0m Trial 99 finished with values: [0.7555555555555555, 0.8010010010010009, 0.7555555555555555, 0.8536475869809202] and parameters: {'C': 0.041857324574661396, 'c_weight': 'balanced'}. \u001b[0m\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(directions=[\"maximize\", \"maximize\", \"maximize\", \"maximize\"])\n",
    "study.optimize(objective, n_trials=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[FrozenTrial(number=2, values=[0.4888888888888889, 0.6567164179104478, 0.4888888888888889, 1.0], datetime_start=datetime.datetime(2022, 12, 22, 9, 1, 15, 772908), datetime_complete=datetime.datetime(2022, 12, 22, 9, 1, 15, 920129), params={'C': 6.0059332588676985e-06, 'c_weight': None}, distributions={'C': FloatDistribution(high=10.0, log=True, low=1e-07, step=None), 'c_weight': CategoricalDistribution(choices=('balanced', None))}, user_attrs={}, system_attrs={'nsga2:generation': 0}, intermediate_values={}, trial_id=2, state=TrialState.COMPLETE, value=None),\n",
       " FrozenTrial(number=3, values=[0.7777777777777778, 0.8248888888888888, 0.7777777777777778, 0.8877665544332211], datetime_start=datetime.datetime(2022, 12, 22, 9, 1, 15, 922129), datetime_complete=datetime.datetime(2022, 12, 22, 9, 1, 16, 469482), params={'C': 0.00334141326704672, 'c_weight': None}, distributions={'C': FloatDistribution(high=10.0, log=True, low=1e-07, step=None), 'c_weight': CategoricalDistribution(choices=('balanced', None))}, user_attrs={}, system_attrs={'nsga2:generation': 0}, intermediate_values={}, trial_id=3, state=TrialState.COMPLETE, value=None),\n",
       " FrozenTrial(number=6, values=[0.4888888888888889, 0.6567164179104478, 0.4888888888888889, 1.0], datetime_start=datetime.datetime(2022, 12, 22, 9, 1, 16, 624112), datetime_complete=datetime.datetime(2022, 12, 22, 9, 1, 16, 779752), params={'C': 5.727408720496117e-07, 'c_weight': None}, distributions={'C': FloatDistribution(high=10.0, log=True, low=1e-07, step=None), 'c_weight': CategoricalDistribution(choices=('balanced', None))}, user_attrs={}, system_attrs={'nsga2:generation': 0}, intermediate_values={}, trial_id=6, state=TrialState.COMPLETE, value=None),\n",
       " FrozenTrial(number=18, values=[0.4888888888888889, 0.6567164179104478, 0.4888888888888889, 1.0], datetime_start=datetime.datetime(2022, 12, 22, 9, 1, 19, 907943), datetime_complete=datetime.datetime(2022, 12, 22, 9, 1, 20, 58604), params={'C': 1.0946557027804699e-07, 'c_weight': None}, distributions={'C': FloatDistribution(high=10.0, log=True, low=1e-07, step=None), 'c_weight': CategoricalDistribution(choices=('balanced', None))}, user_attrs={}, system_attrs={'nsga2:generation': 0}, intermediate_values={}, trial_id=18, state=TrialState.COMPLETE, value=None),\n",
       " FrozenTrial(number=24, values=[0.4888888888888889, 0.6567164179104478, 0.4888888888888889, 1.0], datetime_start=datetime.datetime(2022, 12, 22, 9, 1, 20, 941135), datetime_complete=datetime.datetime(2022, 12, 22, 9, 1, 21, 170039), params={'C': 4.213347000944026e-06, 'c_weight': None}, distributions={'C': FloatDistribution(high=10.0, log=True, low=1e-07, step=None), 'c_weight': CategoricalDistribution(choices=('balanced', None))}, user_attrs={}, system_attrs={'nsga2:generation': 0}, intermediate_values={}, trial_id=24, state=TrialState.COMPLETE, value=None),\n",
       " FrozenTrial(number=25, values=[0.4888888888888889, 0.6567164179104478, 0.4888888888888889, 1.0], datetime_start=datetime.datetime(2022, 12, 22, 9, 1, 21, 171040), datetime_complete=datetime.datetime(2022, 12, 22, 9, 1, 21, 295569), params={'C': 1.82938418284745e-05, 'c_weight': None}, distributions={'C': FloatDistribution(high=10.0, log=True, low=1e-07, step=None), 'c_weight': CategoricalDistribution(choices=('balanced', None))}, user_attrs={}, system_attrs={'nsga2:generation': 0}, intermediate_values={}, trial_id=25, state=TrialState.COMPLETE, value=None),\n",
       " FrozenTrial(number=28, values=[0.5333333333333333, 0.6557264957264958, 0.5333333333333333, 0.9604938271604938], datetime_start=datetime.datetime(2022, 12, 22, 9, 1, 21, 746470), datetime_complete=datetime.datetime(2022, 12, 22, 9, 1, 21, 906135), params={'C': 8.182328977043016e-05, 'c_weight': None}, distributions={'C': FloatDistribution(high=10.0, log=True, low=1e-07, step=None), 'c_weight': CategoricalDistribution(choices=('balanced', None))}, user_attrs={}, system_attrs={'nsga2:generation': 0}, intermediate_values={}, trial_id=28, state=TrialState.COMPLETE, value=None),\n",
       " FrozenTrial(number=30, values=[0.4888888888888889, 0.6567164179104478, 0.4888888888888889, 1.0], datetime_start=datetime.datetime(2022, 12, 22, 9, 1, 22, 266995), datetime_complete=datetime.datetime(2022, 12, 22, 9, 1, 22, 396885), params={'C': 4.408083750717457e-07, 'c_weight': None}, distributions={'C': FloatDistribution(high=10.0, log=True, low=1e-07, step=None), 'c_weight': CategoricalDistribution(choices=('balanced', None))}, user_attrs={}, system_attrs={'nsga2:generation': 0}, intermediate_values={}, trial_id=30, state=TrialState.COMPLETE, value=None),\n",
       " FrozenTrial(number=32, values=[0.4888888888888889, 0.6567164179104478, 0.4888888888888889, 1.0], datetime_start=datetime.datetime(2022, 12, 22, 9, 1, 22, 688847), datetime_complete=datetime.datetime(2022, 12, 22, 9, 1, 22, 827603), params={'C': 1.5370852538400068e-07, 'c_weight': None}, distributions={'C': FloatDistribution(high=10.0, log=True, low=1e-07, step=None), 'c_weight': CategoricalDistribution(choices=('balanced', None))}, user_attrs={}, system_attrs={'nsga2:generation': 0}, intermediate_values={}, trial_id=32, state=TrialState.COMPLETE, value=None),\n",
       " FrozenTrial(number=44, values=[0.4888888888888889, 0.6567164179104478, 0.4888888888888889, 1.0], datetime_start=datetime.datetime(2022, 12, 22, 9, 1, 25, 332702), datetime_complete=datetime.datetime(2022, 12, 22, 9, 1, 25, 468643), params={'C': 1.6929020417717633e-05, 'c_weight': None}, distributions={'C': FloatDistribution(high=10.0, log=True, low=1e-07, step=None), 'c_weight': CategoricalDistribution(choices=('balanced', None))}, user_attrs={}, system_attrs={'nsga2:generation': 0}, intermediate_values={}, trial_id=44, state=TrialState.COMPLETE, value=None),\n",
       " FrozenTrial(number=45, values=[0.4888888888888889, 0.6567164179104478, 0.4888888888888889, 1.0], datetime_start=datetime.datetime(2022, 12, 22, 9, 1, 25, 469575), datetime_complete=datetime.datetime(2022, 12, 22, 9, 1, 25, 599066), params={'C': 1.791587296177834e-05, 'c_weight': None}, distributions={'C': FloatDistribution(high=10.0, log=True, low=1e-07, step=None), 'c_weight': CategoricalDistribution(choices=('balanced', None))}, user_attrs={}, system_attrs={'nsga2:generation': 0}, intermediate_values={}, trial_id=45, state=TrialState.COMPLETE, value=None),\n",
       " FrozenTrial(number=47, values=[0.4888888888888889, 0.6567164179104478, 0.4888888888888889, 1.0], datetime_start=datetime.datetime(2022, 12, 22, 9, 1, 25, 665318), datetime_complete=datetime.datetime(2022, 12, 22, 9, 1, 25, 792811), params={'C': 3.8952288928811387e-07, 'c_weight': None}, distributions={'C': FloatDistribution(high=10.0, log=True, low=1e-07, step=None), 'c_weight': CategoricalDistribution(choices=('balanced', None))}, user_attrs={}, system_attrs={'nsga2:generation': 0}, intermediate_values={}, trial_id=47, state=TrialState.COMPLETE, value=None),\n",
       " FrozenTrial(number=56, values=[0.4888888888888889, 0.6567164179104478, 0.4888888888888889, 1.0], datetime_start=datetime.datetime(2022, 12, 22, 9, 1, 27, 915119), datetime_complete=datetime.datetime(2022, 12, 22, 9, 1, 28, 117777), params={'C': 2.9546024858190094e-06, 'c_weight': None}, distributions={'C': FloatDistribution(high=10.0, log=True, low=1e-07, step=None), 'c_weight': CategoricalDistribution(choices=('balanced', None))}, user_attrs={}, system_attrs={'nsga2:generation': 1}, intermediate_values={}, trial_id=56, state=TrialState.COMPLETE, value=None),\n",
       " FrozenTrial(number=59, values=[0.4888888888888889, 0.6567164179104478, 0.4888888888888889, 1.0], datetime_start=datetime.datetime(2022, 12, 22, 9, 1, 28, 574214), datetime_complete=datetime.datetime(2022, 12, 22, 9, 1, 28, 701213), params={'C': 6.343201371043475e-07, 'c_weight': None}, distributions={'C': FloatDistribution(high=10.0, log=True, low=1e-07, step=None), 'c_weight': CategoricalDistribution(choices=('balanced', None))}, user_attrs={}, system_attrs={'nsga2:generation': 1}, intermediate_values={}, trial_id=59, state=TrialState.COMPLETE, value=None),\n",
       " FrozenTrial(number=63, values=[0.4888888888888889, 0.6567164179104478, 0.4888888888888889, 1.0], datetime_start=datetime.datetime(2022, 12, 22, 9, 1, 28, 870929), datetime_complete=datetime.datetime(2022, 12, 22, 9, 1, 29, 19419), params={'C': 1.0946557027804699e-07, 'c_weight': None}, distributions={'C': FloatDistribution(high=10.0, log=True, low=1e-07, step=None), 'c_weight': CategoricalDistribution(choices=('balanced', None))}, user_attrs={}, system_attrs={'nsga2:generation': 1}, intermediate_values={}, trial_id=63, state=TrialState.COMPLETE, value=None),\n",
       " FrozenTrial(number=65, values=[0.7777777777777778, 0.8248888888888888, 0.7777777777777778, 0.8877665544332211], datetime_start=datetime.datetime(2022, 12, 22, 9, 1, 29, 95903), datetime_complete=datetime.datetime(2022, 12, 22, 9, 1, 29, 430914), params={'C': 0.003521405324906963, 'c_weight': None}, distributions={'C': FloatDistribution(high=10.0, log=True, low=1e-07, step=None), 'c_weight': CategoricalDistribution(choices=('balanced', None))}, user_attrs={}, system_attrs={'nsga2:generation': 1}, intermediate_values={}, trial_id=65, state=TrialState.COMPLETE, value=None),\n",
       " FrozenTrial(number=66, values=[0.4888888888888889, 0.6567164179104478, 0.4888888888888889, 1.0], datetime_start=datetime.datetime(2022, 12, 22, 9, 1, 29, 432924), datetime_complete=datetime.datetime(2022, 12, 22, 9, 1, 29, 580633), params={'C': 1.0946557027804699e-07, 'c_weight': None}, distributions={'C': FloatDistribution(high=10.0, log=True, low=1e-07, step=None), 'c_weight': CategoricalDistribution(choices=('balanced', None))}, user_attrs={}, system_attrs={'nsga2:generation': 1}, intermediate_values={}, trial_id=66, state=TrialState.COMPLETE, value=None),\n",
       " FrozenTrial(number=67, values=[0.7777777777777778, 0.8248888888888888, 0.7777777777777778, 0.8877665544332211], datetime_start=datetime.datetime(2022, 12, 22, 9, 1, 29, 581638), datetime_complete=datetime.datetime(2022, 12, 22, 9, 1, 29, 939505), params={'C': 0.00334141326704672, 'c_weight': None}, distributions={'C': FloatDistribution(high=10.0, log=True, low=1e-07, step=None), 'c_weight': CategoricalDistribution(choices=('balanced', None))}, user_attrs={}, system_attrs={'nsga2:generation': 1}, intermediate_values={}, trial_id=67, state=TrialState.COMPLETE, value=None),\n",
       " FrozenTrial(number=74, values=[0.4888888888888889, 0.6567164179104478, 0.4888888888888889, 1.0], datetime_start=datetime.datetime(2022, 12, 22, 9, 1, 31, 432443), datetime_complete=datetime.datetime(2022, 12, 22, 9, 1, 31, 554989), params={'C': 3.5430773284483997e-06, 'c_weight': None}, distributions={'C': FloatDistribution(high=10.0, log=True, low=1e-07, step=None), 'c_weight': CategoricalDistribution(choices=('balanced', None))}, user_attrs={}, system_attrs={'nsga2:generation': 1}, intermediate_values={}, trial_id=74, state=TrialState.COMPLETE, value=None),\n",
       " FrozenTrial(number=76, values=[0.4888888888888889, 0.6567164179104478, 0.4888888888888889, 1.0], datetime_start=datetime.datetime(2022, 12, 22, 9, 1, 31, 823733), datetime_complete=datetime.datetime(2022, 12, 22, 9, 1, 31, 953889), params={'C': 2.4772861244359134e-05, 'c_weight': None}, distributions={'C': FloatDistribution(high=10.0, log=True, low=1e-07, step=None), 'c_weight': CategoricalDistribution(choices=('balanced', None))}, user_attrs={}, system_attrs={'nsga2:generation': 1}, intermediate_values={}, trial_id=76, state=TrialState.COMPLETE, value=None),\n",
       " FrozenTrial(number=82, values=[0.4888888888888889, 0.6567164179104478, 0.4888888888888889, 1.0], datetime_start=datetime.datetime(2022, 12, 22, 9, 1, 33, 849157), datetime_complete=datetime.datetime(2022, 12, 22, 9, 1, 33, 972968), params={'C': 1.265595025547944e-05, 'c_weight': None}, distributions={'C': FloatDistribution(high=10.0, log=True, low=1e-07, step=None), 'c_weight': CategoricalDistribution(choices=('balanced', None))}, user_attrs={}, system_attrs={'nsga2:generation': 1}, intermediate_values={}, trial_id=82, state=TrialState.COMPLETE, value=None),\n",
       " FrozenTrial(number=83, values=[0.7777777777777778, 0.8248888888888888, 0.7777777777777778, 0.8877665544332211], datetime_start=datetime.datetime(2022, 12, 22, 9, 1, 33, 973480), datetime_complete=datetime.datetime(2022, 12, 22, 9, 1, 34, 337629), params={'C': 0.003479807667371505, 'c_weight': None}, distributions={'C': FloatDistribution(high=10.0, log=True, low=1e-07, step=None), 'c_weight': CategoricalDistribution(choices=('balanced', None))}, user_attrs={}, system_attrs={'nsga2:generation': 1}, intermediate_values={}, trial_id=83, state=TrialState.COMPLETE, value=None),\n",
       " FrozenTrial(number=92, values=[0.7777777777777778, 0.8248888888888888, 0.7777777777777778, 0.8877665544332211], datetime_start=datetime.datetime(2022, 12, 22, 9, 1, 36, 35122), datetime_complete=datetime.datetime(2022, 12, 22, 9, 1, 36, 392662), params={'C': 0.00334141326704672, 'c_weight': None}, distributions={'C': FloatDistribution(high=10.0, log=True, low=1e-07, step=None), 'c_weight': CategoricalDistribution(choices=('balanced', None))}, user_attrs={}, system_attrs={'nsga2:generation': 1}, intermediate_values={}, trial_id=92, state=TrialState.COMPLETE, value=None),\n",
       " FrozenTrial(number=98, values=[0.4888888888888889, 0.6567164179104478, 0.4888888888888889, 1.0], datetime_start=datetime.datetime(2022, 12, 22, 9, 1, 37, 862755), datetime_complete=datetime.datetime(2022, 12, 22, 9, 1, 38, 89920), params={'C': 1.5918444402001894e-07, 'c_weight': None}, distributions={'C': FloatDistribution(high=10.0, log=True, low=1e-07, step=None), 'c_weight': CategoricalDistribution(choices=('balanced', None))}, user_attrs={}, system_attrs={'nsga2:generation': 1}, intermediate_values={}, trial_id=98, state=TrialState.COMPLETE, value=None)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.778, F1: 0.825, Recall: 0.778, Precision: 0.888, Params: {'C': 0.00334141326704672, 'c_weight': None}\n",
      "Accuracy: 0.778, F1: 0.825, Recall: 0.778, Precision: 0.888, Params: {'C': 0.003521405324906963, 'c_weight': None}\n",
      "Accuracy: 0.778, F1: 0.825, Recall: 0.778, Precision: 0.888, Params: {'C': 0.00334141326704672, 'c_weight': None}\n",
      "Accuracy: 0.778, F1: 0.825, Recall: 0.778, Precision: 0.888, Params: {'C': 0.003479807667371505, 'c_weight': None}\n",
      "Accuracy: 0.778, F1: 0.825, Recall: 0.778, Precision: 0.888, Params: {'C': 0.00334141326704672, 'c_weight': None}\n"
     ]
    }
   ],
   "source": [
    "for trial in study.best_trials:\n",
    "    if trial.values[0] > 0.6:\n",
    "        print(f\"Accuracy: {round(trial.values[0], 3)}, F1: {round(trial.values[1], 3)}, Recall: {round(trial.values[2], 3)}, Precision: {round(trial.values[3], 3)}, Params: {trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "\n",
    "clf = LogisticRegression(C=0.003)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "pred = clf.predict(X_test)\n",
    "\n",
    "acc = accuracy_score(pred, y_test)\n",
    "recall = recall_score(pred, y_test, average=\"weighted\")\n",
    "precision = precision_score(pred, y_test, average=\"weighted\")\n",
    "f1 = f1_score(pred, y_test, average=\"weighted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.778, F1: 0.825, Recall: 0.778, Precision: 0.888\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy: {round(acc, 3)}, F1: {round(f1, 3)}, Recall: {round(recall, 3)}, Precision: {round(precision, 3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'              precision    recall  f1-score   support\\n\\n           0       0.78      0.82      0.80        17\\n           1       0.00      0.00      0.00         0\\n           2       0.95      0.75      0.84        28\\n\\n    accuracy                           0.78        45\\n   macro avg       0.58      0.52      0.55        45\\nweighted avg       0.89      0.78      0.82        45\\n'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_report(pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "443c96f07534edf61d2e520f7701ba5fe2602e8b5ceabdcfb66f122d33fe2a22"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
