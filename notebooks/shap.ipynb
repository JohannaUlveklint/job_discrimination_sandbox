{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import sklearn.ensemble\n",
    "import sklearn.metrics\n",
    "from sklearn.utils import shuffle\n",
    "from io import StringIO\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "# import lime\n",
    "# from lime import lime_text\n",
    "# from lime.lime_text import LimeTextExplainer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Code\\\\job_discrimination'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "workspace_path = os.path.join(os.path.abspath(\"..\"))\n",
    "sys.path.append(workspace_path)\n",
    "workspace_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.float_format = \"{:.2f}\".format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>ID</th>\n",
       "      <th>Job Description</th>\n",
       "      <th>Apps Received</th>\n",
       "      <th>Female</th>\n",
       "      <th>Male</th>\n",
       "      <th>Unknown_Gender</th>\n",
       "      <th>File Names</th>\n",
       "      <th>Label</th>\n",
       "      <th>Text</th>\n",
       "      <th>Cleaned text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9206</td>\n",
       "      <td>311 DIRECTOR</td>\n",
       "      <td>54</td>\n",
       "      <td>20</td>\n",
       "      <td>31</td>\n",
       "      <td>3</td>\n",
       "      <td>311 DIRECTOR  9206 041814.txt</td>\n",
       "      <td>M</td>\n",
       "      <td>311 DIRECTOR Class Code:       9206 Open Date:...</td>\n",
       "      <td>director class code open date annual salary du...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1223</td>\n",
       "      <td>ACCOUNTING CLERK</td>\n",
       "      <td>648</td>\n",
       "      <td>488</td>\n",
       "      <td>152</td>\n",
       "      <td>8</td>\n",
       "      <td>ACCOUNTING CLERK 1223 071318.txt</td>\n",
       "      <td>W</td>\n",
       "      <td>ACCOUNTING CLERK  Class Code:       1223 Open ...</td>\n",
       "      <td>accounting clerk class code open date exam ope...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>7260</td>\n",
       "      <td>AIRPORT MANAGER</td>\n",
       "      <td>51</td>\n",
       "      <td>13</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>AIRPORT MANAGER 7260 120216.txt</td>\n",
       "      <td>M</td>\n",
       "      <td>AIRPORT MANAGER  Class Code:       7260 Open D...</td>\n",
       "      <td>airport manager class code open date exam open...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3227</td>\n",
       "      <td>AIRPORT POLICE LIEUTENANT</td>\n",
       "      <td>48</td>\n",
       "      <td>9</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>AIRPORT POLICE LIEUTENANT 3227 091616.txt</td>\n",
       "      <td>M</td>\n",
       "      <td>AIRPORT POLICE LIEUTENANT                 ...</td>\n",
       "      <td>airport police lieutenant class code open date...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2400</td>\n",
       "      <td>AQUARIST</td>\n",
       "      <td>40</td>\n",
       "      <td>15</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>AQUARIST 2400 050214.txt</td>\n",
       "      <td>M</td>\n",
       "      <td>AQUARIST Class Code:       2400 Open Date:  05...</td>\n",
       "      <td>aquarist class code open date annual salary ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>172</td>\n",
       "      <td>172</td>\n",
       "      <td>7840</td>\n",
       "      <td>WASTEWATER TREATMENT LABORATORY MANAGER</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>WASTEWATER TREATMENT LABORATORY MANAGER 7840 1...</td>\n",
       "      <td>M</td>\n",
       "      <td>WASTEWATER TREATMENT LABORATORY MANAGER  Class...</td>\n",
       "      <td>wastewater treatment laboratory manager class ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>173</td>\n",
       "      <td>173</td>\n",
       "      <td>4123</td>\n",
       "      <td>WASTEWATER TREATMENT OPERATOR</td>\n",
       "      <td>125</td>\n",
       "      <td>9</td>\n",
       "      <td>113</td>\n",
       "      <td>3</td>\n",
       "      <td>WASTEWATER TREATMENT OPERATOR 120718.txt</td>\n",
       "      <td>M</td>\n",
       "      <td>WASTEWATER TREATMENT OPERATOR  Class Code:    ...</td>\n",
       "      <td>wastewater treatment operator class code open ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>174</td>\n",
       "      <td>174</td>\n",
       "      <td>7857</td>\n",
       "      <td>WATER MICROBIOLOGIST</td>\n",
       "      <td>179</td>\n",
       "      <td>89</td>\n",
       "      <td>82</td>\n",
       "      <td>8</td>\n",
       "      <td>WATER MICROBIOLOGIST  7857 072514 rev073114.txt</td>\n",
       "      <td>N</td>\n",
       "      <td>WATER MICROBIOLOGIST Class Code:       7857...</td>\n",
       "      <td>water microbiologist class code open date revi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>175</td>\n",
       "      <td>175</td>\n",
       "      <td>3912</td>\n",
       "      <td>WATER UTILITY WORKER</td>\n",
       "      <td>96</td>\n",
       "      <td>2</td>\n",
       "      <td>92</td>\n",
       "      <td>2</td>\n",
       "      <td>WATER UTILITY WORKER 3912 120817.txt</td>\n",
       "      <td>M</td>\n",
       "      <td>WATER UTILITY WORKER Class Code:       3912 Op...</td>\n",
       "      <td>water utility worker class code open date exam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>176</td>\n",
       "      <td>176</td>\n",
       "      <td>1774</td>\n",
       "      <td>WORKERS COMPENSATION ANALYST</td>\n",
       "      <td>166</td>\n",
       "      <td>100</td>\n",
       "      <td>61</td>\n",
       "      <td>5</td>\n",
       "      <td>WORKERS_ COMPENSATION ANALYST 1774 032417R.txt</td>\n",
       "      <td>W</td>\n",
       "      <td>WORKERS' COMPENSATION ANALYST Class Code:     ...</td>\n",
       "      <td>worker compensation analyst class code open da...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>177 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0.1  Unnamed: 0    ID                          Job Description  \\\n",
       "0               0           0  9206                             311 DIRECTOR   \n",
       "1               1           1  1223                         ACCOUNTING CLERK   \n",
       "2               2           2  7260                          AIRPORT MANAGER   \n",
       "3               3           3  3227                AIRPORT POLICE LIEUTENANT   \n",
       "4               4           4  2400                                 AQUARIST   \n",
       "..            ...         ...   ...                                      ...   \n",
       "172           172         172  7840  WASTEWATER TREATMENT LABORATORY MANAGER   \n",
       "173           173         173  4123            WASTEWATER TREATMENT OPERATOR   \n",
       "174           174         174  7857                     WATER MICROBIOLOGIST   \n",
       "175           175         175  3912                     WATER UTILITY WORKER   \n",
       "176           176         176  1774             WORKERS COMPENSATION ANALYST   \n",
       "\n",
       "     Apps Received  Female  Male  Unknown_Gender  \\\n",
       "0               54      20    31               3   \n",
       "1              648     488   152               8   \n",
       "2               51      13    37               1   \n",
       "3               48       9    38               1   \n",
       "4               40      15    24               1   \n",
       "..             ...     ...   ...             ...   \n",
       "172             16       6     9               1   \n",
       "173            125       9   113               3   \n",
       "174            179      89    82               8   \n",
       "175             96       2    92               2   \n",
       "176            166     100    61               5   \n",
       "\n",
       "                                            File Names Label  \\\n",
       "0                        311 DIRECTOR  9206 041814.txt     M   \n",
       "1                     ACCOUNTING CLERK 1223 071318.txt     W   \n",
       "2                      AIRPORT MANAGER 7260 120216.txt     M   \n",
       "3            AIRPORT POLICE LIEUTENANT 3227 091616.txt     M   \n",
       "4                             AQUARIST 2400 050214.txt     M   \n",
       "..                                                 ...   ...   \n",
       "172  WASTEWATER TREATMENT LABORATORY MANAGER 7840 1...     M   \n",
       "173           WASTEWATER TREATMENT OPERATOR 120718.txt     M   \n",
       "174    WATER MICROBIOLOGIST  7857 072514 rev073114.txt     N   \n",
       "175               WATER UTILITY WORKER 3912 120817.txt     M   \n",
       "176     WORKERS_ COMPENSATION ANALYST 1774 032417R.txt     W   \n",
       "\n",
       "                                                  Text  \\\n",
       "0    311 DIRECTOR Class Code:       9206 Open Date:...   \n",
       "1    ACCOUNTING CLERK  Class Code:       1223 Open ...   \n",
       "2    AIRPORT MANAGER  Class Code:       7260 Open D...   \n",
       "3        AIRPORT POLICE LIEUTENANT                 ...   \n",
       "4    AQUARIST Class Code:       2400 Open Date:  05...   \n",
       "..                                                 ...   \n",
       "172  WASTEWATER TREATMENT LABORATORY MANAGER  Class...   \n",
       "173  WASTEWATER TREATMENT OPERATOR  Class Code:    ...   \n",
       "174     WATER MICROBIOLOGIST Class Code:       7857...   \n",
       "175  WATER UTILITY WORKER Class Code:       3912 Op...   \n",
       "176  WORKERS' COMPENSATION ANALYST Class Code:     ...   \n",
       "\n",
       "                                          Cleaned text  \n",
       "0    director class code open date annual salary du...  \n",
       "1    accounting clerk class code open date exam ope...  \n",
       "2    airport manager class code open date exam open...  \n",
       "3    airport police lieutenant class code open date...  \n",
       "4    aquarist class code open date annual salary ca...  \n",
       "..                                                 ...  \n",
       "172  wastewater treatment laboratory manager class ...  \n",
       "173  wastewater treatment operator class code open ...  \n",
       "174  water microbiologist class code open date revi...  \n",
       "175  water utility worker class code open date exam...  \n",
       "176  worker compensation analyst class code open da...  \n",
       "\n",
       "[177 rows x 12 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading application statistics into dataframe\n",
    "filepath = os.path.join(workspace_path, \"data\", \"cleaned_data\", \"bulletins_w_labels_and_content.csv\")\n",
    "df = pd.read_csv(filepath)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_corpus = df[\"Cleaned text\"].tolist()\n",
    "list_labels = df[\"Label\"].tolist()\n",
    "X_train, X_test, y_train, y_test = train_test_split(list_corpus, list_labels, test_size=0.2, random_state=40)\n",
    "vectorizer = CountVectorizer(analyzer='word',token_pattern=r'\\w{1,}', ngram_range=(1, 3), stop_words = 'english', binary=True)\n",
    "train_vectors = vectorizer.fit_transform(X_train)\n",
    "test_vectors = vectorizer.transform(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 0.639, precision = 0.777, recall = 0.639, f1 = 0.543\n"
     ]
    }
   ],
   "source": [
    "# logreg = LogisticRegression(n_jobs=1, C=1e5)\n",
    "# logreg.fit(train_vectors, y_train)\n",
    "# pred = logreg.predict(test_vectors)\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svm = SVC(kernel=\"linear\", probability=True)\n",
    "svm.fit(train_vectors, y_train)\n",
    "pred = svm.predict(test_vectors)\n",
    "\n",
    "accuracy = accuracy_score(y_test, pred)\n",
    "precision = precision_score(y_test, pred, average='weighted')\n",
    "recall = recall_score(y_test, pred, average='weighted')\n",
    "f1 = f1_score(y_test, pred, average='weighted')\n",
    "print(\"accuracy = %.3f, precision = %.3f, recall = %.3f, f1 = %.3f\" % (accuracy, precision, recall, f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0],\n",
       "       [0, 0, 1],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 0, 1],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 1, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 0, 1],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 0, 1],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 1, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       [1, 0, 0]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "y should be a 1d array, got an array of shape (141, 3) instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 46\u001b[0m\n\u001b[0;32m     44\u001b[0m     \u001b[39mreturn\u001b[39;00m model\n\u001b[0;32m     45\u001b[0m \u001b[39m# model = create_model(VOCAB_SIZE, num_tags)\u001b[39;00m\n\u001b[1;32m---> 46\u001b[0m svm\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n\u001b[0;32m     47\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mEval loss/accuracy:\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(svm\u001b[39m.\u001b[39mevaluate(X_test, y_test)))\n",
      "File \u001b[1;32mc:\\Code\\job_discrimination\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:173\u001b[0m, in \u001b[0;36mBaseLibSVM.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    171\u001b[0m     check_consistent_length(X, y)\n\u001b[0;32m    172\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 173\u001b[0m     X, y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[0;32m    174\u001b[0m         X,\n\u001b[0;32m    175\u001b[0m         y,\n\u001b[0;32m    176\u001b[0m         dtype\u001b[39m=\u001b[39;49mnp\u001b[39m.\u001b[39;49mfloat64,\n\u001b[0;32m    177\u001b[0m         order\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mC\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    178\u001b[0m         accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    179\u001b[0m         accept_large_sparse\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    180\u001b[0m     )\n\u001b[0;32m    182\u001b[0m y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_targets(y)\n\u001b[0;32m    184\u001b[0m sample_weight \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masarray(\n\u001b[0;32m    185\u001b[0m     [] \u001b[39mif\u001b[39;00m sample_weight \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m sample_weight, dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mfloat64\n\u001b[0;32m    186\u001b[0m )\n",
      "File \u001b[1;32mc:\\Code\\job_discrimination\\venv\\lib\\site-packages\\sklearn\\base.py:596\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    594\u001b[0m         y \u001b[39m=\u001b[39m check_array(y, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_y_params)\n\u001b[0;32m    595\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 596\u001b[0m         X, y \u001b[39m=\u001b[39m check_X_y(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_params)\n\u001b[0;32m    597\u001b[0m     out \u001b[39m=\u001b[39m X, y\n\u001b[0;32m    599\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m check_params\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mensure_2d\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m):\n",
      "File \u001b[1;32mc:\\Code\\job_discrimination\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1090\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1070\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1071\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mestimator_name\u001b[39m}\u001b[39;00m\u001b[39m requires y to be passed, but the target y is None\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1072\u001b[0m     )\n\u001b[0;32m   1074\u001b[0m X \u001b[39m=\u001b[39m check_array(\n\u001b[0;32m   1075\u001b[0m     X,\n\u001b[0;32m   1076\u001b[0m     accept_sparse\u001b[39m=\u001b[39maccept_sparse,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1087\u001b[0m     input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mX\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1088\u001b[0m )\n\u001b[1;32m-> 1090\u001b[0m y \u001b[39m=\u001b[39m _check_y(y, multi_output\u001b[39m=\u001b[39;49mmulti_output, y_numeric\u001b[39m=\u001b[39;49my_numeric, estimator\u001b[39m=\u001b[39;49mestimator)\n\u001b[0;32m   1092\u001b[0m check_consistent_length(X, y)\n\u001b[0;32m   1094\u001b[0m \u001b[39mreturn\u001b[39;00m X, y\n",
      "File \u001b[1;32mc:\\Code\\job_discrimination\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1111\u001b[0m, in \u001b[0;36m_check_y\u001b[1;34m(y, multi_output, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1109\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1110\u001b[0m     estimator_name \u001b[39m=\u001b[39m _check_estimator_name(estimator)\n\u001b[1;32m-> 1111\u001b[0m     y \u001b[39m=\u001b[39m column_or_1d(y, warn\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m   1112\u001b[0m     _assert_all_finite(y, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my\u001b[39m\u001b[39m\"\u001b[39m, estimator_name\u001b[39m=\u001b[39mestimator_name)\n\u001b[0;32m   1113\u001b[0m     _ensure_no_complex_data(y)\n",
      "File \u001b[1;32mc:\\Code\\job_discrimination\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1156\u001b[0m, in \u001b[0;36mcolumn_or_1d\u001b[1;34m(y, warn)\u001b[0m\n\u001b[0;32m   1147\u001b[0m         warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m   1148\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mA column-vector y was passed when a 1d array was\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1149\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m expected. Please change the shape of y to \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1152\u001b[0m             stacklevel\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m,\n\u001b[0;32m   1153\u001b[0m         )\n\u001b[0;32m   1154\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39mravel(y)\n\u001b[1;32m-> 1156\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1157\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39my should be a 1d array, got an array of shape \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m instead.\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(shape)\n\u001b[0;32m   1158\u001b[0m )\n",
      "\u001b[1;31mValueError\u001b[0m: y should be a 1d array, got an array of shape (141, 3) instead."
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import text\n",
    "# import keras.backend.tensorflow_backend as K\n",
    "# K.set_session\n",
    "import shap\n",
    "\n",
    "tags_split = [tags.split(',') for tags in df['Label'].values]\n",
    "tag_encoder = MultiLabelBinarizer()\n",
    "tags_encoded = tag_encoder.fit_transform(tags_split)\n",
    "num_tags = len(tags_encoded[0])\n",
    "train_size = int(len(df) * .8)\n",
    "\n",
    "y_train = tags_encoded[: train_size]\n",
    "y_test = tags_encoded[train_size:]\n",
    "\n",
    "class TextPreprocessor(object):\n",
    "    def __init__(self, vocab_size):\n",
    "        self._vocab_size = vocab_size\n",
    "        self._tokenizer = None\n",
    "    def create_tokenizer(self, text_list):\n",
    "        tokenizer = text.Tokenizer(num_words = self._vocab_size)\n",
    "        tokenizer.fit_on_texts(text_list)\n",
    "        self._tokenizer = tokenizer\n",
    "    def transform_text(self, text_list):\n",
    "        text_matrix = self._tokenizer.texts_to_matrix(text_list)\n",
    "        return text_matrix\n",
    "     \n",
    "VOCAB_SIZE = 500\n",
    "train_post = df['Cleaned text'].values[: train_size]\n",
    "test_post = df['Cleaned text'].values[train_size: ]\n",
    "processor = TextPreprocessor(VOCAB_SIZE)\n",
    "processor.create_tokenizer(train_post)\n",
    "X_train = processor.transform_text(train_post)\n",
    "X_test = processor.transform_text(test_post)\n",
    "\n",
    "def create_model(vocab_size, num_tags):\n",
    "    # model = tf.keras.models.Sequential()\n",
    "    # model.add(tf.keras.layers.Dense(50, input_shape = (VOCAB_SIZE,), activation='relu'))\n",
    "    # model.add(tf.keras.layers.Dense(25, activation='relu'))\n",
    "    # model.add(tf.keras.layers.Dense(num_tags, activation='sigmoid'))\n",
    "    # model.compile(loss = 'binary_crossentropy', optimizer='adam', metrics = ['accuracy'])\n",
    "    model = SVC(kernel=\"linear\", probability=True)\n",
    "    return model\n",
    "# model = create_model(VOCAB_SIZE, num_tags)\n",
    "svm.fit(X_train, y_train)\n",
    "print('Eval loss/accuracy:{}'.format(svm.evaluate(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Provided model function fails when applied to the provided data set.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 500 features, but SVC is expecting 60906 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m attrib_data \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(X_train[:\u001b[39m10\u001b[39m])\n\u001b[1;32m----> 2\u001b[0m explainer \u001b[39m=\u001b[39m shap\u001b[39m.\u001b[39;49mKernelExplainer(svm\u001b[39m.\u001b[39;49mpredict_proba, attrib_data)\n\u001b[0;32m      3\u001b[0m num_explanations \u001b[39m=\u001b[39m \u001b[39m20\u001b[39m\n\u001b[0;32m      4\u001b[0m shap_vals \u001b[39m=\u001b[39m explainer\u001b[39m.\u001b[39mshap_values(X_test[:num_explanations])\n",
      "File \u001b[1;32mc:\\Code\\job_discrimination\\venv\\lib\\site-packages\\shap\\explainers\\_kernel.py:70\u001b[0m, in \u001b[0;36mKernel.__init__\u001b[1;34m(self, model, data, link, **kwargs)\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkeep_index_ordered \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mkeep_index_ordered\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m     69\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata \u001b[39m=\u001b[39m convert_to_data(data, keep_index\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkeep_index)\n\u001b[1;32m---> 70\u001b[0m model_null \u001b[39m=\u001b[39m match_model_to_data(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdata)\n\u001b[0;32m     72\u001b[0m \u001b[39m# enforce our current input type limitations\u001b[39;00m\n\u001b[0;32m     73\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata, DenseData) \u001b[39mor\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata, SparseData), \\\n\u001b[0;32m     74\u001b[0m        \u001b[39m\"\u001b[39m\u001b[39mShap explainer only supports the DenseData and SparseData input currently.\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Code\\job_discrimination\\venv\\lib\\site-packages\\shap\\utils\\_legacy.py:112\u001b[0m, in \u001b[0;36mmatch_model_to_data\u001b[1;34m(model, data)\u001b[0m\n\u001b[0;32m    110\u001b[0m         out_val \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mf(data\u001b[39m.\u001b[39mconvert_to_df())\n\u001b[0;32m    111\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 112\u001b[0m         out_val \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mf(data\u001b[39m.\u001b[39;49mdata)\n\u001b[0;32m    113\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[0;32m    114\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mProvided model function fails when applied to the provided data set.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Code\\job_discrimination\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:853\u001b[0m, in \u001b[0;36mBaseSVC.predict_proba\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    826\u001b[0m \u001b[39m@available_if\u001b[39m(_check_proba)\n\u001b[0;32m    827\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict_proba\u001b[39m(\u001b[39mself\u001b[39m, X):\n\u001b[0;32m    828\u001b[0m     \u001b[39m\"\"\"Compute probabilities of possible outcomes for samples in X.\u001b[39;00m\n\u001b[0;32m    829\u001b[0m \n\u001b[0;32m    830\u001b[0m \u001b[39m    The model need to have probability information computed at training\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    851\u001b[0m \u001b[39m    datasets.\u001b[39;00m\n\u001b[0;32m    852\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 853\u001b[0m     X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_for_predict(X)\n\u001b[0;32m    854\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprobA_\u001b[39m.\u001b[39msize \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprobB_\u001b[39m.\u001b[39msize \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    855\u001b[0m         \u001b[39mraise\u001b[39;00m NotFittedError(\n\u001b[0;32m    856\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mpredict_proba is not available when fitted with probability=False\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    857\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Code\\job_discrimination\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:611\u001b[0m, in \u001b[0;36mBaseLibSVM._validate_for_predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    608\u001b[0m check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[0;32m    610\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m callable(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkernel):\n\u001b[1;32m--> 611\u001b[0m     X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[0;32m    612\u001b[0m         X,\n\u001b[0;32m    613\u001b[0m         accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    614\u001b[0m         dtype\u001b[39m=\u001b[39;49mnp\u001b[39m.\u001b[39;49mfloat64,\n\u001b[0;32m    615\u001b[0m         order\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mC\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    616\u001b[0m         accept_large_sparse\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    617\u001b[0m         reset\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    618\u001b[0m     )\n\u001b[0;32m    620\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sparse \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m sp\u001b[39m.\u001b[39misspmatrix(X):\n\u001b[0;32m    621\u001b[0m     X \u001b[39m=\u001b[39m sp\u001b[39m.\u001b[39mcsr_matrix(X)\n",
      "File \u001b[1;32mc:\\Code\\job_discrimination\\venv\\lib\\site-packages\\sklearn\\base.py:600\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    597\u001b[0m     out \u001b[39m=\u001b[39m X, y\n\u001b[0;32m    599\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m check_params\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mensure_2d\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m):\n\u001b[1;32m--> 600\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_n_features(X, reset\u001b[39m=\u001b[39;49mreset)\n\u001b[0;32m    602\u001b[0m \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[1;32mc:\\Code\\job_discrimination\\venv\\lib\\site-packages\\sklearn\\base.py:400\u001b[0m, in \u001b[0;36mBaseEstimator._check_n_features\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    397\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m    399\u001b[0m \u001b[39mif\u001b[39;00m n_features \u001b[39m!=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_features_in_:\n\u001b[1;32m--> 400\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    401\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mX has \u001b[39m\u001b[39m{\u001b[39;00mn_features\u001b[39m}\u001b[39;00m\u001b[39m features, but \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    402\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mis expecting \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_features_in_\u001b[39m}\u001b[39;00m\u001b[39m features as input.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    403\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: X has 500 features, but SVC is expecting 60906 features as input."
     ]
    }
   ],
   "source": [
    "attrib_data = np.array(X_train[:10])\n",
    "explainer = shap.KernelExplainer(svm.predict_proba, attrib_data)\n",
    "num_explanations = 20\n",
    "shap_vals = explainer.shap_values(X_test[:num_explanations])\n",
    "words = processor._tokenizer.word_index\n",
    "word_lookup = list()\n",
    "for i in words.keys():\n",
    "  word_lookup.append(i)\n",
    "word_lookup = [''] + word_lookup\n",
    "shap.summary_plot(shap_vals, feature_names=word_lookup, class_names=tag_encoder.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "03cf01ef86f269a1048d71dde4c501a889394fccdb9fde48c1dca9e7d462554e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
